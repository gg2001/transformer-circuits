{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gg2001/transformer-circuits/blob/master/arena/%5B1_1%5D_Transformer_from_Scratch_(exercises).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [1.1] - Transformers from scratch\n"
      ],
      "metadata": {
        "id": "sRrD2AbyMwmP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usCBu-Op2CeU"
      },
      "source": [
        "Colab: [exercises](https://colab.research.google.com/drive/1lDwKASSYGE4y_7DuGSqlo3DN41NHrXEw?usp=sharing) | [solutions](https://colab.research.google.com/drive/1bZkkJd8pAVnSN23svyszZ3f4WrnYKN_3?usp=sharing)\n",
        "\n",
        "[Streamlit page](https://arena3-chapter1-transformer-interp.streamlit.app/[1.1]_Transformer_from_Scratch)\n",
        "\n",
        "Please send any problems / bugs on the `#errata` channel in the [Slack group](https://join.slack.com/t/arena-uk/shared_invite/zt-28h0xs49u-ZN9ZDbGXl~oCorjbBsSQag), and ask any questions on the dedicated channels for this chapter of material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XdSGDOH2qtL"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/TransformerLens-intro/main/images/page_images/transformer-building.png\" width=\"350\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny4PdCRf3YPu"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGQQ6Sm7fHNm"
      },
      "source": [
        "This is a clean, first principles implementation of GPT-2 in PyTorch. The architectural choices closely follow those used by the TransformerLens library (which you'll be using a lot more in later exercises).\n",
        "\n",
        "The exercises are written to accompany Neel Nanda's [TransformerLens library](https://github.com/neelnanda-io/TransformerLens) for doing mechanistic interpretability research on GPT-2 style language models. We'll be working with this library extensively in this chapter of the course.\n",
        "\n",
        "Each exercise will have a difficulty and importance rating out of 5, as well as an estimated maximum time you should spend on these exercises and sometimes a short annotation. You should interpret the ratings & time estimates relatively (e.g. if you find yourself spending about 50% longer on the exercises than the time estimates, adjust accordingly). Please do skip exercises / look at solutions if you don't feel like they're important enough to be worth doing, and you'd rather get to the good stuff!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugWVaR9Gm4Rw"
      },
      "source": [
        "## Content & Learning Objectives\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzS18i5wfHNm"
      },
      "source": [
        "#### 1️⃣ Understanding Inputs & Outputs of a Transformer\n",
        "\n",
        "In this section, we'll take a first look at transformers - what their function is, how information moves inside a transformer, and what inputs & outputs they take.\n",
        "\n",
        "> ##### Learning objectives\n",
        ">\n",
        "> - Understand what a transformer is used for\n",
        "> - Understand causal attention, and what a transformer's output representsalgebra operations on tensors\n",
        "> - Learn what tokenization is, and how models do it\n",
        "> - Understand what logits are, and how to use them to derive a probability distribution over the vocabulary\n",
        "\n",
        "#### 2️⃣ Clean Transformer Implementation\n",
        "\n",
        "Here, we'll implement a transformer from scratch, using only PyTorch's tensor operations. This will give us a good understanding of how transformers work, and how to use them. We do this by going module-by-module, in an experience which should feel somewhat similar to last week's ResNet exercises. Much like with ResNets, you'll conclude by loading in pretrained weights and verifying that your model works as expected.\n",
        "\n",
        "> ##### Learning objectives\n",
        ">\n",
        "> * Understand that a transformer is composed of attention heads and MLPs, with each one performing operations on the residual stream\n",
        "> * Understand that the attention heads in a single layer operate independently, and that they have the role of calculating attention patterns (which determine where information is moved to & from in the residual stream)\n",
        "> * Learn about & implement the following transformer modules:\n",
        ">     * LayerNorm (transforming the input to have zero mean and unit variance)\n",
        ">     * Positional embedding (a lookup table from position indices to residual stream vectors)\n",
        ">     * Attention (the method of computing attention patterns for residual stream vectors)\n",
        ">     * MLP (the collection of linear and nonlinear transformations which operate on each residual stream vector in the same way)\n",
        ">     * Embedding (a lookup table from tokens to residual stream vectors)\n",
        ">     * Unembedding (a matrix for converting residual stream vectors into a distribution over tokens)\n",
        "\n",
        "#### 3️⃣ Training a Transformer\n",
        "\n",
        "Next, you'll learn how to train your transformer from scratch. This will be quite similar to the training loops you wrote for ResNet in your first week.\n",
        "\n",
        "> ##### Learning objectives\n",
        ">\n",
        "> * Understand how to train a transformer from scratch\n",
        "> * Write a basic transformer training loop\n",
        "> * Interpret the transformer's falling cross entropy loss with reference to features of the training data (e.g. bigram frequencies)\n",
        "\n",
        "#### 4️⃣ Sampling from a Transformer\n",
        "\n",
        "Lastly, you'll learn how to sample from a transformer. This will involve implementing a few different sampling methods, and writing a caching system which can reuse computations from previous forward passes to improve your model's text generation speed.\n",
        "\n",
        "*The second half of this section is less important, and you can skip it if you want.*\n",
        "\n",
        "> ##### Learning objectives\n",
        ">\n",
        "> * Learn how to sample from a transformer\n",
        ">     * This includes basic methods like greedy search or top-k, and more advanced methods like beam search\n",
        "> * Learn how to cache the output of a transformer, so that it can be used to generate text more efficiently\n",
        ">     * Optionally, rewrite your sampling functions to make use of your caching methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mItbKVVm4Rx"
      },
      "source": [
        "## Setup (don't read, just run!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_ngQtCbm4Rx",
        "outputId": "627fff50-b76d-4c1b-b1f9-c301921bb439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-2.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.32.1)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer_lens)\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.8.0)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.2.34-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.1.4)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.4.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.5)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.42.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.12.2)\n",
            "Collecting wandb>=0.13.5 (from transformer_lens)\n",
            "  Downloading wandb-0.17.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.23.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.15.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.10.5)\n",
            "Collecting typeguard==2.13.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (0.19.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (4.2.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer_lens) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer_lens) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading transformer_lens-2.4.0-py3-none-any.whl (174 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.8/174.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading jaxtyping-0.2.34-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading wandb-0.17.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.1/309.1 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: better-abc, xxhash, typeguard, smmap, setproctitle, sentry-sdk, pyarrow, fancy-einsum, docker-pycreds, dill, beartype, multiprocess, jaxtyping, gitdb, gitpython, wandb, datasets, transformer_lens\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.3.0\n",
            "    Uninstalling typeguard-4.3.0:\n",
            "      Successfully uninstalled typeguard-4.3.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
            "inflect 7.3.1 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 datasets-2.21.0 dill-0.3.8 docker-pycreds-0.4.0 fancy-einsum-0.0.3 gitdb-4.0.11 gitpython-3.1.43 jaxtyping-0.2.34 multiprocess-0.70.16 pyarrow-17.0.0 sentry-sdk-2.13.0 setproctitle-1.3.3 smmap-5.0.1 transformer_lens-2.4.0 typeguard-2.13.3 wandb-0.17.8 xxhash-3.5.0\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (0.2.34)\n",
            "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping) (2.13.3)\n",
            "Collecting git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
            "  Cloning https://github.com/callummcdougall/CircuitsVis.git to /tmp/pip-req-build-ceje6s0e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/callummcdougall/CircuitsVis.git /tmp/pip-req-build-ceje6s0e\n",
            "  Resolved https://github.com/callummcdougall/CircuitsVis.git to commit 1e6129d08cae7af9242d9ab5d3ed322dd44b4dd3\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata<6.0.0,>=5.1.0 (from circuitsvis==0.0.0)\n",
            "  Downloading importlib_metadata-5.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis==0.0.0) (2.4.0+cu121)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis==0.0.0) (3.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3.0,>=2.0->circuitsvis==0.0.0) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0,>=2.0->circuitsvis==0.0.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<3.0,>=2.0->circuitsvis==0.0.0) (1.3.0)\n",
            "Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
            "Building wheels for collected packages: circuitsvis\n",
            "  Building wheel for circuitsvis (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for circuitsvis: filename=circuitsvis-0.0.0-py3-none-any.whl size=6172334 sha256=59415c32edc93016c6c42f3b4833706a3be43b700e7573be5495cc7c0ec5f306\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2cuf2673/wheels/86/be/ad/78078aba9344d200aad61b63d35cdaecdec160212f039eed74\n",
            "Successfully built circuitsvis\n",
            "Installing collected packages: importlib-metadata, circuitsvis\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.4.0\n",
            "    Uninstalling importlib_metadata-8.4.0:\n",
            "      Successfully uninstalled importlib_metadata-8.4.0\n",
            "Successfully installed circuitsvis-0.0.0 importlib-metadata-5.2.0\n",
            "--2024-09-02 13:33:03--  https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main [following]\n",
            "--2024-09-02 13:33:03--  https://codeload.github.com/callummcdougall/ARENA_3.0/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n",
            "Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [      <=>           ]  81.63M  7.84MB/s    in 10s     \n",
            "\n",
            "2024-09-02 13:33:14 (7.78 MB/s) - ‘main.zip’ saved [85598896]\n",
            "\n",
            "Archive:  /content/main.zip\n",
            "01c987ab63e2340020dcc18f40b2c197fc88bf86\n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/\n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/\n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/dataset.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/first_unique_char_model.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/model.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/training.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/august23_unique_char/training_model.ipynb  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/caesar_cipher_model_easy.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/caesar_cipher_model_hard.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/caesar_cipher_model_medium.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/dataset.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/hitchhikers.txt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/model.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/training.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/january24_caesar_cipher/training_model.ipynb  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/dataset.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/model.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/palindrome_classifier.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/training.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/july23_palindromes/training_model.ipynb  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/cumsum_model.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/dataset.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/model.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/training.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/november23_cumsum/training_model.ipynb  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/dataset.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/model.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/sorted_list_model.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/training.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/october23_sorted_list/training_model.ipynb  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/dataset.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/model.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/sum_model.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/training.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/monthly_algorithmic_problems/september23_sum/training_model.ipynb  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/solutions.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/tests.py  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/solutions.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part2_intro_to_mech_interp/tests.py  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part3_indirect_object_identification/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part3_indirect_object_identification/ioi_circuit_extraction.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part3_indirect_object_identification/ioi_dataset.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part3_indirect_object_identification/solutions.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part3_indirect_object_identification/tests.py  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part4_superposition_and_saes/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part4_superposition_and_saes/solutions.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part4_superposition_and_saes/tests.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part4_superposition_and_saes/utils.py  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/\n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/data/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/data/antonym_pairs.txt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/data/country_capital_pairs.txt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/data/test_fn_vector.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/data/test_fn_vector_1.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/data/test_fn_vector_2.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/data/test_h.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/solutions.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part5_function_vectors_and_model_steering/tests.py  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part6_othellogpt/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part6_othellogpt/solutions.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part6_othellogpt/tests.py  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part7_balanced_bracket_classifier/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part7_balanced_bracket_classifier/brackets_data.json  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part7_balanced_bracket_classifier/brackets_datasets.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part7_balanced_bracket_classifier/brackets_model_state_dict.pt  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part7_balanced_bracket_classifier/solutions.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part7_balanced_bracket_classifier/tests.py  \n",
            "   creating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part8_grokking_and_modular_arithmetic/\n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part8_grokking_and_modular_arithmetic/my_utils.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part8_grokking_and_modular_arithmetic/solutions.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/part8_grokking_and_modular_arithmetic/tests.py  \n",
            "  inflating: ARENA_3.0-main/chapter1_transformer_interp/exercises/plotly_utils.py  \n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import google.colab # type: ignore\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "import os, sys\n",
        "chapter = \"chapter1_transformer_interp\"\n",
        "repo = \"ARENA_3.0\"\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Install packages\n",
        "    %pip install transformer_lens\n",
        "    %pip install einops\n",
        "    %pip install jaxtyping\n",
        "    %pip install git+https://github.com/callummcdougall/CircuitsVis.git#subdirectory=python\n",
        "\n",
        "    # Code to download the necessary files (e.g. solutions, test funcs)\n",
        "    if not os.path.exists(f\"/content/{chapter}\"):\n",
        "        !wget https://github.com/callummcdougall/ARENA_3.0/archive/refs/heads/main.zip\n",
        "        !unzip /content/main.zip 'ARENA_3.0-main/chapter1_transformer_interp/exercises/*'\n",
        "        sys.path.append(f\"/content/{repo}-main/{chapter}/exercises\")\n",
        "        os.remove(\"/content/main.zip\")\n",
        "        os.rename(f\"{repo}-main/{chapter}\", chapter)\n",
        "        os.rmdir(f\"{repo}-main\")\n",
        "        os.chdir(f\"{chapter}/exercises\")\n",
        "else:\n",
        "    chapter_dir = r\"./\" if chapter in os.listdir() else os.getcwd().split(chapter)[0]\n",
        "    sys.path.append(chapter_dir + f\"{chapter}/exercises\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfWhhdEBm4Ry",
        "outputId": "c134949f-d4b9-4f2a-84fc-a9ac711fc748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422,
          "referenced_widgets": [
            "0015946918f945d9af146b54051acd94",
            "ee1eff99922f457e8a526d773364dbe8",
            "fe9503f78dd348a3ab2cbb78d19c1dd8",
            "cb551ee879a64bfca7fd5a5eaee9f11c",
            "ed26d38dd6e34c0caaddd489aa536059",
            "075a61310c004b92b4bc47e70b9662cf",
            "2c8ccf42eafa49928164bce44f7a29a5",
            "5cb9a1cffb654cf79f39f3461d464092",
            "630a94807c3a4275a97e32e4db240d9b",
            "4e0eed38fd0a4c6f959d6690b10791e0",
            "876adc8e220d47dda83a0077675dfa31",
            "950813e2a1984a0082977286c7c7022b",
            "54e16222c1f949db85ee609f3d120d0e",
            "20bf8db8e6374db399d59705252d5408",
            "ad8b1cf5c9014c6a9d800acec123294b",
            "9fadb4b96e404eb49d6f5fdd844e39ea",
            "278b03504c6c451c934b47e7635cf0bd",
            "77eddc25f01c4639a1a1ac178554fbab",
            "86a222009ddf4e4a9192a7a6ca1a1e91",
            "3c24c09556174b94a47704886315dd3e",
            "de3e465282f44ce6911dd96919452dbd",
            "d9205faec51e4b57bc3978da18503d08",
            "a62aa7649d2748d2b41df6e4fb6d2e91",
            "222b8ec93e894e22957900e2787a3e2e",
            "1bf8dfa8582a40f3ad751caddf170bae",
            "f87e918953e04ddd9bb431782ed4e253",
            "b5e75fabaee142b9ab1639fcfb5ffe2c",
            "cdec3bea0df942a99fef2f04c9d0f0b0",
            "41adb3370eff408eb6c6b199e2bdd550",
            "76362cdfd0534825a28473fd9b6f4693",
            "4e21bc65eada4bf2aff27119aa117f09",
            "34834eff60784feeb52edec0ebd6738c",
            "e72541af8cac46e3b494a1c849923cde",
            "553e9f39e15340bc836fa51befa7ce11",
            "e565c1ec5eb8448496ba4a5dd8996048",
            "ae1b6d049ef54bfb81e24e05ee0b3641",
            "f6b30fb26e254831b40527e4c72b875f",
            "78a175dca13b416c90cc4edd42756260",
            "1694aaddf86f4385ac792548ad98d584",
            "480a21cd285e4b39af2cbb354bba3bf6",
            "188b50214aea42e3a31036b65667ef06",
            "45941b84bcf6418da9ec01c6d4cf07ee",
            "aacc411046b348e5ab2770bfb94a0eb4",
            "0edf547e29844a00b63c6b1ef90f7fcc",
            "f0cf94d75fd247d6802e7d13dc1ca7bc",
            "d37e4bc33edb47fb8a7248855b27596e",
            "34ac0d9e887941ac8f084f875b7fd442",
            "eb39057fc005401cb65b094185763b60",
            "af950be1ba7945f0a00da6f65687ba15",
            "3075afe58c824d8ab9ee46b67c6e8f84",
            "ed7bb1f544784007b8638ba3455fdd1d",
            "3947d6d4147c417599ddc686439671bc",
            "b34bbc55b9314902ba71966cedc7f944",
            "64d6ae72a52d47dd9bdf9011fe31cab7",
            "9c7e8139bd464f9a913a0d9e5e790799",
            "de831afb681746e59e007e72d694025d",
            "20e8e3556294493db0eeed85342eba3f",
            "c232be08bc624b4bb74a84ac6a9ae616",
            "04e22bec6aed478281cc3c2e8887222b",
            "9fc56e7238e54dd690d8c2359d83ee13",
            "a0a886a4acf444ceaca08dca6d63e503",
            "ace0d8edc2c44b74b6e0982be3f13e70",
            "29012f2aa71444dfa6bce280f0a1619a",
            "170866a0785a4f5a805f3a5478947d2a",
            "4c87c004d35441459811f42545a1ee65",
            "4165bad1fa324a2998d8ea1cdaba5112",
            "cef61e4095994d5eadaa12a0bcd1cc04",
            "7d9c3007e35446c19f8ddaadfca01dae",
            "736eabd2ba224a11a97a497db93d695e",
            "cb3fd81af37148b6b14625bf055b51b3",
            "5ce511c7aba8434b94b1eb5df961e37b",
            "1169ab7623e34855bb8316fe87d1a086",
            "64c02213a26546a4ace65f53c3e6e6b4",
            "71f644378fdb4bad94e0ccde33df06d7",
            "f7c301aa2f084c1794349d0aa1cec480",
            "6b4a931186f64274bd84c8bb2a3d63cb",
            "edab8ff22ad547098ad33cb04d69b72d"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/imports.py:282: UserWarning: `ACCELERATE_DISABLE_RICH` is deprecated and will be removed in v0.22.0 and deactivated by default. Please use `ACCELERATE_ENABLE_RICH` if you wish to use `rich`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0015946918f945d9af146b54051acd94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "950813e2a1984a0082977286c7c7022b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a62aa7649d2748d2b41df6e4fb6d2e91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "553e9f39e15340bc836fa51befa7ce11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0cf94d75fd247d6802e7d13dc1ca7bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de831afb681746e59e007e72d694025d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cef61e4095994d5eadaa12a0bcd1cc04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "import os; os.environ['ACCELERATE_DISABLE_RICH'] = \"1\"\n",
        "import sys\n",
        "import einops\n",
        "from dataclasses import dataclass\n",
        "from transformer_lens import HookedTransformer\n",
        "from transformer_lens.utils import gelu_new, tokenize_and_concatenate\n",
        "import torch as t\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import math\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import Tuple, List, Optional, Dict, Callable\n",
        "from jaxtyping import Float, Int\n",
        "from transformers.models.gpt2.tokenization_gpt2_fast import GPT2TokenizerFast\n",
        "from collections import defaultdict\n",
        "from rich.table import Table\n",
        "from rich import print as rprint\n",
        "import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "import webbrowser\n",
        "\n",
        "# Make sure exercises are in the path\n",
        "exercises_dir = Path(f\"{os.getcwd().split(chapter)[0]}/{chapter}/exercises\").resolve()\n",
        "section_dir = (exercises_dir / \"part1_transformer_from_scratch\").resolve()\n",
        "if str(exercises_dir) not in sys.path: sys.path.append(str(exercises_dir))\n",
        "\n",
        "from plotly_utils import imshow\n",
        "import part1_transformer_from_scratch.solutions as solutions\n",
        "import part1_transformer_from_scratch.tests as tests\n",
        "\n",
        "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
        "\n",
        "MAIN = __name__ == '__main__'\n",
        "\n",
        "reference_gpt2 = HookedTransformer.from_pretrained(\"gpt2-small\", fold_ln=False, center_unembed=False, center_writing_weights=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1x_mWI6m4Rz"
      },
      "source": [
        "# 1️⃣ Understanding Inputs & Outputs of a Transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_FUMfnwA6Oq"
      },
      "source": [
        "> ### Learning Objectives\n",
        ">\n",
        "> * Understand what a transformer is used for\n",
        "> * Understand causal attention, and what a transformer's output represents\n",
        "> * Learn what tokenization is, and how models do it\n",
        "> * Understand what logits are, and how to use them to derive a probability distribution over the vocabulary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d--zV4Crm4Rz"
      },
      "source": [
        "## What is the point of a transformer?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaMw4jYgm4Rz"
      },
      "source": [
        "**Transformers exist to model text!**\n",
        "\n",
        "We're going to focus GPT-2 style transformers. Key feature: They generate text! You feed in language, and the model generates a probability distribution over tokens. And you can repeatedly sample from this to generate text!\n",
        "\n",
        "(To explain this in more detail - you feed in a sequence of length $N$, then sample from the probability distribution over the $N+1$-th word, use this to construct a new sequence of length $N+1$, then feed this new sequence into the model to get a probability distribution over the $N+2$-th word, and so on.)\n",
        "\n",
        "### How is the model trained?\n",
        "\n",
        "You give it a bunch of text, and train it to predict the next token.\n",
        "\n",
        "Importantly, if you give a model 100 tokens in a sequence, it predicts the next token for *each* prefix, i.e. it produces 100 logit vectors (= probability distributions) over the set of all words in our vocabulary, with the `i`-th logit vector representing the probability distribution over the token *following* the `i`-th token in the sequence.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - logits</summary>\n",
        "\n",
        "If you haven't encountered the term \"logits\" before, here's a quick refresher.\n",
        "\n",
        "Given an arbitrary vector $x$, we can turn it into a probability distribution via the **softmax** function: $x_i \\to \\frac{e^{x_i}}{\\sum e^{x_j}}$. The exponential makes everything positive; the normalization makes it add to one.\n",
        "\n",
        "The model's output is the vector $x$ (one for each prediction it makes). We call this vector a logit because it represents a probability distribution, and it is related to the actual probabilities via the softmax function.\n",
        "</details>\n",
        "\n",
        "How do we stop the transformer by \"cheating\" by just looking at the tokens it's trying to predict? Answer - we make the transformer have *causal attention* (as opposed to *bidirectional attention*). Causal attention only allows information to move forwards in the sequence, never backwards. The prediction of what comes after token 50 is only a function of the first 50 tokens, *not* of token 51. We say the transformer is **autoregressive**, because it only predicts future words based on past data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHzR45fBfHNq"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/transformer-overview-new.png\" width=\"900\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ZVvPhDm4R0"
      },
      "source": [
        "## Tokens - Transformer Inputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkBYr2qym4R0"
      },
      "source": [
        "Our tranformer's input is natural language (i.e. a sequence of characters, strings, etc). But ML models generally take vectors as input, not language. How do we convert language to vectors?\n",
        "\n",
        "We can factor this into 2 questions:\n",
        "\n",
        "1. How do we split up language into small sub-units?\n",
        "2. How do we convert these sub-units into vectors?\n",
        "\n",
        "Let's start with the second of these questions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRP795JofHNq"
      },
      "source": [
        "### Converting sub-units to vectors\n",
        "\n",
        "We basically make a massive lookup table, which is called an **embedding**. It has one vector for each possible sub-unit of language we might get (we call this set of all sub-units our **vocabulary**). We label every element in our vocabulary with an integer (this labelling never changes), and we use this integer to index into the embedding.\n",
        "\n",
        "A key intuition is that one-hot encodings let you think about each integer independently. We don't bake in any relation between words when we perform our embedding, because every word has a completely separate embedding vector.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - one-hot encodings</summary>\n",
        "\n",
        "We sometimes think about **one-hot encodings** of words. These are vectors with zeros everywhere, except for a single one in the position corresponding to the word's index in the vocabulary. This means that indexing into the embedding is equivalent to multiplying the **embedding matrix** by the one-hot encoding (where the embedding matrix is the matrix we get by stacking all the embedding vectors on top of each other).\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "W_E &= \\begin{bmatrix}\n",
        "\\leftarrow v_0 \\rightarrow \\\\\n",
        "\\leftarrow v_1 \\rightarrow \\\\\n",
        "\\vdots \\\\\n",
        "\\leftarrow v_{d_{vocab}-1} \\rightarrow \\\\\n",
        "\\end{bmatrix} \\quad \\text{is the embedding matrix (size }d_{vocab} \\times d_{embed}\\text{),} \\\\\n",
        "\\\\\n",
        "t_i &= (0, \\dots, 0, 1, 0, \\dots, 0) \\quad \\text{is the one-hot encoding for the }i\\text{th word (length }d_{vocab}\\text{)} \\\\\n",
        "\\\\\n",
        "v_i &= t_i W_E \\quad \\text{is the embedding vector for the }i\\text{th word (length }d_{embed}\\text{).} \\\\\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "</details>\n",
        "\n",
        "Now, let's answer the first question - how do we split language into sub-units?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7t_YsDxm4R0"
      },
      "source": [
        "### Splitting language into sub-units\n",
        "\n",
        "We need to define a standard way of splitting up language into a series of substrings, where each substring is a member of our **vocabulary** set.\n",
        "\n",
        "Could we use a dictionary, and have our vocabulary be the set of all words in the dictionary? No, because this couldn't handle arbitrary text (e.g. URLs, punctuation, etc). We need a more general way of splitting up language.\n",
        "\n",
        "Could we just use the 256 ASCII characters? This fixes the previous problem, but it loses structure of language - some sequences of characters are more meaningful than others. For example, \"language\" is a lot more meaningful than \"hjksdfiu\". We want \"language\" to be a single token, but not \"hjksdfiu\" - this is a more efficient use of our vocab.\n",
        "\n",
        "What actually happens? The most common strategy is called **Byte-Pair encodings**.\n",
        "\n",
        "We begin with the 256 ASCII characters as our tokens, and then find the most common pair of tokens, and merge that into a new token. Note that we do have a space character as one of our 256 tokens, and merges using space are very common. For instance, here are the five first merges for the tokenizer used by GPT-2 (you'll be able to verify this below).\n",
        "\n",
        "```\n",
        "\" t\"\n",
        "\" a\"\n",
        "\"he\"\n",
        "\"in\"\n",
        "\"re\"\n",
        "```\n",
        "\n",
        "Note - you might see the character `Ġ` in front of some tokens. This is a special token that indicates that the token begins with a space. Tokens with a leading space vs not are different.\n",
        "\n",
        "You can run the code below to see some more of GPT-2's tokenizer's vocabulary:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHq2U0hKnXMm",
        "outputId": "10410513-1f32-40e0-d355-b9f97ae5f99c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('!', 0), ('\"', 1), ('#', 2), ('$', 3), ('%', 4), ('&', 5), (\"'\", 6), ('(', 7), (')', 8), ('*', 9), ('+', 10), (',', 11), ('-', 12), ('.', 13), ('/', 14), ('0', 15), ('1', 16), ('2', 17), ('3', 18), ('4', 19)]\n",
            "\n",
            "[('ľ', 250), ('Ŀ', 251), ('ŀ', 252), ('Ł', 253), ('ł', 254), ('Ń', 255), ('Ġt', 256), ('Ġa', 257), ('he', 258), ('in', 259), ('re', 260), ('on', 261), ('Ġthe', 262), ('er', 263), ('Ġs', 264), ('at', 265), ('Ġw', 266), ('Ġo', 267), ('en', 268), ('Ġc', 269)]\n",
            "\n",
            "[('Ġprodu', 990), ('Ġstill', 991), ('led', 992), ('ah', 993), ('Ġhere', 994), ('Ġworld', 995), ('Ġthough', 996), ('Ġnum', 997), ('arch', 998), ('imes', 999), ('ale', 1000), ('ĠSe', 1001), ('ĠIf', 1002), ('//', 1003), ('ĠLe', 1004), ('Ġret', 1005), ('Ġref', 1006), ('Ġtrans', 1007), ('ner', 1008), ('ution', 1009)]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sorted_vocab = sorted(list(reference_gpt2.tokenizer.vocab.items()), key=lambda n: n[1])\n",
        "print(sorted_vocab[:20])\n",
        "print()\n",
        "print(sorted_vocab[250:270])\n",
        "print()\n",
        "print(sorted_vocab[990:1010])\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddGjdpeinaI8"
      },
      "source": [
        "As you get to the end of the vocabulary, you'll be producing some pretty weird-looking esoteric tokens (because you'll already have exhausted all of the short frequently-occurring ones):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl40Jlw0m4R0",
        "outputId": "31a501cf-999b-4146-f9a5-9cc510af0251",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Revolution', 50237), ('Ġsnipers', 50238), ('Ġreverted', 50239), ('Ġconglomerate', 50240), ('Terry', 50241), ('794', 50242), ('Ġharsher', 50243), ('Ġdesolate', 50244), ('ĠHitman', 50245), ('Commission', 50246), ('Ġ(/', 50247), ('âĢ¦.\"', 50248), ('Compar', 50249), ('Ġamplification', 50250), ('ominated', 50251), ('Ġregress', 50252), ('ĠCollider', 50253), ('Ġinformants', 50254), ('Ġgazed', 50255), ('<|endoftext|>', 50256)]\n"
          ]
        }
      ],
      "source": [
        "print(sorted_vocab[-20:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<details>\n",
        "<summary>Fun (totally optional) exercise - can you guess what the first-formed 3/4/5/6/7-letter encodings in GPT-2's vocabulary are?</summary>\n",
        "Run this code to find out:\n",
        "\n",
        "```python\n",
        "lengths = dict.fromkeys(range(3, 8), \"\")\n",
        "for tok, idx in sorted_vocab:\n",
        "    if not lengths.get(len(tok), True):\n",
        "        lengths[len(tok)] = tok\n",
        "\n",
        "for length, tok in lengths.items():\n",
        "    print(f\"{length}: {tok}\")\n",
        "```\n",
        "</details>\n"
      ],
      "metadata": {
        "id": "QcOKIhU-1IOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = dict.fromkeys(range(3, 8), \"\")\n",
        "for tok, idx in sorted_vocab:\n",
        "    if not lengths.get(len(tok), True):\n",
        "        lengths[len(tok)] = tok\n",
        "\n",
        "for length, tok in lengths.items():\n",
        "    print(f\"{length}: {tok}\")"
      ],
      "metadata": {
        "id": "I1jCYL0lBVrK",
        "outputId": "a6264939-8ffd-4b64-ea5a-d9162506c764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3: ing\n",
            "4: Ġthe\n",
            "5: Ġthat\n",
            "6: Ġtheir\n",
            "7: Ġpeople\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5OKWOqHnmBg"
      },
      "source": [
        "Transformers in the `transformer_lens` library have a `to_tokens` method that converts text to numbers. It also prepends them with a special token called BOS (beginning of sequence) to indicate the start of a sequence. You can disable this with the `prepend_bos=False` argument.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - BOS token</summary>\n",
        "\n",
        "The beginning of sequence (BOS) token is a special token used to mark the beginning of the sequence. Confusingly, in GPT-2, the End of Sequence (EOS), Beginning of Sequence (BOS) and Padding (PAD) tokens are all the same, `<|endoftext|>` with index `50256`.\n",
        "\n",
        "Why is this token added? Some basic intuitions are:\n",
        "\n",
        "* It provides context that this is the start of a sequence, which can help the model generate more appropriate text.\n",
        "* It can act as a \"rest position\" for attention heads (more on this later, when we discuss attention).\n",
        "\n",
        "TransformerLens adds this token automatically (including in forward passes of transformer models, e.g. it's implicitly added when you call `model(\"Hello World\")`). You can disable this behaviour by setting the flag `prepend_bos=False` in `to_tokens`, `to_str_tokens`, `model.forward` and any other function that converts strings to multi-token tensors.\n",
        "\n",
        "**Key Point: *If you get weird off-by-one errors, check whether there's an unexpected `prepend_bos`!***\n",
        "\n",
        "Why are the BOS, EOS and PAD tokens the same? This is because GPT-2 is an autoregressive model, and uses these kinds of tokens in a slightly different way to other transformer families (e.g. BERT). For instance, GPT has no need to distinguish between BOS and EOS tokens, because it only processes text from left to right.\n",
        "\n",
        "</details>\n",
        "\n",
        "### Some tokenization annoyances\n",
        "\n",
        "There are a few funky and frustrating things about tokenization, which causes it to behave differently than you might expect. For instance:\n",
        "\n",
        "#### Whether a word begins with a capital or space matters!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vlZ-pRAnoEw",
        "outputId": "d6549fa2-41f5-4b0d-9fe4-8170c9056116",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', 'R', 'alph']\n",
            "['<|endoftext|>', ' Ralph']\n",
            "['<|endoftext|>', ' r', 'alph']\n",
            "['<|endoftext|>', 'ral', 'ph']\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_str_tokens(\"Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" Ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\" ralph\"))\n",
        "print(reference_gpt2.to_str_tokens(\"ralph\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joPO920PntIw"
      },
      "source": [
        "#### Arithmetic is a mess.\n",
        "\n",
        "Length is inconsistent, common numbers bundle together.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzbf4t-Zm4R1",
        "outputId": "3ffd45dd-190b-4dbc-9efa-027655c48334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', '568', '73', '+', '318', '46', '23', '=', '123', '45', '67', '89', '-', '1', '000000', '000']\n"
          ]
        }
      ],
      "source": [
        "print(reference_gpt2.to_str_tokens(\"56873+3184623=123456789-1000000000\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgtPkQE-m4R2"
      },
      "source": [
        "> ### Key Takeaways\n",
        ">\n",
        "> * We learn a dictionary of vocab of tokens (sub-words).\n",
        "> * We (approx) losslessly convert language to integers via tokenizing it.\n",
        "> * We convert integers to vectors via a lookup table.\n",
        "> * Note: input to the transformer is a sequence of *tokens* (ie integers), not vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCSs3uXgn9Kb"
      },
      "source": [
        "## Text generation\n",
        "\n",
        "Now that we understand the basic ideas here, let's go through the entire process of text generation, from our original string to a new token which we can append to our string and plug back into the model.\n",
        "\n",
        "#### **Step 1:** Convert text to tokens\n",
        "\n",
        "The sequence gets tokenized, so it has shape `[batch, seq_len]`. Here, the batch dimension is just one (because we only have one sequence).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mommexyJm4R3",
        "outputId": "68e8e09b-f238-4d7d-9570-b23ac3dea1a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256,    40,   716,   281,  4998,  1960,   382, 19741,    11,   875,\n",
            "         12342,    12,  8807,    11,   402, 11571,    12,    17,  3918, 47385,\n",
            "            13,  1881,  1110,   314,   481,  7074,  1692,  1241,  4430,   290,\n",
            "          1011,   625,   262,   995,     0]], device='cuda:0')\n",
            "torch.Size([1, 35])\n",
            "['<|endoftext|>', 'I', ' am', ' an', ' amazing', ' aut', 'ore', 'gressive', ',', ' dec', 'oder', '-', 'only', ',', ' G', 'PT', '-', '2', ' style', ' transformer', '.', ' One', ' day', ' I', ' will', ' exceed', ' human', ' level', ' intelligence', ' and', ' take', ' over', ' the', ' world', '!']\n"
          ]
        }
      ],
      "source": [
        "reference_text = \"I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!\"\n",
        "tokens = reference_gpt2.to_tokens(reference_text).to(device)\n",
        "print(tokens)\n",
        "print(tokens.shape)\n",
        "print(reference_gpt2.to_str_tokens(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovci8XHNm4R3"
      },
      "source": [
        "#### **Step 2:** Map tokens to logits\n",
        "\n",
        "\n",
        "From our input of shape `[batch, seq_len]`, we get output of shape `[batch, seq_len, vocab_size]`. The `[i, j, :]`-th element of our output is a vector of logits representing our prediction for the `j+1`-th token in the `i`-th sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iK_hEUzm4R3",
        "outputId": "f9816062-1012-4580-abbb-809af6922c73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39kXnrmrgeIw"
      },
      "source": [
        "(`run_with_cache` tells the model to cache all intermediate activations. This isn't important right now; we'll look at it in more detail later.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDv_ftwFm4R4"
      },
      "source": [
        "#### **Step 3:** Convert the logits to a distribution with a softmax\n",
        "\n",
        "This doesn't change the shape, it is still `[batch, seq_len, vocab_size]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csYLLcvcm4R4",
        "outputId": "39c49f57-7c22-4fa1-b2e8-b3d6a958e6fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 35, 50257])\n"
          ]
        }
      ],
      "source": [
        "probs = logits.softmax(dim=-1)\n",
        "print(probs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkOqYy8qm4R4"
      },
      "source": [
        "#### **Bonus step:** What is the most likely next token at each position?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tKcEGLXm4R4",
        "outputId": "451c42c5-adeb-4c96-9cc4-5641bcb346d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<|endoftext|>', '\\n'), ('I', \"'m\"), (' am', ' a'), (' an', ' avid'), (' amazing', ' person'), (' aut', 'od'), ('ore', 'sp'), ('gressive', '.'), (',', ' and'), (' dec', 'ently'), ('oder', ','), ('-', 'driven'), ('only', ' programmer'), (',', ' and'), (' G', 'IM'), ('PT', '-'), ('-', 'only'), ('2', '.'), (' style', ','), (' transformer', '.'), ('.', ' I'), (' One', ' of'), (' day', ' I'), (' I', ' will'), (' will', ' be'), (' exceed', ' my'), (' human', 'ly'), (' level', ' of'), (' intelligence', ' and'), (' and', ' I'), (' take', ' over'), (' over', ' the'), (' the', ' world'), (' world', '.'), ('!', ' I')]\n"
          ]
        }
      ],
      "source": [
        "most_likely_next_tokens = reference_gpt2.tokenizer.batch_decode(logits.argmax(dim=-1)[0])\n",
        "\n",
        "print(list(zip(reference_gpt2.to_str_tokens(tokens), most_likely_next_tokens)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yESVZd2igyPd"
      },
      "source": [
        "We can see that, in a few cases (particularly near the end of the sequence), the model accurately predicts the next token in the sequence. We might guess that `\"take over the world\"` is a common phrase that the model has seen in training, which is why the model can predict it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrZCnki1m4R4"
      },
      "source": [
        "#### **Step 4:** Map distribution to a token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp9PB99Mm4R4",
        "outputId": "6969f808-fa45-458e-b68d-02794ba1a64f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "' I'\n"
          ]
        }
      ],
      "source": [
        "next_token = logits[0, -1].argmax(dim=-1)\n",
        "next_char = reference_gpt2.to_string(next_token)\n",
        "print(repr(next_char))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4uXGn1mhSnf"
      },
      "source": [
        "Note that we're indexing `logits[0, -1]`. This is because logits have shape `[1, sequence_length, vocab_size]`, so this indexing returns the vector of length `vocab_size` representing the model's prediction for what token follows the **last** token in the input sequence.\n",
        "\n",
        "In this case, we can see that the model predicts the token `' I'`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XmSN1YFm4R5"
      },
      "source": [
        "### **Step 5:** Add this to the end of the input, re-run\n",
        "\n",
        "There are more efficient ways to do this (e.g. where we cache some of the values each time we run our input, so we don't have to do as much calculation each time we generate a new value), but this doesn't matter conceptually right now.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpgN-auXm4R6",
        "outputId": "cb8b4c46-2793-47a1-8e71-7c2e2a742a10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence so far: '<|endoftext|>I am an amazing autoregressive, decoder-only, GPT-2 style transformer. One day I will exceed human level intelligence and take over the world!'\n",
            "36th char = ' I'\n",
            "37th char = ' am'\n",
            "38th char = ' a'\n",
            "39th char = ' very'\n",
            "40th char = ' talented'\n",
            "41th char = ' and'\n",
            "42th char = ' talented'\n",
            "43th char = ' person'\n",
            "44th char = ','\n",
            "45th char = ' and'\n"
          ]
        }
      ],
      "source": [
        "print(f\"Sequence so far: {reference_gpt2.to_string(tokens)[0]!r}\")\n",
        "\n",
        "for i in range(10):\n",
        "    print(f\"{tokens.shape[-1]+1}th char = {next_char!r}\")\n",
        "    # Define new input sequence, by appending the previously generated token\n",
        "    tokens = t.cat([tokens, next_token[None, None]], dim=-1)\n",
        "    # Pass our new sequence through the model, to get new output\n",
        "    logits = reference_gpt2(tokens)\n",
        "    # Get the predicted token at the end of our sequence\n",
        "    next_token = logits[0, -1].argmax(dim=-1)\n",
        "    # Decode and print the result\n",
        "    next_char = reference_gpt2.to_string(next_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVd8J0QLm4R6"
      },
      "source": [
        "## Key takeaways\n",
        "\n",
        "* Transformer takes in language, predicts next token (for *each* token in a causal way)\n",
        "* We convert language to a sequence of integers with a tokenizer.\n",
        "* We convert integers to vectors with a lookup table.\n",
        "* Output is a vector of logits (one for each input token), we convert to a probability distn with a softmax, and can then convert this to a token (eg taking the largest logit, or sampling).\n",
        "* We append this to the input + run again to generate more text (Jargon: *autoregressive*)\n",
        "* Meta level point: Transformers are sequence operation models, they take in a sequence, do processing in parallel at each position, and use attention to move information between positions!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaSOTaLdm4R6"
      },
      "source": [
        "# 2️⃣ Clean Transformer Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3YLmU9boWEv"
      },
      "source": [
        "> ##### Learning objectives\n",
        ">\n",
        "> * Understand that a transformer is composed of attention heads and MLPs, with each one performing operations on the residual stream\n",
        "> * Understand that the attention heads in a single layer operate independently, and that they have the role of calculating attention patterns (which determine where information is moved to & from in the residual stream)\n",
        "> * Learn about & implement the following transformer modules:\n",
        ">     * LayerNorm (transforming the input to have zero mean and unit variance)\n",
        ">     * Positional embedding (a lookup table from position indices to residual stream vectors)\n",
        ">     * Attention (the method of computing attention patterns for residual stream vectors)\n",
        ">     * MLP (the collection of linear and nonlinear transformations which operate on each residual stream vector in the same way)\n",
        ">     * Embedding (a lookup table from tokens to residual stream vectors)\n",
        ">     * Unembedding (a matrix for converting residual stream vectors into a distribution over tokens)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2LTUZkXm4R7"
      },
      "source": [
        "## High-Level architecture\n",
        "\n",
        "Go watch Neel's [Transformer Circuits walkthrough](https://www.youtube.com/watch?v=KV5gbOmHbjU) if you want more intuitions!\n",
        "\n",
        "(Diagram is bottom to top.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XtGO8lYm4R6"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/transformer-new.png\" width=\"850\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "347we6hfo6oP"
      },
      "source": [
        "### Tokenization & Embedding\n",
        "\n",
        "The input tokens $t$ are integers. We get them from taking a sequence, and tokenizing it (like we saw in the previous section).\n",
        "\n",
        "The token embedding is a lookup table mapping tokens to vectors, which is implemented as a matrix $W_E$. The matrix consists of a stack of token embedding vectors (one for each token).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SVWlk-qo9Bg"
      },
      "source": [
        "### Residual stream\n",
        "\n",
        "The residual stream is the sum of all previous outputs of layers of the model, is the input to each new layer. It has shape `[batch, seq_len, d_model]` (where `d_model` is the length of a single embedding vector).\n",
        "\n",
        "The initial value of the residual stream is denoted $x_0$ in the diagram, and $x_i$ are later values of the residual stream (after more attention and MLP layers have been applied to the residual stream).\n",
        "\n",
        "The residual stream is *really* fundamental. It's the central object of the transformer. It's how model remembers things, moves information between layers for composition, and it's the medium used to store the information that attention moves between positions.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - <b>logit lens</b></summary>\n",
        "\n",
        "A key idea of transformers is the [residual stream as output accumulation](https://www.lesswrong.com/posts/X26ksz4p3wSyycKNB/gears-level-mental-models-of-transformer-interpretability#Residual_Stream_as_Output_Accumulation:~:text=The%20Models-,Residual%20Stream%20as%20Output%20Accumulation,-The%20residual%20stream). As we move through the layers of the model, shifting information around and processing it, the values in the residual stream represent the accumulation of all the inferences made by the transformer up to that point.\n",
        "\n",
        "This is neatly illustrated by the **logit lens**. Rather than getting predictions from the residual stream at the very end of the model, we can take the value of the residual stream midway through the model and convert it to a distribution over tokens. When we do this, we find surprisingly coherent predictions, especially in the last few layers before the end.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTQ0R_FIo_Er"
      },
      "source": [
        "### Transformer blocks\n",
        "\n",
        "Then we have a series of `n_layers` **transformer blocks** (also sometimes called **residual blocks**).\n",
        "\n",
        "Note - a block contains an attention layer *and* an MLP layer, but we say a transformer has $k$ layers if it has $k$ blocks (i.e. $2k$ total layers).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN8L6lEgpBNB"
      },
      "source": [
        "#### Attention\n",
        "\n",
        "First we have attention. This moves information from prior positions in the sequence to the current token.\n",
        "\n",
        "We do this for *every* token in parallel using the same parameters. The only difference is that we look backwards only (to avoid \"cheating\"). This means later tokens have more of the sequence that they can look at.\n",
        "\n",
        "Attention layers are the only bit of a transformer that moves information between positions (i.e. between vectors at different sequence positions in the residual stream).\n",
        "\n",
        "Attention layers are made up of `n_heads` heads - each with their own parameters, own attention pattern, and own information how to copy things from source to destination. The heads act independently and additively, we just add their outputs together, and back to the stream.\n",
        "\n",
        "Each head does the following:\n",
        "* Produces an **attention pattern** for each destination token, a probability distribution of prior source tokens (including the current one) weighting how much information to copy.\n",
        "* Moves information (via a linear map) in the same way from each source token to each destination token.\n",
        "\n",
        "A few key points:\n",
        "\n",
        "* What information we copy depends on the source token's *residual stream*, but this doesn't mean it only depends on the value of that token, because the residual stream can store more information than just the token identity (the purpose of the attention heads is to move information between vectors at different positions in the residual stream!)\n",
        "* We can think of each attention head as consisting of two different **circuits**:\n",
        "    * One circuit determines **where to move information to and from** (this is a function of the residual stream for the source and destination tokens)\n",
        "    * The other circuit determines **what information to move** (this is a function of only the source token's residual stream)\n",
        "    * For reasons which will become clear later, we refer to the first circuit as the **QK circuit**, and the second circuit as the **OV circuit**\n",
        "\n",
        "<details>\n",
        "<summary>Key intuition - attention as generalized convolution</summary>\n",
        "\n",
        "We can think of attention as a kind of generalized convolution. Standard convolution layers work by imposing a \"prior of locality\", i.e. the assumption that pixels which are close together are more likely to share information. Although language has some locality (two words next to each other are more likely to share information than two words 100 tokens apart), the picture is a lot more nuanced, because which tokens are relevant to which others depends on the context of the sentence. For instance, in the sentence `\"When Mary and John went to the store, John gave a drink to Mary\"`, the names in this sentence are the most important tokens for predicting that the final token will be `\"Mary\"`, and this is because of the particular context of this sentence rather than the tokens' position.\n",
        "\n",
        "Attention layers are effectively our way of saying to the transformer, \"don't impose a prior of locality, but instead develop your own algorithm to figure out which tokens are important to which other tokens in any given sequence.\"\n",
        "</details>\n",
        "\n",
        "Below is a schematic diagram of the attention layers. Don't worry if you don't follow this right now, we'll go into more detail during implementation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oU4oR-_omed"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/transformer-attn-new.png\" width=\"1100\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGmfTAbCm4R7"
      },
      "source": [
        "### MLP\n",
        "\n",
        "The MLP layers are just a standard neural network, with a singular hidden layer and a nonlinear activation function. The exact activation isn't conceptually important ([GELU](https://paperswithcode.com/method/gelu) seems to perform best).\n",
        "\n",
        "Our hidden dimension is normally `d_mlp = 4 * d_model`. Exactly why the ratios are what they are isn't super important (people basically cargo-cult what GPT did back in the day!).\n",
        "\n",
        "Importantly, **the MLP operates on positions in the residual stream independently, and in exactly the same way**. It doesn't move information between positions.\n",
        "\n",
        "Intuition - once attention has moved relevant information to a single position in the residual stream, MLPs can actually do computation, reasoning, lookup information, etc. *What the hell is going on inside MLPs* is a pretty big open problem in transformer mechanistic interpretability - see the [Toy Model of Superposition Paper](https://transformer-circuits.pub/2022/toy_model/index.html) for more on why this is hard.\n",
        "\n",
        "<details>\n",
        "<summary>Key intuition - MLPs as key-value pairs</summary>\n",
        "\n",
        "We can write the MLP's output as $f(x^T W^{in})W^{out}$, where $W^{in}$ and $W^{out}$ are the different weights of the MLP (ignoring biases), $f$ is the activation function, and $x$ is a vector in the residual stream. This can be rewritten as:\n",
        "\n",
        "$$\n",
        "f(x^T W^{in}) W^{out} = \\sum_{i=1}^{d_{mlp}} f(x^T W^{in}_{[:, i]}) W^{out}_{[i, :]}\n",
        "$$\n",
        "\n",
        "We can view the vectors $W^{in}_{[:, i]}$ as the **input directions**, and $W^{out}_{[i, :]}$ as the **output directions**. We say the input directions are **activated** by certain textual features, and when they are activated, vectors are written in the corresponding output direction. This is very similar to the concept of keys and values in attention layers, which is why these vectors are also sometimes called keys and values (e.g. see the paper [Transformer Feed-Forward Layers Are Key-Value Memories](https://arxiv.org/pdf/2012.14913.pdf)).\n",
        "\n",
        "Terminology note - sometimes we refer to each of these $d_{mlp}$ input-output pairs as **neurons**.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/mlp-neurons-2.png\" width=\"900\">\n",
        "\n",
        "---\n",
        "\n",
        "Here's a step-by-step breakdown of the linear algebra, if it was too fast above. We have:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "x^T W^{in} &= x^T [W^{in}_{[:, 1]}\\,, ...\\;, W^{in}_{[:, n]}] \\\\\n",
        "&= (x^T W^{in}_{[:, 1]}\\,, \\; ...\\;, \\; x^T W^{in}_{[:, n]})\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $W^{in}_{[:, i]}$ are the columns of $W^{in}$. In other words, these values (the pre-GELU activations) are projections of $x$ along the input directions of the neurons.\n",
        "\n",
        "If we add our activation function and the second matrix, then we get:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "f(x^T W^{in})W^{out} &= (f(x^T W^{in}_{[:, 1]})\\,, \\; ...\\;,\\; f(x^T W^{in}_{[:, n]})) \\begin{bmatrix} \\leftarrow W^{out}_{[1, :]} \\rightarrow \\\\ \\vdots \\\\ \\leftarrow W^{out}_{[n, :]} \\rightarrow \\end{bmatrix} \\\\\n",
        "&= f(x^T W^{in}_{[:, 1]}) W^{out}_{[1, :]} + \\;...\\; + f(x^T W^{in}_{[:, n]}) W^{out}_{[n, :]} \\\\\n",
        "&= \\sum_{i=1}^n f(x^T W^{in}_{[:, i]}) W^{out}_{[i, :]}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $W^{out}_{[i, :]}$ are the rows of $W^{out}$. In other words, our output is a linear combination of the rows of $W^{out}$, with the coefficients of that linear combination given by the projections of $x$ along the columns of $W^{in}$.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Key intuition - MLPs as knowledge storage</summary>\n",
        "\n",
        "We can think of MLPs as where knowledge gets stored in our transformer. The attention mechanism is what moves information around between sequence positions, but the MLPs is where this information is processed, and new information is written into the residual stream which is a function of the old information.\n",
        "\n",
        "This is deeply connected to the key-value pairs model, since you can treat key-value pairs as a kind of associative memory system (where the key serves as a unique identifier, and the value holds the related information).\n",
        "\n",
        "Another related intuition (for which there is some evidence) is **MLPs as memory management**. In an idealized case, we might find that the $i$-th neuron satisfies $W^{in}_{[:, i]} \\approx - W^{out}_{[i, :]} \\approx \\vec v$ for some unit vector $\\vec v$, meaning it may be responsible for erasing the positive component of vector $\\vec x$ in the direction $\\vec v$ (exercise - can you show why this is the case?). This can free up space in the residual stream for other components to write to.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxqWjPd2pI2p"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/transformer-mlp-new-2.png\" width=\"650\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvfe6yEtpYMd"
      },
      "source": [
        "### Unembedding\n",
        "\n",
        "Finally, we unembed!\n",
        "\n",
        "This just consists of applying a linear map $W_U$, going from final residual stream to a vector of logits - this is the output.\n",
        "\n",
        "<details>\n",
        "<summary>Aside - tied embeddings</summary>\n",
        "\n",
        "Note - sometimes we use something called a **tied embedding** - this is where we use the same weights for our $W_E$ and $W_U$ matrices. In other words, to get the logit score for a particular token at some sequence position, we just take the vector in the residual stream at that sequence position and take the inner product with the corresponding token embedding vector. This is more training-efficient (because there are fewer parameters in our model), and it might seem pricipled at first. After all, if two words have very similar meanings, shouldn't they have similar embedding vectors because the model will treat them the same, and similar unembedding vectors because they could both be substituted for each other in most output?\n",
        "\n",
        "However, this is actually not very principled, for the following main reason: **the direct path involving the embedding and unembedding should approximate bigram frequencies**.\n",
        "\n",
        "Let's break down this claim. **Bigram frequencies** refers to the frequencies of pairs of words in the english language (e.g. the bigram frequency of \"Barack Obama\" is much higher than the product of the individual frequencies of the words \"Barack\" and \"Obama\"). If our model had no attention heads or MLP layers, then all we have is a linear map from our one-hot encoded token `T` to a probability distribution over the token following `T`. This map is represented by the linear transformation $t \\to t^T W_E W_U$ (where $t$ is our one-hot encoded token vector). Since the output of this transformation can only be a function of the token `T` (and no earlier tokens), the best we can do is have this map approximate the true frequency of bigrams starting with `T`, which appear in the training data. Importantly, **this is not a symmetric map**. We want `T = \"Barack\"` to result in a high probability of the next token being `\"Obama\"`, but not the other way around!\n",
        "\n",
        "Even in multi-layer models, a similar principle applies. There will be more paths through the model than just the \"direct path\" $W_E W_U$, but because of the residual connections there will always exist a direct path, so there will always be some incentive for $W_E W_U$ to approximate bigram frequencies.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5isIxIEpnO6"
      },
      "source": [
        "### Bonus things - less conceptually important but key technical details\n",
        "\n",
        "#### LayerNorm\n",
        "\n",
        "* Simple normalization function applied at the start of each layer (i.e. before each MLP, attention layer, and before the unembedding)\n",
        "* Converts each input vector (independently in parallel for each batch x position residual stream vector) to have mean zero and variance 1.\n",
        "* Then applies an elementwise scaling and translation\n",
        "* Cool maths tangent: The scale & translate is just a linear map. LayerNorm is only applied immediately before another linear map. Linear compose linear = linear, so we can just fold this into a single effective linear layer and ignore it.\n",
        "    * `fold_ln=True` flag in `from_pretrained` does this for you.\n",
        "* LayerNorm is annoying for interpertability - the scale part is not linear, so you can't think about different bits of the input independently. But it's *almost* linear - if you're changing a small part of the input it's linear, but if you're changing enough to alter the norm substantially it's not linear.\n",
        "</details>\n",
        "\n",
        "\n",
        "#### Positional embeddings\n",
        "\n",
        "* **Problem:** Attention operates over all pairs of positions. This means it's symmetric with regards to position - the attention calculation from token 5 to token 1 and token 5 to token 2 are the same by default\n",
        "    * This is dumb because nearby tokens are more relevant.\n",
        "* There's a lot of dumb hacks for this.\n",
        "* We'll focus on **learned, absolute positional embeddings**. This means we learn a lookup table mapping the index of the position of each token to a residual stream vector, and add this to the embed.\n",
        "    * Note that we *add* rather than concatenate. This is because the residual stream is shared memory, and likely under significant superposition (the model compresses more features in there than the model has dimensions)\n",
        "    * We basically never concatenate inside a transformer, unless doing weird shit like generating text efficiently.\n",
        "* This connects to **attention as generalized convolution**\n",
        "    * We argued that language does still have locality, and so it's helpful for transformers to have access to the positional information so they \"know\" two tokens are next to each other (and hence probably relevant to each other).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb3wtM2bm4R7"
      },
      "source": [
        "## Actual Code!\n",
        "\n",
        "Key (for the results you get when running the code immediately below)\n",
        "\n",
        "```\n",
        "batch = 1\n",
        "position = 35\n",
        "d_model = 768\n",
        "n_heads = 12\n",
        "n_layers = 12\n",
        "d_mlp = 3072 (= 4 * d_model)\n",
        "d_head = 64 (= d_model / n_heads)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC9PaopAm4R7"
      },
      "source": [
        "### Parameters and Activations\n",
        "\n",
        "It's important to distinguish between parameters and activations in the model.\n",
        "\n",
        "* **Parameters** are the weights and biases that are learned during training.\n",
        "    * These don't change when the model input changes.\n",
        "* **Activations** are temporary numbers calculated during a forward pass, that are functions of the input.\n",
        "    * We can think of these values as only existing for the duration of a single forward pass, and disappearing afterwards.\n",
        "    * We can use hooks to access these values during a forward pass (more on hooks later), but it doesn't make sense to talk about a model's activations outside the context of some particular input.\n",
        "    * Attention scores and patterns are activations (this is slightly non-intuitve because they're used in a matrix multiplication with another activation).\n",
        "\n",
        "#### Print All Activation Shapes of Reference Model\n",
        "\n",
        "Run the following code to print all the activation shapes of the reference model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "m6lM8CJmpwDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815c090c-3b58-4dbe-bf15-412a070168e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hook_embed                     (1, 35, 768)\n",
            "hook_pos_embed                 (1, 35, 768)\n",
            "blocks.0.hook_resid_pre        (1, 35, 768)\n",
            "blocks.0.ln1.hook_scale        (1, 35, 1)\n",
            "blocks.0.ln1.hook_normalized   (1, 35, 768)\n",
            "blocks.0.attn.hook_q           (1, 35, 12, 64)\n",
            "blocks.0.attn.hook_k           (1, 35, 12, 64)\n",
            "blocks.0.attn.hook_v           (1, 35, 12, 64)\n",
            "blocks.0.attn.hook_attn_scores (1, 12, 35, 35)\n",
            "blocks.0.attn.hook_pattern     (1, 12, 35, 35)\n",
            "blocks.0.attn.hook_z           (1, 35, 12, 64)\n",
            "blocks.0.hook_attn_out         (1, 35, 768)\n",
            "blocks.0.hook_resid_mid        (1, 35, 768)\n",
            "blocks.0.ln2.hook_scale        (1, 35, 1)\n",
            "blocks.0.ln2.hook_normalized   (1, 35, 768)\n",
            "blocks.0.mlp.hook_pre          (1, 35, 3072)\n",
            "blocks.0.mlp.hook_post         (1, 35, 3072)\n",
            "blocks.0.hook_mlp_out          (1, 35, 768)\n",
            "blocks.0.hook_resid_post       (1, 35, 768)\n",
            "ln_final.hook_scale            (1, 35, 1)\n",
            "ln_final.hook_normalized       (1, 35, 768)\n"
          ]
        }
      ],
      "source": [
        "for activation_name, activation in cache.items():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in activation_name or \"blocks\" not in activation_name:\n",
        "        print(f\"{activation_name:30} {tuple(activation.shape)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTSyQI7wm4R7"
      },
      "source": [
        "#### Print All Parameters Shapes of Reference Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HiiiIUbdm4R7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "762c8204-324b-45fc-bf9c-4fc944514922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed.W_E          (50257, 768)\n",
            "pos_embed.W_pos    (1024, 768)\n",
            "blocks.0.ln1.w     (768,)\n",
            "blocks.0.ln1.b     (768,)\n",
            "blocks.0.ln2.w     (768,)\n",
            "blocks.0.ln2.b     (768,)\n",
            "blocks.0.attn.W_Q  (12, 768, 64)\n",
            "blocks.0.attn.W_O  (12, 64, 768)\n",
            "blocks.0.attn.b_Q  (12, 64)\n",
            "blocks.0.attn.b_O  (768,)\n",
            "blocks.0.attn.W_K  (12, 768, 64)\n",
            "blocks.0.attn.W_V  (12, 768, 64)\n",
            "blocks.0.attn.b_K  (12, 64)\n",
            "blocks.0.attn.b_V  (12, 64)\n",
            "blocks.0.mlp.W_in  (768, 3072)\n",
            "blocks.0.mlp.b_in  (3072,)\n",
            "blocks.0.mlp.W_out (3072, 768)\n",
            "blocks.0.mlp.b_out (768,)\n",
            "ln_final.w         (768,)\n",
            "ln_final.b         (768,)\n",
            "unembed.W_U        (768, 50257)\n",
            "unembed.b_U        (50257,)\n"
          ]
        }
      ],
      "source": [
        "for name, param in reference_gpt2.named_parameters():\n",
        "    # Only print for first layer\n",
        "    if \".0.\" in name or \"blocks\" not in name:\n",
        "        print(f\"{name:18} {tuple(param.shape)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7tXtTowp0Fy"
      },
      "source": [
        "[This diagram](https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/full-merm.svg) shows the name of all activations and parameters in a fully general transformer model from transformerlens (except for a few at the start and end, like the embedding and unembedding). Lots of this won't make sense at first, but you can return to this diagram later and check that you understand most/all parts of it.\n",
        "\n",
        "There's also an annotated version [here](https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/transformer-full-updated.png).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTbG6T8Bm4R8"
      },
      "source": [
        "### Config\n",
        "\n",
        "The config object contains all the hyperparameters of the model. We can print the config of the reference model to see what it contains:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WPzJd3z-m4R8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d67106-1809-4391-b412-eb66599286c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HookedTransformerConfig:\n",
            "{'act_fn': 'gelu_new',\n",
            " 'attention_dir': 'causal',\n",
            " 'attn_only': False,\n",
            " 'attn_scale': 8.0,\n",
            " 'attn_scores_soft_cap': -1.0,\n",
            " 'attn_types': None,\n",
            " 'checkpoint_index': None,\n",
            " 'checkpoint_label_type': None,\n",
            " 'checkpoint_value': None,\n",
            " 'd_head': 64,\n",
            " 'd_mlp': 3072,\n",
            " 'd_model': 768,\n",
            " 'd_vocab': 50257,\n",
            " 'd_vocab_out': 50257,\n",
            " 'decoder_start_token_id': None,\n",
            " 'default_prepend_bos': True,\n",
            " 'device': device(type='cuda'),\n",
            " 'dtype': torch.float32,\n",
            " 'eps': 1e-05,\n",
            " 'experts_per_token': None,\n",
            " 'final_rms': False,\n",
            " 'from_checkpoint': False,\n",
            " 'gated_mlp': False,\n",
            " 'init_mode': 'gpt2',\n",
            " 'init_weights': False,\n",
            " 'initializer_range': 0.02886751345948129,\n",
            " 'load_in_4bit': False,\n",
            " 'model_name': 'gpt2',\n",
            " 'n_ctx': 1024,\n",
            " 'n_devices': 1,\n",
            " 'n_heads': 12,\n",
            " 'n_key_value_heads': None,\n",
            " 'n_layers': 12,\n",
            " 'n_params': 84934656,\n",
            " 'normalization_type': 'LN',\n",
            " 'num_experts': None,\n",
            " 'original_architecture': 'GPT2LMHeadModel',\n",
            " 'output_logits_soft_cap': -1.0,\n",
            " 'parallel_attn_mlp': False,\n",
            " 'positional_embedding_type': 'standard',\n",
            " 'post_embedding_ln': False,\n",
            " 'relative_attention_max_distance': None,\n",
            " 'relative_attention_num_buckets': None,\n",
            " 'rotary_adjacent_pairs': False,\n",
            " 'rotary_base': 10000,\n",
            " 'rotary_dim': None,\n",
            " 'scale_attn_by_inverse_layer_idx': False,\n",
            " 'seed': None,\n",
            " 'tie_word_embeddings': False,\n",
            " 'tokenizer_name': 'gpt2',\n",
            " 'tokenizer_prepends_bos': False,\n",
            " 'trust_remote_code': False,\n",
            " 'use_attn_in': False,\n",
            " 'use_attn_result': False,\n",
            " 'use_attn_scale': True,\n",
            " 'use_hook_mlp_in': False,\n",
            " 'use_hook_tokens': False,\n",
            " 'use_local_attn': False,\n",
            " 'use_normalization_before_and_after': False,\n",
            " 'use_split_qkv_input': False,\n",
            " 'window_size': None}\n"
          ]
        }
      ],
      "source": [
        "# As a reference - note there's a lot of stuff we don't care about in here, to do with library internals or other architectures\n",
        "print(reference_gpt2.cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCXCsrSSm4R8"
      },
      "source": [
        "We define a stripped down config for our model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VzsnAKw7m4R8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92dece2b-5b84-4e09-ebe5-f271a0a1de5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config(d_model=768, debug=True, layer_norm_eps=1e-05, d_vocab=50257, init_range=0.02, n_ctx=1024, d_head=64, d_mlp=3072, n_heads=12, n_layers=12)\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    d_model: int = 768\n",
        "    debug: bool = True\n",
        "    layer_norm_eps: float = 1e-5\n",
        "    d_vocab: int = 50257\n",
        "    init_range: float = 0.02\n",
        "    n_ctx: int = 1024\n",
        "    d_head: int = 64\n",
        "    d_mlp: int = 3072\n",
        "    n_heads: int = 12\n",
        "    n_layers: int = 12\n",
        "\n",
        "cfg = Config()\n",
        "print(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZlXjTMWm4R8"
      },
      "source": [
        "## Tests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ8aqDkYm4R8"
      },
      "source": [
        "Tests are great, write lightweight ones to use as you go!\n",
        "\n",
        "**Naive test:** Generate random inputs of the right shape, input to your model, check whether there's an error and print the correct output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iqUK4acom4R8"
      },
      "outputs": [],
      "source": [
        "def rand_float_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).to(device)\n",
        "    random_input = t.randn(shape).to(device)\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    if isinstance(output, tuple): output = output[0]\n",
        "    print(\"Output shape:\", output.shape, \"\\n\")\n",
        "\n",
        "def rand_int_test(cls, shape):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).to(device)\n",
        "    random_input = t.randint(100, 1000, shape).to(device)\n",
        "    print(\"Input shape:\", random_input.shape)\n",
        "    output = layer(random_input)\n",
        "    if isinstance(output, tuple): output = output[0]\n",
        "    print(\"Output shape:\", output.shape, \"\\n\")\n",
        "\n",
        "def load_gpt2_test(cls, gpt2_layer, input):\n",
        "    cfg = Config(debug=True)\n",
        "    layer = cls(cfg).to(device)\n",
        "    layer.load_state_dict(gpt2_layer.state_dict(), strict=False)\n",
        "    print(\"Input shape:\", input.shape)\n",
        "    output = layer(input)\n",
        "    if isinstance(output, tuple): output = output[0]\n",
        "    print(\"Output shape:\", output.shape)\n",
        "    try: reference_output = gpt2_layer(input)\n",
        "    except: reference_output = gpt2_layer(input, input, input)\n",
        "    print(\"Reference output shape:\", reference_output.shape, \"\\n\")\n",
        "    comparison = t.isclose(output, reference_output, atol=1e-4, rtol=1e-3)\n",
        "    print(f\"{comparison.sum()/comparison.numel():.2%} of the values are correct\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo4pVDvim4R8"
      },
      "source": [
        "## LayerNorm\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "You should fill in the code below, and then run the tests to verify that your layer is working correctly.\n",
        "\n",
        "Your LayerNorm should do the following:\n",
        "\n",
        "* Make mean 0\n",
        "* Normalize to have variance 1\n",
        "* Scale with learned weights\n",
        "* Translate with learned bias\n",
        "\n",
        "You can use the PyTorch [LayerNorm documentation](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html) as a reference. A few more notes:\n",
        "\n",
        "* Your layernorm implementation always has `affine=True`, i.e. you do learn parameters `w` and `b` (which are represented as $\\gamma$ and $\\beta$ respectively in the PyTorch documentation).\n",
        "* Remember that, after the centering and normalization, each vector of length `d_model` in your input should have mean 0 and variance 1.\n",
        "* As the PyTorch documentation page says, your variance should be computed using `unbiased=False`.\n",
        "* The `layer_norm_eps` argument in your config object corresponds to the $\\epsilon$ term in the PyTorch documentation (it is included to avoid division-by-zero errors).\n",
        "* We've given you a `debug` argument in your config. If `debug=True`, then you can print output like the shape of objects in your `forward` function to help you debug (this is a very useful trick to improve your coding speed).\n",
        "\n",
        "Fill in the function, where it says `pass` (this will be the basic pattern for most other exercises in this section).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OlU317NRm4R9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f666dc1b-15e3-4e16-f720-4c74b96e59d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.w = nn.Parameter(t.ones(cfg.d_model))\n",
        "        self.b = nn.Parameter(t.zeros(cfg.d_model))\n",
        "\n",
        "    def forward(self, residual: Float[Tensor, \"batch posn d_model\"]) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        mean = residual.mean(dim=-1, keepdim=True) # (batch, posn, 1)\n",
        "        variance = residual.var(dim=-1, keepdim=True, unbiased=False) # (batch, posn, 1)\n",
        "\n",
        "        normalized = (residual - mean) / (\n",
        "            variance + self.cfg.layer_norm_eps\n",
        "        ).sqrt() # (batch, posn, d_model)\n",
        "\n",
        "        out = normalized * self.w + self.b  # (batch, posn, d_model)\n",
        "        return out\n",
        "\n",
        "rand_float_test(LayerNorm, [2, 4, 768])\n",
        "load_gpt2_test(LayerNorm, reference_gpt2.ln_final, cache[\"resid_post\", 11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9GJDIsAm4R9"
      },
      "source": [
        "## Embedding\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 5-10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "This is basically a lookup table from tokens to residual stream vectors.\n",
        "\n",
        "(Hint - you can implement this in just one line, without any complicated functions.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oc6WFuDAm4R9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68286637-c8c7-4f7e-a1de-3479a9c7d360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 45])\n",
            "Output shape: torch.Size([1, 45, 768])\n",
            "Reference output shape: torch.Size([1, 45, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class Embed(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_E = nn.Parameter(t.empty((cfg.d_vocab, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_E, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens: Int[Tensor, \"batch position\"]) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        return self.W_E[tokens] # (batch, position, d_model)\n",
        "\n",
        "rand_int_test(Embed, [2, 4])\n",
        "load_gpt2_test(Embed, reference_gpt2.embed, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fStv2M35fHN0"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I keep getting <code>RuntimeError: CUDA error: device-side assert triggered</code>.</summary>\n",
        "\n",
        "This is a uniquely frustrating type of error message, because it (1) forces you to restart the kernel, and (2) often won't tell you where the error message actually originated from!\n",
        "\n",
        "You can fix the second problem by adding the line `os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"` to the very top of your file (after importing `os`). This won't fix your bug, but it makes sure the correct origin point is identified.\n",
        "\n",
        "As for actually fixing the bug, this error usually ends up being the result of bad indexing, e.g. you're trying to apply an embedding layer to tokens which are larger than your maximum embedding.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhHFmPZ6m4R9"
      },
      "source": [
        "## Positional Embedding\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Positional embedding can also be thought of as a lookup table, but rather than the indices being our token IDs, the indices are just the numbers `0`, `1`, `2`, ..., `seq_len-1` (i.e. the position indices of the tokens in the sequence).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fNAkYB8dm4R9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dedcc358-f80e-4e63-f8c8-0c94e01d048d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 45])\n",
            "Output shape: torch.Size([45, 768])\n",
            "Reference output shape: torch.Size([1, 45, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(self, tokens: Int[Tensor, \"batch position\"]) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        return self.W_pos[t.arange(tokens.shape[1], device=device)] # (batch, position, d_model)\n",
        "\n",
        "rand_int_test(PosEmbed, [2, 4])\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Causal Mask\n",
        "```yaml\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵🔵🔵\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "The causal mask function will be a method of the `Attention` class.\n",
        "It will take in attention scores, and apply a mask to them so that the model\n",
        "can only attend to previous positions (i.e. the model can't cheat by looking at future positions).\n",
        "We will implement this function first, and test it, before moving onto the `forward` method\n",
        "of the `Attention` class.\n",
        "\n",
        "A few hints:\n",
        "\n",
        "* You can use [`torch.where`](https://pytorch.org/docs/stable/generated/torch.where.html), or the [`torch.masked_fill_`](https://pytorch.org/docs/stable/generated/torch.Tensor.masked_fill.html) function when masking the attention scores.\n",
        "* The [`torch.triu`](https://pytorch.org/docs/stable/generated/torch.triu.html) function is useful for creating a mask that is True for all positions we want to set probabilities to zero for.\n",
        "* Make sure to use the `self.IGNORE` attribute to set the masked positions to negative infinity.\n",
        "<details>\n",
        "<summary>Question - why do you think we mask the attention scores by setting them to negative infinity, rather than the attention probabilities by setting them to zero?</summary>\n",
        "\n",
        "If we masked the attention probabilities, then the probabilities would no longer sum to 1.\n",
        "\n",
        "We want to mask the scores and *then* take softmax, so that the probabilities are still valid probabilities (i.e. they sum to 1), and the values in the masked positions have no influence on the model's output.\n",
        "</details>"
      ],
      "metadata": {
        "id": "rsSCH4QIi_Y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.register_buffer(\"IGNORE\", t.tensor(float(\"-inf\"), dtype=t.float32, device=device))\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self, attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"],\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "        '''\n",
        "        Applies a causal mask to attention scores, and returns masked scores.\n",
        "        '''\n",
        "        mask = t.triu(t.ones(attn_scores.shape[2], attn_scores.shape[3], device=device), diagonal=1) # (query_pos, key_pos)\n",
        "        attn_scores = attn_scores.masked_fill(mask == 1, self.IGNORE)\n",
        "        return attn_scores\n",
        "\n",
        "tests.test_causal_mask(Attention.apply_causal_mask)"
      ],
      "metadata": {
        "id": "3PFipibtjEKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d967c525-f002-4f0c-9512-4eddf72220df"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_causal_mask` passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_WZWukYm4R-"
      },
      "source": [
        "## Attention\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴🔴⚪\n",
        "Importance: 🔵🔵🔵🔵🔵\n",
        "\n",
        "You should spend up to 30-45 minutes on this exercise.\n",
        "```\n",
        "\n",
        "* **Step 1:** Produce an attention pattern - for each destination token, probability distribution over previous tokens (including current token)\n",
        "    * Linear map from input -> query, key shape `[batch, seq_posn, head_index, d_head]`\n",
        "    * Dot product every *pair* of queries and keys to get attn_scores `[batch, head_index, query_pos, key_pos]` (query = dest, key = source)\n",
        "    * **Scale** and mask `attn_scores` to make it lower triangular, i.e. causal\n",
        "    * Softmax along the `key_pos` dimension, to get a probability distribution for each query (destination) token - this is our attention pattern!\n",
        "* **Step 2:** Move information from source tokens to destination token using attention pattern (move = apply linear map)\n",
        "    * Linear map from input -> value `[batch, key_pos, head_index, d_head]`\n",
        "    * Mix along the `key_pos` with attn pattern to get `z`, which is a weighted average of the value vectors `[batch, query_pos, head_index, d_head]`\n",
        "    * Map to output, `[batch, position, d_model]` (position = query_pos, we've summed over all heads)\n",
        "\n",
        "Note - when we say **scale**, we mean dividing by `sqrt(d_head)`. The purpose of this is to avoid vanishing gradients (which is a big problem when we're dealing with a function like softmax - if one of the values is much larger than all the others, the probabilities will be close to 0 or 1, and the gradients will be close to 0).\n",
        "\n",
        "Below is a much larger, more detailed version of the attention head diagram from earlier. This should give you an idea of the actual tensor operations involved. A few clarifications on this diagram:\n",
        "\n",
        "* Whenever there is a third dimension shown in the pictures, this refers to the `head_index` dimension. We can see that all operations within the attention layer are done independently for each head.\n",
        "* The objects in the box are activations; they have a batch dimension (for simplicity, we assume the batch dimension is 1 in the diagram). The objects to the right of the box are our parameters (weights and biases); they have no batch dimension.\n",
        "* We arrange the keys, queries and values as `(batch, seq_pos, head_idx, d_head)`, because the biases have shape `(head_idx, d_head)`, so this makes it convenient to add the biases (recall the rules of array broadcasting!).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuZvGlnhsIcr"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/transformer-attn-21.png\" width=\"1400\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCODWJmAsr8x"
      },
      "source": [
        "<details>\n",
        "<summary><b>A few extra notes on attention (optional)</b></summary>\n",
        "\n",
        "Usually we have the relation `e = n * h` (i.e. `d_model = num_heads * d_head`). There are some computational justifications for this, but mostly this is just done out of convention (just like how we usually have `d_mlp = 4 * d_model`!).\n",
        "\n",
        "---\n",
        "\n",
        "The names **keys**, **queries** and **values** come from their analogy to retrieval systems. Broadly speaking:\n",
        "\n",
        "* The **queries** represent some information that a token is **\"looking for\"**\n",
        "* The **keys** represent the information that a token **\"contains\"**\n",
        "    * So the attention score being high basically means that the source (key) token contains the information which the destination (query) token **is looking for**\n",
        "* The **values** represent the information that is actually taken from the source token, to be moved to the destination token\n",
        "\n",
        "---\n",
        "\n",
        "This diagram can better help us understand the difference between the **QK** and **OV** circuit. We'll discuss this just briefly here, and will go into much more detail later on.\n",
        "\n",
        "The **QK** circuit consists of the operation of the $W_Q$ and $W_K$ matrices. In other words, it determines the attention pattern, i.e. where information is moved to and from in the residual stream. The functional form of the attention pattern $A$ is:\n",
        "\n",
        "$$\n",
        "A = \\text{softmax}\\left(\\frac{x^T W_Q W_K^T x}{\\sqrt{d_{head}}}\\right)\n",
        "$$\n",
        "\n",
        "where $x$ is the residual stream (shape `[seq_len, d_model]`), and $W_Q$, $W_K$ are the weight matrices for a single head (i.e. shape `[d_model, d_head]`).\n",
        "\n",
        "The **OV** circuit consists of the operation of the $W_V$ and $W_O$ matrices. Once attention patterns are fixed, these matrices operate on the residual stream at the source position, and their output is the thing which gets moved from source to destination position.\n",
        "\n",
        "The functional form of an entire attention head is:\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "\\text{output} &= \\text{softmax}\\left(\\frac{x W_Q W_K^T x^T}{\\sqrt{d_{head}}}\\right) (x W_V W_O) \\\\\n",
        "    &= Ax W_V W_O\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "where $W_V$ has shape `[d_model, d_head]`, and $W_O$ has shape `[d_head, d_model]`.\n",
        "\n",
        "Here, we can clearly see that the **QK circuit** and **OV circuit** are doing conceptually different things, and should be thought of as two distinct parts of the attention head.\n",
        "\n",
        "Again, don't worry if you don't follow all of this right now - we'll go into **much** more detail on all of this in subsequent exercises. The purpose of the discussion here is just to give you a flavour of what's to come!\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA2JcOaHm4R-"
      },
      "source": [
        "First, it's useful to visualize and play around with attention patterns - what exactly are we looking at here? (Click on a head to lock onto just showing that head's pattern, it'll make it easier to interpret)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "T38f-qpJtBTD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d2a5c4d8-4d24-42d2-adc3-dcd27611cf1e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7cdbe134db40>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-c757296d-1b96\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-c757296d-1b96\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"<|endoftext|>\", \"I\", \" am\", \" an\", \" amazing\", \" aut\", \"ore\", \"gressive\", \",\", \" dec\", \"oder\", \"-\", \"only\", \",\", \" G\", \"PT\", \"-\", \"2\", \" style\", \" transformer\", \".\", \" One\", \" day\", \" I\", \" will\", \" exceed\", \" human\", \" level\", \" intelligence\", \" and\", \" take\", \" over\", \" the\", \" world\", \"!\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9679255485534668, 0.032074473798274994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8024235367774963, 0.16839203238487244, 0.029184352606534958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6959055662155151, 0.12269631028175354, 0.14588488638401031, 0.035513248294591904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5661025047302246, 0.14705194532871246, 0.08665254712104797, 0.11258415132761002, 0.08760887384414673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4621872901916504, 0.13512834906578064, 0.09698349237442017, 0.17473752796649933, 0.046246010810136795, 0.08471736311912537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.43251609802246094, 0.10382883995771408, 0.0833013653755188, 0.06995750963687897, 0.074793741106987, 0.2156866192817688, 0.019915923476219177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22236739099025726, 0.0916769802570343, 0.08796326071023941, 0.25168728828430176, 0.08263691514730453, 0.10428163409233093, 0.06469019502401352, 0.09469636529684067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4049956202507019, 0.09078018367290497, 0.05237356200814247, 0.026201872155070305, 0.11047190427780151, 0.036674048751592636, 0.025538960471749306, 0.24528275430202484, 0.007681120652705431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39985963702201843, 0.04361317306756973, 0.061838824301958084, 0.0729835107922554, 0.03661304712295532, 0.09147469699382782, 0.07241712510585785, 0.07013335824012756, 0.06429054588079453, 0.08677610009908676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09702549129724503, 0.035527583211660385, 0.023214811459183693, 0.036767054349184036, 0.025158407166600227, 0.27756166458129883, 0.07676514238119125, 0.1950118988752365, 0.05580098181962967, 0.14529390633106232, 0.031873054802417755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24143841862678528, 0.03971061110496521, 0.0768737941980362, 0.02804269827902317, 0.12435992062091827, 0.05601579695940018, 0.0606367290019989, 0.1284009963274002, 0.015699446201324463, 0.09114032983779907, 0.13185447454452515, 0.005826778709888458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1436309665441513, 0.05110502988100052, 0.05505892634391785, 0.07798511534929276, 0.0785427913069725, 0.035019710659980774, 0.1349860280752182, 0.22634069621562958, 0.04162851721048355, 0.03513140231370926, 0.02023601345717907, 0.04114445298910141, 0.0591902956366539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3156285583972931, 0.06791999936103821, 0.037872374057769775, 0.01787460222840309, 0.0868317037820816, 0.02922781929373741, 0.017664166167378426, 0.1830163300037384, 0.0049877953715622425, 0.043228648602962494, 0.05172262713313103, 0.008913454599678516, 0.1289924532175064, 0.0061195120215415955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28410208225250244, 0.053453970700502396, 0.023969216272234917, 0.02256225235760212, 0.046198226511478424, 0.06391073763370514, 0.04539216309785843, 0.07758502662181854, 0.027644306421279907, 0.05804116278886795, 0.17727360129356384, 0.03400600329041481, 0.030527280643582344, 0.03213080018758774, 0.023203175514936447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14103920757770538, 0.028577815741300583, 0.0376039557158947, 0.03137826919555664, 0.03697335720062256, 0.07347068935632706, 0.07151783257722855, 0.09211234748363495, 0.03358153626322746, 0.03639131039381027, 0.18937668204307556, 0.032445166260004044, 0.060210373252630234, 0.03916924446821213, 0.04040950909256935, 0.055742647498846054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2026529461145401, 0.030252814292907715, 0.06003406643867493, 0.021786153316497803, 0.1031423807144165, 0.04516838863492012, 0.04681028798222542, 0.10542111843824387, 0.011398821137845516, 0.07159948348999023, 0.10570328682661057, 0.004199368413537741, 0.1107979267835617, 0.013912523165345192, 0.028923507779836655, 0.032869454473257065, 0.005327512975782156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20498360693454742, 0.04007228836417198, 0.042298126965761185, 0.02493901364505291, 0.04992290213704109, 0.029371697455644608, 0.030769698321819305, 0.10315564274787903, 0.02549021691083908, 0.07886797189712524, 0.10560183972120285, 0.01735270954668522, 0.08083697408437729, 0.03128695487976074, 0.054510582238435745, 0.05288316309452057, 0.0217428021132946, 0.0059138014912605286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24350900948047638, 0.036364901810884476, 0.04196161776781082, 0.026215724647045135, 0.040445733815431595, 0.09965366870164871, 0.025752248242497444, 0.03249461203813553, 0.024459943175315857, 0.035202644765377045, 0.033835381269454956, 0.033476900309324265, 0.04664861783385277, 0.027967926114797592, 0.0186407882720232, 0.11764257401227951, 0.038752853870391846, 0.022786684334278107, 0.05418814718723297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14194568991661072, 0.034064050763845444, 0.033009886741638184, 0.020238706842064857, 0.03927314281463623, 0.026005549356341362, 0.006318643689155579, 0.0407978817820549, 0.03638002276420593, 0.146310493350029, 0.016386177390813828, 0.023598454892635345, 0.015842773020267487, 0.042276062071323395, 0.02245822362601757, 0.0686740130186081, 0.027878452092409134, 0.037222422659397125, 0.08677618950605392, 0.13454319536685944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21778136491775513, 0.026903675869107246, 0.02364719845354557, 0.007102563977241516, 0.03517002984881401, 0.01399853453040123, 0.010392282158136368, 0.09431242942810059, 0.00296228751540184, 0.03783802688121796, 0.037923313677310944, 0.0037339734844863415, 0.06506101042032242, 0.0036364602856338024, 0.014758041128516197, 0.12028626352548599, 0.004900881089270115, 0.008107365109026432, 0.017449840903282166, 0.24998724460601807, 0.004047100432217121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1218722015619278, 0.07663217931985855, 0.030231976881623268, 0.016371842473745346, 0.05268790200352669, 0.021402154117822647, 0.02340387925505638, 0.10649685561656952, 0.018582480028271675, 0.035091664642095566, 0.0839415043592453, 0.017393290996551514, 0.04183056950569153, 0.02145387977361679, 0.0333310104906559, 0.05027427151799202, 0.020740864798426628, 0.040903590619564056, 0.03054095432162285, 0.09200657904148102, 0.028245704248547554, 0.036564696580171585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21260197460651398, 0.020284097641706467, 0.05000370740890503, 0.015904178842902184, 0.057225070893764496, 0.02285732328891754, 0.046045877039432526, 0.03530844300985336, 0.011784467846155167, 0.041404839605093, 0.016803624108433723, 0.015782050788402557, 0.02020842768251896, 0.01309018861502409, 0.020854245871305466, 0.06297554075717926, 0.018039442598819733, 0.018052957952022552, 0.024445295333862305, 0.17059145867824554, 0.015939772129058838, 0.04152188450098038, 0.04827510938048363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26714006066322327, 0.03564617782831192, 0.02042287588119507, 0.006622723303735256, 0.04034103453159332, 0.019110340625047684, 0.014575295150279999, 0.056416332721710205, 0.008403628133237362, 0.015526887960731983, 0.04414670914411545, 0.011055906303226948, 0.04001997783780098, 0.009353081695735455, 0.019351869821548462, 0.07054154574871063, 0.012798824347555637, 0.012832624837756157, 0.014165612868964672, 0.11736990511417389, 0.007312782108783722, 0.09727413952350616, 0.020751142874360085, 0.03882049396634102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14591234922409058, 0.03319380059838295, 0.031387705355882645, 0.00992790050804615, 0.05209650844335556, 0.019840899854898453, 0.019401725381612778, 0.07582411170005798, 0.012863261625170708, 0.03345128893852234, 0.01656840555369854, 0.01479717344045639, 0.05908384174108505, 0.015597393736243248, 0.01136922836303711, 0.021859480068087578, 0.019473880529403687, 0.014793709851801395, 0.05341864004731178, 0.09521486610174179, 0.016204562038183212, 0.06210915371775627, 0.061828501522541046, 0.0665796548128128, 0.03720194473862648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06265703588724136, 0.014285163953900337, 0.025387218222022057, 0.030092518776655197, 0.021246911957859993, 0.02952992171049118, 0.026446694508194923, 0.014830503612756729, 0.015861935913562775, 0.043314337730407715, 0.021963955834507942, 0.0199701227247715, 0.04342854395508766, 0.018692897632718086, 0.009475365281105042, 0.024197489023208618, 0.02385362610220909, 0.0269087515771389, 0.014060708694159985, 0.1752849817276001, 0.03583677113056183, 0.047922562807798386, 0.035750601440668106, 0.01207051333039999, 0.05927426367998123, 0.1476566046476364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09766799211502075, 0.03152173385024071, 0.026686420664191246, 0.03645577281713486, 0.03492369130253792, 0.08635794371366501, 0.013895386829972267, 0.03018672950565815, 0.019402576610445976, 0.035141684114933014, 0.048781562596559525, 0.012551559135317802, 0.04099080711603165, 0.020208824425935745, 0.012653257697820663, 0.007451050449162722, 0.013522964902222157, 0.02407807484269142, 0.04302708059549332, 0.15066799521446228, 0.029252585023641586, 0.018810171633958817, 0.016104498878121376, 0.02854987047612667, 0.02987591177225113, 0.051215607672929764, 0.04001831263303757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0915181115269661, 0.01142112072557211, 0.039799030870199203, 0.011658591218292713, 0.03344331309199333, 0.04107605665922165, 0.009538301266729832, 0.04061255231499672, 0.00911438837647438, 0.04690402373671532, 0.02731761522591114, 0.010844956152141094, 0.0245475135743618, 0.010004601441323757, 0.008095634169876575, 0.00839681550860405, 0.01185548771172762, 0.008184152655303478, 0.04104064032435417, 0.3625810444355011, 0.007537385914474726, 0.009961556643247604, 0.021045755594968796, 0.01185503602027893, 0.030058305710554123, 0.03281192108988762, 0.028863219544291496, 0.00991280097514391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10946289449930191, 0.02587275020778179, 0.02392871491611004, 0.02004525251686573, 0.03590444475412369, 0.03167986124753952, 0.029145274311304092, 0.11399827897548676, 0.013954712077975273, 0.034807175397872925, 0.018105627968907356, 0.01762225665152073, 0.01900731772184372, 0.015307599678635597, 0.0097030159085989, 0.012407945469021797, 0.02009168267250061, 0.02726256288588047, 0.0656459853053093, 0.027155401185154915, 0.02622661367058754, 0.01894299127161503, 0.04077143594622612, 0.019073303788900375, 0.021573418751358986, 0.03021942265331745, 0.07011833041906357, 0.06031468138098717, 0.04165106639266014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11406350880861282, 0.026556234806776047, 0.01995842717587948, 0.008931470103561878, 0.034943222999572754, 0.01683431677520275, 0.009377745911478996, 0.0445132851600647, 0.00377222103998065, 0.02876032516360283, 0.02074114792048931, 0.005650992039591074, 0.060077618807554245, 0.004424978978931904, 0.01082183700054884, 0.04112928733229637, 0.007085718214511871, 0.010434001684188843, 0.026548532769083977, 0.11019264161586761, 0.00719001330435276, 0.05651939660310745, 0.028027096763253212, 0.06370092928409576, 0.03407694771885872, 0.07150981575250626, 0.040933214128017426, 0.014252983033657074, 0.06984366476535797, 0.009128453209996223, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14399932324886322, 0.020454606041312218, 0.04262388497591019, 0.011592099443078041, 0.027789423242211342, 0.014342913404107094, 0.029106194153428078, 0.04215822368860245, 0.013669716194272041, 0.02058148942887783, 0.008641066960990429, 0.01240221131592989, 0.01957707293331623, 0.014879737049341202, 0.023319046944379807, 0.022367175668478012, 0.014413881115615368, 0.006065307185053825, 0.006985309533774853, 0.08859116584062576, 0.014219224452972412, 0.027541182935237885, 0.057073067873716354, 0.02498571015894413, 0.057332996279001236, 0.048089705407619476, 0.018268706277012825, 0.07940172404050827, 0.04377175495028496, 0.024849100038409233, 0.020907001569867134, 0.0, 0.0, 0.0, 0.0], [0.07786805182695389, 0.019732864573597908, 0.019906366243958473, 0.015179570764303207, 0.02926989272236824, 0.008963337168097496, 0.011427867226302624, 0.03169625252485275, 0.006965262349694967, 0.04064170643687248, 0.01998521387577057, 0.008789058774709702, 0.03574990853667259, 0.007953666150569916, 0.009612184017896652, 0.014965921640396118, 0.010367297567427158, 0.013545000925660133, 0.01374734565615654, 0.06818549335002899, 0.01183705497533083, 0.01935550943017006, 0.016761228442192078, 0.016301216557621956, 0.06125021353363991, 0.12023527920246124, 0.04739146679639816, 0.02382204681634903, 0.14942999184131622, 0.014121495187282562, 0.04741879925131798, 0.007523441221565008, 0.0, 0.0, 0.0], [0.14836615324020386, 0.036274224519729614, 0.023768767714500427, 0.0053084008395671844, 0.03226036578416824, 0.017439451068639755, 0.015090287663042545, 0.04443071782588959, 0.004935791250318289, 0.02115151286125183, 0.023849114775657654, 0.00612779101356864, 0.04430978000164032, 0.005717849358916283, 0.006861449219286442, 0.016362622380256653, 0.007707122713327408, 0.009109629318118095, 0.02842760644853115, 0.144913911819458, 0.0063516004011034966, 0.03453824296593666, 0.023273009806871414, 0.04803793504834175, 0.03441666439175606, 0.06975367665290833, 0.027561908587813377, 0.0120165403932333, 0.03535730764269829, 0.008575203828513622, 0.03916303440928459, 0.009715795516967773, 0.00882658176124096, 0.0, 0.0], [0.11389314383268356, 0.021931476891040802, 0.026447594165802002, 0.007602885365486145, 0.02053067833185196, 0.029713159427046776, 0.03694962337613106, 0.028757939115166664, 0.007981306873261929, 0.029359182342886925, 0.015349611639976501, 0.01842017099261284, 0.020850980654358864, 0.008514756336808205, 0.010930925607681274, 0.009227696806192398, 0.021279292181134224, 0.009222986176609993, 0.027651088312268257, 0.12458859384059906, 0.010509626939892769, 0.06096193566918373, 0.022033261135220528, 0.03036692924797535, 0.027411185204982758, 0.03459944576025009, 0.03202729672193527, 0.039529699832201004, 0.05353795364499092, 0.017732897773385048, 0.017497550696134567, 0.01777147874236107, 0.012080208398401737, 0.034737344831228256, 0.0], [0.13933588564395905, 0.02137126959860325, 0.014541366137564182, 0.005123288370668888, 0.0316350944340229, 0.010921811684966087, 0.012541363015770912, 0.02249286137521267, 0.004774264059960842, 0.024901436641812325, 0.01085835974663496, 0.010577704757452011, 0.025906087830662727, 0.005286508239805698, 0.016752298921346664, 0.04520439729094505, 0.012112229131162167, 0.014714703895151615, 0.014629190787672997, 0.08781159669160843, 0.007287841755896807, 0.07496529817581177, 0.015995560213923454, 0.04392345994710922, 0.04102412983775139, 0.07587806135416031, 0.02792457304894924, 0.015250182710587978, 0.013413453474640846, 0.014532781206071377, 0.02721545472741127, 0.03453553467988968, 0.018207406625151634, 0.03505333513021469, 0.023301267996430397]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041899754432961345, 0.9995810389518738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00013394761481322348, 0.009511838667094707, 0.9903541803359985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008606771007180214, 0.0026100394316017628, 0.015066809952259064, 0.9814624786376953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.717040817718953e-05, 0.0006769567262381315, 0.0012692938325926661, 0.0002140780707122758, 0.9978025555610657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.425416308455169e-05, 0.0007904717931523919, 0.0032152850180864334, 0.0027085694018751383, 0.0013058256590738893, 0.9918956160545349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014960527187213302, 0.0018361854599788785, 0.0016375032719224691, 0.001013060798868537, 0.004209812264889479, 8.004387927940115e-05, 0.9910737872123718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002685565559659153, 0.0009259640937671065, 0.0008250505197793245, 0.0006819659029133618, 0.007268862333148718, 0.001351707149296999, 0.00034691710607148707, 0.9883310198783875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007326364051550627, 0.007828550413250923, 0.0039318762719631195, 0.0001837400923250243, 6.43310122541152e-05, 0.0001008316467050463, 6.769897299818695e-05, 7.164081034716219e-05, 0.9804249405860901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.917570938938297e-05, 9.137415327131748e-05, 0.00033399087260477245, 6.816770473960787e-05, 7.81232156441547e-05, 0.0009843026055023074, 0.00016941322246566415, 0.002541458932682872, 4.413309216033667e-05, 0.9956498742103577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.5203117881319486e-06, 2.3466483980882913e-05, 9.186465467792004e-05, 8.01341884653084e-05, 3.939209636882879e-05, 8.521587733412161e-05, 2.573589881649241e-05, 7.120813097571954e-05, 4.276960225979565e-06, 0.00015049739158712327, 0.9994226694107056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010400302708148956, 0.002299361629411578, 0.0023920685052871704, 0.0003133234567940235, 0.00013362923345994204, 0.0005168461939319968, 0.0011971096973866224, 6.827443576185033e-05, 0.005444325506687164, 0.0002821744710672647, 4.3057276343461126e-05, 0.9862697720527649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.63041833427269e-05, 0.0003248237771913409, 0.00024459476117044687, 0.001531170099042356, 0.0008613731479272246, 0.0012943913461640477, 6.198477058205754e-05, 2.664277417352423e-05, 4.84087759105023e-05, 0.001985571114346385, 0.00013971907901577652, 0.0001143431436503306, 0.9933207035064697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0030442429706454277, 0.0018223646329715848, 0.0009289867011830211, 4.8802314267959446e-05, 1.6391171811847016e-05, 2.9095650461385958e-05, 2.507984208932612e-05, 2.9130302209523506e-05, 0.4563218355178833, 2.4578692318755202e-05, 2.483218486304395e-05, 0.003004396567121148, 1.677382101661351e-06, 0.5346786379814148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00039817875949665904, 0.0010285003809258342, 0.000828111544251442, 0.00023753165442030877, 7.348863437073305e-05, 0.0014350308338180184, 6.765663420083001e-05, 0.00029547399026341736, 0.0001429579424438998, 9.929091902449727e-05, 4.60821593151195e-06, 0.000514006766024977, 5.035657068219734e-06, 0.00012475518451537937, 0.9947452545166016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.074864647118375e-05, 0.0002652599068824202, 0.00011011186870746315, 0.00021231947175692767, 8.290550613310188e-05, 0.0011814209865406156, 1.5688718121964484e-05, 0.0016655955696478486, 1.1725332115020137e-05, 0.0020509453024715185, 0.00013842586486134678, 1.557363611937035e-05, 1.150744083133759e-05, 9.066193342732731e-06, 0.00022655802604276687, 0.9939122200012207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00044135426287539303, 0.0006528961239382625, 0.0006495665293186903, 9.398067049914971e-05, 4.112707028980367e-05, 0.00017028416914399713, 0.0005066704470664263, 2.889607821998652e-05, 0.0023701833561062813, 0.0001045431854436174, 1.923093805089593e-05, 0.4705588221549988, 1.680400782788638e-05, 0.002284094225615263, 0.00021698094496969134, 3.276941424701363e-05, 0.5218117833137512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005350523279048502, 0.0006631254218518734, 0.00018957522115670145, 0.00011594548413995653, 3.930590901290998e-05, 8.452115434920415e-05, 0.00026859997888095677, 0.0003003481833729893, 0.0001272758818231523, 0.00015363430429715663, 2.1524516341742128e-05, 0.0004102020466234535, 0.0015090389642864466, 0.00011659036681521684, 0.0001377397566102445, 7.38915623514913e-05, 0.00039899448165670037, 0.9948546886444092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002235247375210747, 0.0002502534771338105, 0.00011739338515326381, 1.8608267055242322e-05, 0.0006291492027230561, 0.0007579223602078855, 3.784089858527295e-05, 0.0033851482439786196, 1.791827889974229e-05, 0.00017818294872995466, 3.4344266168773174e-05, 7.747584459139034e-05, 6.471157394116744e-05, 1.5270292351488024e-05, 0.0002935958909802139, 0.0005734387668780982, 7.154404011089355e-05, 0.0001588314480613917, 0.993094801902771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00030641001649200916, 0.0004168010491412133, 0.0004519718640949577, 0.0001574639609316364, 0.0015800739638507366, 0.002266631228849292, 0.00014483617269434035, 0.00251887203194201, 4.4711858208756894e-05, 0.0027394636999815702, 0.000434897345257923, 0.00015683105448260903, 2.8505710361059755e-05, 4.005827577202581e-05, 0.000593667384237051, 0.00011775219900300726, 0.0001403962232870981, 0.00018060373258776963, 0.0009641882497817278, 0.9867159128189087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009046882390975952, 0.0007260903948917985, 6.491786189144477e-05, 4.578266089083627e-05, 3.669528086902574e-05, 3.389695848454721e-05, 4.131328751100227e-05, 9.000120917335153e-05, 0.016163919121026993, 1.8953802282339893e-05, 3.3513781090732664e-05, 0.0021810815669596195, 5.341176802176051e-06, 0.018749460577964783, 0.0001789774833014235, 0.00049936881987378, 0.0024355659261345863, 4.271611032891087e-05, 7.329288928303868e-05, 1.9154360415996052e-05, 0.9495131969451904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00021946291963104159, 0.0011669580126181245, 0.00021983245096635073, 0.0009876289404928684, 0.00031338463304564357, 0.00012072654499206692, 5.631537533190567e-06, 2.4260070858872496e-05, 4.544197872746736e-05, 1.852959394454956e-05, 1.4025716154719703e-05, 1.0154987649002578e-05, 0.0004018021281808615, 4.0526429074816406e-05, 0.0001710674405330792, 9.8690579761751e-06, 9.488572686677799e-06, 0.0003931091050617397, 5.709413926524576e-06, 1.7844293324742466e-05, 2.8530415875138715e-05, 0.9957762360572815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00019361003069207072, 0.0008434180053882301, 0.0005215295823290944, 2.566456350905355e-05, 0.00046233212924562395, 0.00025401596212759614, 1.8471198927727528e-05, 0.00011509784235386178, 0.00027288994169794023, 0.00015436687681358308, 1.2149157555541024e-05, 0.0006913748802617192, 5.695979416486807e-05, 0.00024024784215725958, 3.827492764685303e-05, 9.934457921190187e-05, 0.0006488919025287032, 8.011747559066862e-05, 0.00019218817760702223, 2.5529448976158164e-05, 0.00032434772583656013, 0.0010871072299778461, 0.9936420321464539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0016077648615464568, 0.1769733428955078, 0.015483599156141281, 0.0003713879268616438, 0.0003786341694649309, 0.00016452741692773998, 0.00032773835118860006, 0.00016989713185466826, 0.0021229630801826715, 3.573103458620608e-05, 6.090146052883938e-05, 0.00045621677418239415, 1.5447807527380064e-05, 0.0022543170489370823, 0.0015666891122236848, 0.00011843765969388187, 0.0004699892597272992, 5.037321534473449e-05, 0.00012108073133276775, 6.008972559357062e-05, 0.0008920581312850118, 0.000751846528146416, 0.00026899686781689525, 0.7952780723571777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003919867449440062, 0.00021421202109195292, 0.0005306120729073882, 1.0745785402832553e-05, 0.00011862390965688974, 4.225783050060272e-05, 0.00021160392498131841, 4.692554284702055e-05, 0.00044815847650170326, 0.00010691297211451456, 3.935468339477666e-05, 0.00016830874665174633, 0.00017352365830447525, 0.000452450942248106, 0.00014294125139713287, 0.00011699349124683067, 0.00017526814190205187, 0.00010119970829691738, 4.25139041908551e-05, 2.0371742721181363e-05, 3.83713559131138e-05, 0.00011344622180331498, 0.00025279319379478693, 6.991033296799287e-05, 0.9959704875946045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002153067762264982, 0.0001000583142740652, 0.0023809161502867937, 0.0019831405952572823, 0.0011120109120383859, 5.563462036661804e-05, 0.0006109256646595895, 0.0002456431102473289, 8.818998321658e-05, 0.0011510387994349003, 0.00010669889161363244, 0.00017554854275658727, 5.7362729421583936e-05, 7.814786658855155e-05, 0.000245734496274963, 9.594661605660804e-06, 0.00017032361938618124, 2.8972623113077134e-05, 1.4011687198944855e-05, 0.00016692050849087536, 1.2888858691439964e-05, 0.0002449550956953317, 0.0005147008341737092, 4.942110172123648e-05, 0.0005746547831222415, 0.9896072745323181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00011423427349654958, 0.0008627416682429612, 0.0007732235244475305, 0.0007090758881531656, 0.0007292147492989898, 0.0014031626051291823, 0.00021403632126748562, 0.00017666479106992483, 6.622055661864579e-05, 3.2159430702449754e-05, 0.0004533061583060771, 0.0001200851402245462, 2.2129046556074172e-05, 5.8075143897440284e-05, 0.00012917444109916687, 1.9079669073107652e-05, 0.00011076675582444295, 8.56419592309976e-06, 2.363056773901917e-05, 0.0003379980626050383, 5.211896859691478e-05, 0.00014455695054493845, 0.0001969498407561332, 0.0004510532016865909, 2.0576282622641884e-05, 8.76431877259165e-05, 0.992683470249176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001979833614313975, 0.00019567940034903586, 0.00022612242901232094, 0.00041943672113120556, 0.000597969745285809, 0.000451744650490582, 0.0003478288999758661, 0.0002585809852462262, 2.80198801192455e-05, 0.0007220012485049665, 0.0001301045558648184, 0.001163206878118217, 6.916908751009032e-05, 2.478912938386202e-05, 0.00010386014764662832, 0.00038124938146211207, 0.0011587801855057478, 0.00033144469489343464, 0.00024494543322362006, 0.00012755172792822123, 0.0001609843602636829, 1.9267921743448824e-05, 0.00027174208662472665, 2.0765552108059637e-05, 6.82506724842824e-05, 0.0008764253580011427, 0.0006782166310586035, 0.9907240271568298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.157188984914683e-05, 0.0006791111663915217, 0.0007090717554092407, 0.00024164833303075284, 0.00041205473826266825, 0.000923742598388344, 0.00020848578424192965, 6.639298953814432e-05, 0.00011664839985314757, 8.601942681707442e-05, 0.010591322556138039, 0.0003372912178747356, 2.1898511477047578e-05, 0.00010110744187841192, 0.00010436101729283109, 5.858746590092778e-05, 0.0003251215966884047, 1.5854146113269962e-05, 5.0336129788775e-06, 0.00040949060348793864, 1.3119516552251298e-05, 5.313358997227624e-05, 1.1887270375154912e-05, 5.536681055673398e-05, 1.2197706382721663e-05, 8.95265256986022e-05, 0.0022435507271438837, 0.00021041935542598367, 0.9818660616874695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007582925027236342, 0.0012331441976130009, 8.604933827882633e-05, 6.291332101682201e-05, 2.8791733711841516e-05, 3.3166903449455276e-05, 7.622712291777134e-05, 0.00010868187382584438, 0.006450854241847992, 0.00014789080887567252, 1.0376486898167059e-05, 0.0023889716248959303, 7.88359175203368e-05, 0.007510697469115257, 0.00028743132133968174, 0.000136757327709347, 0.002760292263701558, 0.0007447165553458035, 8.81111845956184e-05, 2.470205072313547e-05, 0.0061888666823506355, 0.00011647037172224373, 0.0001724402973195538, 0.0002621748426463455, 0.0001841977791627869, 4.4321401219349355e-05, 4.855170482187532e-05, 8.903052366804332e-05, 2.6887826606980525e-05, 0.9698501229286194, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00024627428501844406, 0.00035919909714721143, 0.00020521896658465266, 9.38774537644349e-05, 8.577330299885944e-05, 5.495211007655598e-05, 4.531835293164477e-05, 1.0722159458964597e-05, 4.8671085096430033e-05, 0.00011017618089681491, 0.00010064091475214809, 9.7722360806074e-05, 0.0005496814846992493, 4.362939216662198e-05, 3.945788193959743e-05, 7.140226080082357e-05, 9.814348595682532e-05, 5.7009699958143756e-05, 2.4251108698081225e-05, 2.31456533583696e-06, 5.056934242020361e-05, 0.0001131849130615592, 0.0002906991576310247, 6.889962241984904e-05, 0.0006683259271085262, 0.0002321746142115444, 8.348713890882209e-06, 1.743463144521229e-05, 1.027311009238474e-05, 0.00013885677617508918, 0.9960569143295288, 0.0, 0.0, 0.0, 0.0], [0.0001110591838369146, 3.599160481826402e-05, 4.4160620745969936e-05, 0.00022596407507080585, 0.00024025874154176563, 1.73489679582417e-05, 7.204319263109937e-05, 0.00023739012249279767, 8.274764695670456e-05, 0.00010178561933571473, 7.876398740336299e-06, 6.3918465457391e-05, 3.295214628451504e-05, 7.889204425737262e-05, 0.0001162747576017864, 7.139155968616251e-06, 6.571767153218389e-05, 5.396374945121352e-06, 8.334040103363805e-06, 1.9613918993854895e-05, 4.11063629144337e-05, 8.538004476577044e-05, 3.1616236810805276e-05, 9.91701290331548e-06, 2.3832457372918725e-05, 0.0018293556058779359, 2.6111281840712763e-05, 3.3135143894469365e-05, 1.4612752238463145e-05, 0.000854729616548866, 0.00016745176981203258, 0.995307981967926, 0.0, 0.0, 0.0], [0.0022552241571247578, 0.00046477530850097537, 0.0001228374312631786, 0.006661206018179655, 8.828952559269965e-05, 0.00024942768504843116, 0.0001755515404511243, 2.6563478968455456e-05, 0.004149139393121004, 0.00020833070448134094, 1.597335358383134e-05, 0.0007248217007145286, 1.2318085282458924e-05, 0.004929243586957455, 0.0007067761616781354, 2.7460198907647282e-05, 0.0008252441766671836, 5.1487335440469906e-05, 9.107246114581358e-06, 0.00117019796743989, 0.0011320497142150998, 0.00038722759927622974, 0.00010000279144151136, 0.0005395386251620948, 0.0001279767748201266, 7.41870971978642e-05, 0.0006351852207444608, 5.991850048303604e-05, 0.00020302319899201393, 0.02264126017689705, 7.11138709448278e-05, 0.0034798544365912676, 0.9476746916770935, 0.0, 0.0], [0.00010488810949027538, 0.0005403983523137867, 0.0002700608456507325, 2.781992225209251e-05, 0.0008878528606146574, 0.0002531727368477732, 0.00029214046662673354, 0.000995146343484521, 3.9432117773685604e-05, 6.531640246976167e-05, 5.1983381126774475e-05, 0.0006716344505548477, 1.9524166418705136e-05, 3.796433884417638e-05, 0.00031547032995149493, 0.00015760336827952415, 0.0006809111800976098, 0.00017366735846735537, 0.00023275859712157398, 0.000493519997689873, 0.00015254231402650476, 8.968860493041575e-05, 0.0014225798659026623, 0.00022503072977997363, 0.00015392254863400012, 0.00010696907702367753, 0.005650238133966923, 0.000865322828758508, 0.0002874949714168906, 0.00013868501991964877, 1.4354158338392153e-05, 2.8161975933471695e-05, 0.00011612014350248501, 0.9844375848770142, 0.0], [0.001883037737570703, 0.0002301394852111116, 7.19053641660139e-05, 3.7982904359523673e-06, 0.0022563613019883633, 4.367973451735452e-05, 0.00012782943667843938, 0.0006368017056956887, 0.0005363993695937097, 5.325703114067437e-06, 7.917853508843109e-05, 2.6015983166871592e-05, 1.125325434259139e-05, 0.0005611245869658887, 9.10379003471462e-06, 0.00021052206284366548, 2.689109169295989e-05, 3.242435195716098e-05, 0.00025939318584278226, 0.00045266683446243405, 0.0011520986445248127, 1.149352829088457e-05, 4.8182344471570104e-05, 0.0001057150075212121, 8.452797192148864e-05, 0.000100208621006459, 2.848373151209671e-05, 2.041544757958036e-05, 1.8022971062237048e-06, 7.62895360821858e-05, 4.604330752044916e-05, 9.973573469324037e-05, 5.258398232399486e-06, 0.0001948850112967193, 0.9905609488487244]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9424744844436646, 0.05752559006214142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8506749868392944, 0.09740971028804779, 0.051915302872657776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7641513347625732, 0.10970375686883926, 0.07497038692235947, 0.051174528896808624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6748191714286804, 0.08416195213794708, 0.0547025091946125, 0.07581549882888794, 0.11050094664096832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6857606768608093, 0.08229531347751617, 0.052021171897649765, 0.08139175921678543, 0.04085882008075714, 0.05767223984003067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6174605488777161, 0.056534551084041595, 0.09111697971820831, 0.06854881346225739, 0.06338423490524292, 0.035969749093055725, 0.066985122859478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6047279834747314, 0.06088972091674805, 0.05921151116490364, 0.09558156132698059, 0.04265914857387543, 0.031843431293964386, 0.0426306426525116, 0.06245603412389755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4008437991142273, 0.0753358006477356, 0.04270840436220169, 0.01176072470843792, 0.02668057195842266, 0.013492080383002758, 0.02846546284854412, 0.01390059757977724, 0.38681259751319885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49680253863334656, 0.06792881339788437, 0.057920027524232864, 0.07101528346538544, 0.06963261216878891, 0.018800096586346626, 0.06757565587759018, 0.06346482783555984, 0.06656692922115326, 0.020293202251195908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5176078081130981, 0.08289015293121338, 0.05239764600992203, 0.06842363625764847, 0.046088285744190216, 0.026865946128964424, 0.08181484043598175, 0.03230835497379303, 0.05516275763511658, 0.018549634143710136, 0.01789088174700737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3038182258605957, 0.03185645490884781, 0.029157692566514015, 0.011053645983338356, 0.013536771759390831, 0.016536906361579895, 0.015181954950094223, 0.015511739067733288, 0.026294970884919167, 0.016891004517674446, 0.011886648833751678, 0.5082739591598511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3585989773273468, 0.07880906760692596, 0.05902862176299095, 0.044458650052547455, 0.07822324335575104, 0.019679531455039978, 0.05133118852972984, 0.040098413825035095, 0.08024682104587555, 0.027811912819743156, 0.010250612162053585, 0.1361035257577896, 0.015359451062977314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2511676549911499, 0.04623398557305336, 0.027838557958602905, 0.007056493312120438, 0.017244169488549232, 0.008997938595712185, 0.017309946939349174, 0.0099241454154253, 0.2527511417865753, 0.012778298929333687, 0.008546063676476479, 0.047919970005750656, 0.006098272744566202, 0.28613337874412537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.398007869720459, 0.06433820724487305, 0.049798548221588135, 0.05949560925364494, 0.0318211205303669, 0.03071472980082035, 0.05899549648165703, 0.05480390042066574, 0.03919371962547302, 0.03556447848677635, 0.024916458874940872, 0.04571932554244995, 0.016671661287546158, 0.0389430969953537, 0.05101581662893295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39033836126327515, 0.0754939466714859, 0.03844676911830902, 0.04366776719689369, 0.017820747569203377, 0.012712180614471436, 0.045307233929634094, 0.036030206829309464, 0.0421706885099411, 0.016753025352954865, 0.04224864020943642, 0.05092339962720871, 0.030772069469094276, 0.04072083160281181, 0.056488849222660065, 0.06010529026389122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1818235218524933, 0.018224790692329407, 0.01747790351510048, 0.006372255273163319, 0.007922586984932423, 0.01006288081407547, 0.008703155443072319, 0.01029747910797596, 0.015354439616203308, 0.011538184247910976, 0.007091044448316097, 0.3139554262161255, 0.0060198185965418816, 0.015887578949332237, 0.015422005206346512, 0.013188586570322514, 0.3406583368778229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2388143241405487, 0.07684367150068283, 0.04843555763363838, 0.02831975929439068, 0.04297622665762901, 0.01943075656890869, 0.033217206597328186, 0.027472950518131256, 0.01897592842578888, 0.04046749696135521, 0.02009560540318489, 0.058573175221681595, 0.035305727273225784, 0.019691888242959976, 0.097037672996521, 0.03909808769822121, 0.061994507908821106, 0.09324946254491806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35636118054389954, 0.04354538768529892, 0.054393719881772995, 0.03599719703197479, 0.055608708411455154, 0.03285681828856468, 0.019443828612565994, 0.06911691278219223, 0.020649444311857224, 0.033605340868234634, 0.027618737891316414, 0.034080009907484055, 0.02684745565056801, 0.020337311550974846, 0.022298933938145638, 0.03622739389538765, 0.03464473783969879, 0.022655019536614418, 0.053711891174316406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39670124650001526, 0.05178239569067955, 0.039961934089660645, 0.066307432949543, 0.04557184875011444, 0.023983409628272057, 0.019396748393774033, 0.02136596292257309, 0.020253783091902733, 0.036855828016996384, 0.009492042474448681, 0.041809991002082825, 0.014498688280582428, 0.01978372409939766, 0.02971523255109787, 0.046315472573041916, 0.04246639460325241, 0.031475216150283813, 0.022027641534805298, 0.02023506537079811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23151390254497528, 0.13258200883865356, 0.06026102975010872, 0.011383597739040852, 0.02426271326839924, 0.014553449116647243, 0.016979563981294632, 0.013957408256828785, 0.02247590199112892, 0.027721285820007324, 0.02060706540942192, 0.04084686189889908, 0.027723213657736778, 0.024550706148147583, 0.03857918456196785, 0.04770102724432945, 0.044071096926927567, 0.0772075280547142, 0.04604469612240791, 0.04773346334695816, 0.02924429625272751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20264171063899994, 0.04893086850643158, 0.03894680738449097, 0.026632271707057953, 0.040943484753370285, 0.01617504097521305, 0.043880145996809006, 0.04927309602499008, 0.037442922592163086, 0.01874796487390995, 0.010438330471515656, 0.030274199321866035, 0.011668822728097439, 0.03915899246931076, 0.08361910283565521, 0.026806527748703957, 0.03237596154212952, 0.026771074160933495, 0.04136867821216583, 0.04380553215742111, 0.09921549260616302, 0.03088301047682762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22999975085258484, 0.029275361448526382, 0.024823691695928574, 0.0307475458830595, 0.024439768865704536, 0.025078177452087402, 0.019048267975449562, 0.04161752015352249, 0.02524641901254654, 0.05536344274878502, 0.013840335421264172, 0.03206310421228409, 0.02337372675538063, 0.02689637430012226, 0.03765585273504257, 0.02870967984199524, 0.03498142585158348, 0.03826925903558731, 0.053048763424158096, 0.07750778645277023, 0.042357493191957474, 0.06297062337398529, 0.022685660049319267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2523007094860077, 0.04309260472655296, 0.047794319689273834, 0.021534807980060577, 0.05364761874079704, 0.014357613399624825, 0.016968196257948875, 0.012399843893945217, 0.02810794673860073, 0.022964568808674812, 0.013637283816933632, 0.03462430089712143, 0.013057569973170757, 0.029753560200333595, 0.025925684720277786, 0.03689543902873993, 0.0364658497273922, 0.02009117789566517, 0.03424844145774841, 0.0322706364095211, 0.07516521215438843, 0.03381401300430298, 0.05794452503323555, 0.04293809086084366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24815583229064941, 0.0418383851647377, 0.03725353628396988, 0.019914167001843452, 0.06031177192926407, 0.01376150269061327, 0.010237004607915878, 0.02711835876107216, 0.02124747820198536, 0.014996425248682499, 0.015956399962306023, 0.019741931930184364, 0.016942845657467842, 0.022782426327466965, 0.021159417927265167, 0.013419795781373978, 0.021131549030542374, 0.01588008925318718, 0.03851576894521713, 0.03509928286075592, 0.06386473774909973, 0.042158905416727066, 0.05595177412033081, 0.06510591506958008, 0.0574546717107296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24590620398521423, 0.03979460895061493, 0.034050021320581436, 0.038720108568668365, 0.02834436297416687, 0.024568283930420876, 0.013687249273061752, 0.019880935549736023, 0.017507946118712425, 0.04131212458014488, 0.024649059399962425, 0.017028072848916054, 0.015493784099817276, 0.01803990639746189, 0.028712527826428413, 0.008945342153310776, 0.017858801409602165, 0.02984653413295746, 0.02698221057653427, 0.0611925944685936, 0.03972144052386284, 0.04008689522743225, 0.04656379297375679, 0.04659208655357361, 0.046358171850442886, 0.0281569492071867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24299509823322296, 0.030936647206544876, 0.0372811034321785, 0.029979784041643143, 0.039518240839242935, 0.02068972960114479, 0.024463791400194168, 0.01616225577890873, 0.02351461350917816, 0.015184109099209309, 0.009779490530490875, 0.010400430299341679, 0.008830740116536617, 0.023988915607333183, 0.02441921830177307, 0.037842005491256714, 0.010589987970888615, 0.013367554172873497, 0.01626332476735115, 0.09984055161476135, 0.02563280425965786, 0.02790280431509018, 0.054687805473804474, 0.031704068183898926, 0.027479561045765877, 0.016517246142029762, 0.08002810180187225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24383296072483063, 0.021781543269753456, 0.019058484584093094, 0.026608381420373917, 0.03740561753511429, 0.027086623013019562, 0.0050316122360527515, 0.02665604092180729, 0.017429374158382416, 0.02866247668862343, 0.012150990776717663, 0.030223211273550987, 0.014068293385207653, 0.01816091127693653, 0.01543530635535717, 0.015721842646598816, 0.03215308114886284, 0.024973023682832718, 0.04793376848101616, 0.0459899939596653, 0.03119213879108429, 0.03841527923941612, 0.037881284952163696, 0.03472226858139038, 0.03550754487514496, 0.03336038440465927, 0.05460801348090172, 0.02394956350326538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.308788001537323, 0.04082433506846428, 0.010766160674393177, 0.02708975411951542, 0.019433287903666496, 0.03355547785758972, 0.010839528404176235, 0.01149556040763855, 0.011286415159702301, 0.019319292157888412, 0.03442363440990448, 0.01059587113559246, 0.01946372538805008, 0.011577973142266273, 0.014172402210533619, 0.021593410521745682, 0.010569154284894466, 0.01821252517402172, 0.007991211488842964, 0.05231863632798195, 0.019707778468728065, 0.03532519191503525, 0.029598264023661613, 0.028512977063655853, 0.021019764244556427, 0.018976135179400444, 0.031007949262857437, 0.017736954614520073, 0.10379863530397415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11270298808813095, 0.013211611658334732, 0.015115484595298767, 0.008062331937253475, 0.018075058236718178, 0.020267318934202194, 0.009121793322265148, 0.0216544046998024, 0.024600299075245857, 0.012220285832881927, 0.005230673588812351, 0.021195203065872192, 0.0075057619251310825, 0.0272400863468647, 0.01682899333536625, 0.0093071972951293, 0.023774148896336555, 0.009840184822678566, 0.023520387709140778, 0.018096182495355606, 0.11592709273099899, 0.008296087384223938, 0.015038424171507359, 0.016261843964457512, 0.022837147116661072, 0.007970291189849377, 0.010346011258661747, 0.013601286336779594, 0.00992316659539938, 0.3622281849384308, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19907140731811523, 0.02335296757519245, 0.027535507455468178, 0.020741207525134087, 0.04944240674376488, 0.0396454818546772, 0.011580482125282288, 0.03849606215953827, 0.012212718836963177, 0.012634869664907455, 0.018897859379649162, 0.011502718552947044, 0.014417962171137333, 0.012855133041739464, 0.015916291624307632, 0.009284356608986855, 0.011929106898605824, 0.014574812725186348, 0.029562367126345634, 0.030921468511223793, 0.0493488609790802, 0.02683301642537117, 0.033169783651828766, 0.026513919234275818, 0.03841781243681908, 0.03666592016816139, 0.03740687295794487, 0.037449177354574203, 0.0418136790394783, 0.040804993361234665, 0.02700081095099449, 0.0, 0.0, 0.0, 0.0], [0.1358085423707962, 0.021598204970359802, 0.028431449085474014, 0.0213667880743742, 0.03184177353978157, 0.02831076830625534, 0.011232441291213036, 0.016139332205057144, 0.02343672886490822, 0.025144262239336967, 0.012804518453776836, 0.012000495567917824, 0.02091226726770401, 0.025003299117088318, 0.027692247182130814, 0.017305929213762283, 0.01285973098129034, 0.016066303476691246, 0.03279000148177147, 0.03829028084874153, 0.0608048141002655, 0.03674997389316559, 0.03524733707308769, 0.038578007370233536, 0.03904813900589943, 0.03664340078830719, 0.014530439861118793, 0.021632274612784386, 0.010491003282368183, 0.06733929365873337, 0.03867286071181297, 0.041227128356695175, 0.0, 0.0, 0.0], [0.13088133931159973, 0.023744329810142517, 0.020114341750741005, 0.009702399373054504, 0.02695222571492195, 0.013591106049716473, 0.009517531841993332, 0.013271716423332691, 0.027617909014225006, 0.01149838138371706, 0.008886141702532768, 0.016865810379385948, 0.009971980936825275, 0.031318604946136475, 0.014953814446926117, 0.015636608004570007, 0.018755856901407242, 0.008822464384138584, 0.024258313700556755, 0.018599877133965492, 0.06659715622663498, 0.023935334756970406, 0.03021502122282982, 0.038479723036289215, 0.060547877103090286, 0.0388609804213047, 0.021039584651589394, 0.026919953525066376, 0.030786728486418724, 0.06339394301176071, 0.05302290990948677, 0.07499752938747406, 0.01624254137277603, 0.0, 0.0], [0.21679528057575226, 0.03523937985301018, 0.01448057871311903, 0.03231680765748024, 0.021502699702978134, 0.019766857847571373, 0.007716965861618519, 0.03142579272389412, 0.01142125204205513, 0.03985079005360603, 0.00569754745811224, 0.013826768845319748, 0.011217727325856686, 0.011028861626982689, 0.014342342503368855, 0.016691600903868675, 0.013800655491650105, 0.009054167196154594, 0.01655156910419464, 0.045164525508880615, 0.01674339547753334, 0.040494970977306366, 0.04600660502910614, 0.03918023034930229, 0.02077179029583931, 0.04241837561130524, 0.029444055631756783, 0.01654653437435627, 0.0433904305100441, 0.018028810620307922, 0.01749301142990589, 0.03195444867014885, 0.023179972544312477, 0.026455217972397804, 0.0], [0.12406572699546814, 0.05575518682599068, 0.025793109089136124, 0.007745689712464809, 0.019214725121855736, 0.011872398667037487, 0.009303722530603409, 0.015842609107494354, 0.012728426605463028, 0.012888251803815365, 0.013962885364890099, 0.01662725955247879, 0.01550710666924715, 0.0131952203810215, 0.017325090244412422, 0.02114798128604889, 0.01733550801873207, 0.015824293717741966, 0.02479436621069908, 0.011903030797839165, 0.03651026636362076, 0.023874737322330475, 0.04022136330604553, 0.06286033987998962, 0.10149350762367249, 0.05332258716225624, 0.021689629182219505, 0.018244286999106407, 0.008406993001699448, 0.02320230007171631, 0.04960416629910469, 0.02086932584643364, 0.01601797342300415, 0.011101940646767616, 0.049747928977012634]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10778003185987473, 0.8922199010848999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01184743270277977, 0.5536141395568848, 0.43453848361968994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06322261691093445, 0.02171914279460907, 0.09427288919687271, 0.820785403251648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005095742642879486, 0.0005348750273697078, 0.0010105489054694772, 0.004657563753426075, 0.9887012243270874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005585955921560526, 0.0003024001489393413, 0.0007955087930895388, 0.0006780325202271342, 0.028760099783539772, 0.9638779759407043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00026657318812794983, 0.0001539620861876756, 4.344211993156932e-05, 0.00031633899197913706, 0.007582378573715687, 0.008635704405605793, 0.9830015897750854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006940615130588412, 4.833174170926213e-05, 4.511346196522936e-05, 2.3520820832345635e-05, 0.0022377651184797287, 0.0012080521555617452, 0.00932135060429573, 0.9864218235015869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04771990701556206, 0.006346914917230606, 0.005507620982825756, 0.012776722200214863, 0.012552591040730476, 0.012200531549751759, 0.007760600186884403, 0.017114851623773575, 0.8780203461647034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.40378158702515e-05, 7.299120738935017e-07, 1.2948535186296795e-06, 1.004057139653014e-06, 1.519241322966991e-05, 3.609514533309266e-05, 3.151434430037625e-05, 0.0010808238293975592, 4.236837776261382e-05, 0.9986969828605652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002984422317240387, 1.0225188816548325e-05, 2.0773863070644438e-05, 1.0716744327510241e-05, 7.453822763636708e-05, 0.00016580548253841698, 0.0013668606989085674, 0.0025834820698946714, 5.024061829317361e-05, 0.3243952989578247, 0.6710236072540283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009233679622411728, 0.0007820429746061563, 0.0006810433696955442, 0.0018207874381914735, 0.004383386112749577, 0.017509128898382187, 0.003324248129501939, 0.0176074281334877, 0.08099661767482758, 0.10943026840686798, 0.014291892759501934, 0.7399395704269409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023930329189170152, 3.3237947718589567e-06, 2.2832813556306064e-05, 1.024476659949869e-05, 1.0253623258904554e-05, 4.496405381360091e-05, 2.357668745389674e-05, 6.216625479282811e-05, 0.00032929572626017034, 0.00874954555183649, 0.001878876704722643, 0.0014183479361236095, 0.9872072339057922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012295342981815338, 0.0005298616015352309, 0.00035605113953351974, 0.0006006713374517858, 0.0005327533581294119, 0.0005349713028408587, 0.00034733471693471074, 0.0008671165560372174, 0.034323085099458694, 0.013273628428578377, 0.0075311968103051186, 0.05941798537969589, 0.09377509355545044, 0.775614857673645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.850881229387596e-05, 1.1863348845508881e-05, 5.970536676613847e-06, 4.359465037850896e-06, 6.93304127707961e-06, 5.567320476984605e-05, 8.762012839724775e-06, 2.2130006982479244e-05, 0.0002223829651484266, 0.0002802500384859741, 0.0008127266191877425, 0.0015677284682169557, 0.000189563914318569, 0.005879407748579979, 0.9908537864685059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.475010301684961e-05, 8.603468813817017e-06, 3.744859213838936e-06, 1.4634196077167871e-07, 2.701744051591959e-06, 1.141736993304221e-05, 8.620831067673862e-06, 9.928114013746381e-05, 3.119510893156985e-06, 0.00022620811068918556, 0.0005323358927853405, 2.980489080073312e-05, 0.0013675655936822295, 5.107997640152462e-05, 0.009570839814841747, 0.9879898428916931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003944708965718746, 0.00013029153342358768, 9.94771980913356e-05, 0.00019776367116719484, 0.0004265847092028707, 0.0014889852609485388, 0.00028346848557703197, 0.0015356721123680472, 0.004810091573745012, 0.005567715968936682, 0.0010473597794771194, 0.040826570242643356, 0.009189032949507236, 0.09278513491153717, 0.01585300825536251, 0.02794087491929531, 0.7938733696937561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000217236447497271, 2.3531249098596163e-05, 7.806306712154765e-06, 4.732958132080967e-06, 1.567120762047125e-06, 8.667434485687409e-06, 1.264625825569965e-05, 6.12928852206096e-05, 0.00018869456835091114, 0.0005901302210986614, 0.0004205672303214669, 0.00097465276485309, 0.00042177739669568837, 0.004066713619977236, 0.001442243461497128, 0.011960028670728207, 0.022401951253414154, 0.9571956396102905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007360449526458979, 3.016829850821523e-06, 1.3554752058553277e-06, 1.4014691487318487e-06, 3.387712058611214e-05, 3.752295015146956e-05, 1.0748711247288156e-05, 0.0004302708839531988, 1.6196763681364246e-05, 0.0006748259766027331, 0.0005265927757136524, 0.0001240915444213897, 4.710721259471029e-05, 0.00024138184380717576, 0.0006886586197651923, 0.00038702096207998693, 0.002144157886505127, 0.0017651681555435061, 0.9921305775642395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.529802703880705e-06, 4.013182230977463e-09, 4.275874321280071e-09, 9.052371297002537e-09, 5.135171932124649e-07, 3.731759534275625e-06, 1.4824270522240113e-07, 4.6551231207558885e-06, 1.663049964406582e-08, 3.029677600352443e-06, 3.191981159034185e-05, 1.401741371864773e-07, 4.954928840561479e-07, 2.3671073279274424e-07, 7.952932605803653e-07, 0.00018607274978421628, 2.4466733066219604e-06, 1.1982298929069657e-05, 0.0005082334391772747, 0.9992390871047974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009417888708412647, 0.00017362425569444895, 0.0001959324290510267, 0.00010542469681240618, 0.00012100115418434143, 0.0001375036663375795, 0.00020822316582780331, 0.00026208782219327986, 0.0009803813882172108, 0.00017425179248675704, 0.0013313929084688425, 0.003277308540418744, 0.0048406231217086315, 0.012378795072436333, 0.0018258992349728942, 0.024282047525048256, 0.05479966849088669, 0.07428489625453949, 0.07759265601634979, 0.10845336318016052, 0.6251571178436279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001788632944226265, 2.9717880352109205e-06, 1.287924305870547e-06, 1.661971055000322e-06, 3.153397528876667e-06, 7.608554369653575e-06, 4.4805673837799986e-07, 4.628855549526634e-06, 4.462080141820479e-06, 4.640815859602299e-06, 4.678133336710744e-06, 2.2255193471210077e-05, 0.000688504078425467, 5.880861499463208e-05, 5.511297786142677e-05, 0.0013147693825885653, 0.0004210416809655726, 0.000527929631061852, 0.00030591568793170154, 0.0011363036464899778, 0.004935148172080517, 0.9903199076652527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0009000818245112896, 3.46090855600778e-05, 6.00008161200094e-06, 1.3317902585185948e-06, 8.382407031604089e-06, 7.950188773975242e-06, 8.352956228918629e-07, 5.017455350753153e-06, 1.1085563528467901e-05, 1.5506169802392833e-05, 2.244969073217362e-05, 3.2394586014561355e-05, 7.153382466640323e-05, 0.00011106140300398692, 6.552063041453948e-06, 3.557855961844325e-05, 0.00046084230416454375, 0.0006021021399646997, 0.00773558858782053, 0.0047313859686255455, 0.012920131906867027, 0.0169991385191679, 0.9552805423736572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.094528311630711e-05, 5.4195348639041185e-05, 2.1191086489125155e-05, 8.660334174237505e-07, 5.241397047939245e-06, 2.811412286973791e-06, 9.647682190916385e-07, 4.259624347469071e-06, 6.819966074544936e-06, 2.6370105388195952e-06, 1.038735263136914e-05, 3.11777948809322e-05, 2.574707286839839e-05, 8.829366561258212e-05, 0.0001053006635629572, 0.0003744478744920343, 0.0005833793547935784, 0.0009019345161505044, 0.00043120188638567924, 0.004991129040718079, 0.003515928518027067, 0.015127496793866158, 0.018385041505098343, 0.9552487730979919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00019926734967157245, 5.897880441807501e-07, 4.093079439826397e-07, 5.283635005071119e-07, 4.043731394176575e-07, 6.811440016463166e-07, 2.5019514282575983e-07, 3.190987456491712e-07, 5.018005595047725e-06, 3.059930349991191e-06, 4.776866262545809e-06, 8.106227141979616e-06, 1.787102701200638e-05, 5.904932550038211e-05, 7.019496479188092e-06, 5.101937131257728e-05, 0.0001541965757496655, 0.0001555776543682441, 0.0004630949115380645, 0.00018736706988420337, 0.0029354498255997896, 0.00699869217351079, 0.004895060323178768, 0.010302471928298473, 0.9735496640205383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.041891952510923e-05, 7.668172763430903e-09, 6.183981327012589e-08, 4.109946871722059e-08, 3.1613390660822915e-07, 1.0004030315258206e-07, 6.658518003632707e-08, 4.780262656822742e-07, 4.035145551029018e-08, 6.753236448275857e-06, 8.574267695848903e-08, 1.0514231973957067e-07, 3.270276693001506e-06, 4.896545533483732e-07, 1.2450341273506638e-06, 9.069827683561016e-06, 2.0693112219305476e-06, 8.541710485587828e-06, 4.5136250264476985e-05, 8.52817902341485e-05, 8.47626943141222e-05, 0.0010267914040014148, 0.001334777451120317, 0.00029600723064504564, 0.0056267851032316685, 0.9914274215698242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003747466835193336, 1.2430140827746072e-07, 2.5229209654753504e-07, 3.052446118090302e-07, 4.772530246555107e-06, 6.075460419197043e-07, 8.50173705657653e-07, 1.1030846508219838e-05, 8.098998449668215e-08, 9.651313348513213e-07, 7.193358442236786e-07, 3.2339411859538814e-07, 1.760547775120358e-06, 4.446830530469015e-07, 3.298762862868898e-07, 2.4300346922245808e-05, 3.6642684335674858e-06, 3.0616458843724104e-06, 2.627130743348971e-05, 0.00034267170121893287, 2.078816032735631e-05, 0.00013409749954007566, 0.000304724439047277, 9.803617285797372e-05, 0.0004919689381495118, 0.004237073939293623, 0.9939160943031311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023197678092401475, 7.363636882473656e-07, 1.0658059181878343e-06, 4.7497985633526696e-07, 2.187789050367428e-06, 2.074172016364173e-06, 1.384211998356477e-07, 2.51064807343937e-06, 1.9716030408289953e-07, 6.672007202723762e-06, 8.991812592284987e-07, 6.362203635035257e-07, 6.544809139086283e-07, 7.71796749177156e-07, 4.801893851436034e-07, 1.112231893785065e-05, 5.561920261243358e-06, 3.862761786876945e-06, 6.753717025276273e-05, 0.0002897954545915127, 4.372503826743923e-05, 0.00015209027333185077, 0.0009337739902548492, 0.0001815940486267209, 8.423312101513147e-05, 0.009933865629136562, 0.008723159320652485, 0.979318380355835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00015704902762081474, 3.123183773823257e-07, 2.931928975158371e-07, 3.137148496534792e-07, 2.1960925096209394e-06, 1.4164401136440574e-06, 1.123638185163145e-06, 1.3091762411931995e-06, 5.9215043535232326e-08, 7.978067628755525e-07, 2.803677261908888e-06, 1.9766923742281506e-07, 3.994018413777667e-07, 2.3048994535201928e-07, 2.264246631966671e-06, 1.6729463823139668e-05, 1.6667603404130205e-06, 2.8725414722430287e-06, 2.494689942977857e-05, 0.00025532764266245067, 4.849691322306171e-06, 4.708057167590596e-05, 5.325666279532015e-05, 4.240333873894997e-05, 0.00020874859183095396, 0.0020438090432435274, 0.08346706628799438, 0.003672999795526266, 0.9099873900413513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010030753910541534, 7.605907740071416e-06, 5.47890385860228e-06, 4.704082584794378e-06, 1.08182439362281e-06, 7.24684241504292e-07, 6.057198334019631e-07, 1.5847817849135026e-06, 3.1830979423830286e-05, 1.844483222157578e-06, 1.3723778238272644e-06, 6.841019512648927e-06, 4.9961122385866474e-06, 0.00014220463344827294, 2.1025923615525244e-06, 2.0461138774408028e-05, 6.875459075672552e-05, 8.339442138094455e-05, 7.060819916659966e-05, 0.0002227002987638116, 0.0013453519204631448, 0.0011953136418014765, 0.0007637701346538961, 0.003412768244743347, 0.009595143608748913, 0.008245961740612984, 0.004028412979096174, 0.015673460438847542, 0.03710905462503433, 0.916948676109314, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014598063717130572, 1.3442448221212544e-07, 3.0679643714393023e-07, 1.2700814977506525e-07, 9.539689216353509e-08, 4.421364963036467e-08, 7.2709593901265634e-09, 2.16305849676246e-07, 1.7861790979623038e-07, 1.1440969416298685e-07, 4.546686227513419e-08, 1.1406672228986281e-07, 1.7846296884727053e-07, 8.568714520151843e-07, 1.0497461744307657e-07, 1.2474922641558805e-06, 1.168266066997603e-06, 6.485002472800261e-07, 9.923046491167042e-06, 2.663560189830605e-05, 2.1481033400050364e-05, 7.19235249562189e-05, 0.00015873301890678704, 0.00014563217700924724, 0.0024261672515422106, 0.001514493953436613, 0.0007063172524794936, 0.0022442839108407497, 0.004566811490803957, 0.00983233842998743, 0.9781237244606018, 0.0, 0.0, 0.0, 0.0], [1.0698774531192612e-05, 5.128419644506721e-08, 7.382501365782446e-08, 9.797496858254817e-08, 4.94486982915987e-07, 6.269730761232495e-07, 2.625734509820177e-07, 7.36192021122406e-07, 2.5101189748966135e-07, 2.176487896576873e-06, 5.36374670900841e-07, 8.60690761328442e-07, 2.151581099951727e-07, 1.0358829740653164e-06, 2.489502151092893e-07, 1.3481044334184844e-05, 8.521074960299302e-06, 5.148507170815719e-06, 4.645082753995666e-06, 1.683262780716177e-05, 5.8646506658988073e-05, 3.652455779956654e-05, 0.00016485729429405183, 1.1945001460844651e-05, 0.0005173994577489793, 0.0024279053322970867, 0.00034773541847243905, 0.0015964063350111246, 0.009022926911711693, 0.013163723051548004, 0.06333820521831512, 0.9092468023300171, 0.0, 0.0, 0.0], [0.0012287310091778636, 8.407658242504112e-06, 8.363959750568029e-06, 8.199026524380315e-06, 3.972178546973737e-06, 3.9872684283182025e-06, 1.5942541722324677e-06, 4.764995537698269e-06, 4.4619187065109145e-06, 8.699215868546162e-06, 3.48229764313146e-06, 4.087222805537749e-06, 4.383185569167836e-06, 1.2878697816631757e-05, 2.764999408100266e-06, 1.1550821000128053e-05, 2.8508404284366407e-05, 1.972618883883115e-05, 8.007970609469339e-05, 0.0001638159592403099, 0.0002766103425528854, 0.00048299774061888456, 0.0005903018172830343, 0.001175062032416463, 0.003466710913926363, 0.005802723579108715, 0.011907556094229221, 0.01695297285914421, 0.028466513380408287, 0.06137575954198837, 0.11517595499753952, 0.20177732408046722, 0.5509370565414429, 0.0, 0.0], [3.782525527640246e-05, 6.459638512978927e-08, 1.927358184161676e-08, 7.975797444714772e-08, 6.700330459352699e-07, 1.2464336407447263e-07, 3.072165100093116e-08, 3.3671460641926387e-07, 9.953986790378622e-08, 4.5415069394039165e-07, 3.406016446660942e-08, 1.7256121509490185e-07, 3.3590222869861464e-07, 3.2563309559918707e-07, 1.1636584140717332e-08, 3.2042096336226678e-06, 1.2533513427115395e-06, 1.7663038534010411e-06, 1.112595055019483e-05, 2.0410294382600114e-05, 8.103424079308752e-06, 1.2881071597803384e-05, 0.00014193193055689335, 1.1411083505663555e-05, 0.00010671326890587807, 0.00010951125295832753, 0.0017927117878571153, 0.0015404942678287625, 0.0012465205509215593, 0.001597587252035737, 0.0008927029557526112, 0.009557013399899006, 0.009279937483370304, 0.9736242294311523, 0.0], [0.0003539699246175587, 2.6440395686222473e-06, 1.7576170421307324e-06, 1.2348089057923062e-06, 5.949707428953843e-06, 1.309189087805862e-06, 3.3621091688473825e-07, 2.4850550062183174e-07, 6.705465125378396e-07, 6.699529819798045e-08, 6.061921453692776e-07, 4.6190618263608485e-07, 2.357329321966972e-06, 1.4622188473367714e-06, 2.976372002194694e-07, 1.6005818679332151e-06, 2.460905989210005e-06, 1.931721726577962e-06, 3.200153514626436e-05, 2.465201214363333e-05, 3.429644129937515e-05, 0.00016550871077924967, 7.883973012212664e-05, 0.00018387162708677351, 0.0011651529930531979, 0.00012255363981239498, 0.0011725217336788774, 0.0004984794650226831, 0.003501484403386712, 0.003400748362764716, 0.01183952484279871, 0.005179092288017273, 0.016713876277208328, 0.0291277002543211, 0.9263802766799927]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9238101243972778, 0.07618984580039978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37589243054389954, 0.10050596296787262, 0.5236016511917114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.41213729977607727, 0.0823158249258995, 0.1808476597070694, 0.32469916343688965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1405227929353714, 0.005812313407659531, 0.02827640250325203, 0.05733036249876022, 0.768058180809021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019230686128139496, 0.0014746804954484105, 0.0016810785746201873, 0.004905834794044495, 0.02590656280517578, 0.9468011260032654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006040878128260374, 0.0046582273207604885, 0.012865055352449417, 0.008953898213803768, 0.07021685689687729, 0.12025348842144012, 0.7770116925239563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01624826155602932, 0.003929380793124437, 0.012836656533181667, 0.005099628586322069, 0.01735418289899826, 0.01559932716190815, 0.1360277235507965, 0.7929048538208008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13423283398151398, 0.07014793902635574, 0.03862922266125679, 0.035926904529333115, 0.05720481649041176, 0.06419362872838974, 0.03908977285027504, 0.2145734578371048, 0.34600141644477844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003595878602936864, 0.00038495013723149896, 0.0004921666695736349, 0.0008088786853477359, 0.0025900965556502342, 0.002407651860266924, 0.0001713183446554467, 0.011153006926178932, 0.0021147800143808126, 0.9762812852859497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00022834500123281032, 4.6662524255225435e-05, 8.206470374716446e-05, 7.730659854132682e-05, 0.00012034244718961418, 0.004319248721003532, 0.0038442215882241726, 0.0011964994482696056, 0.00016446932568214834, 0.8530564308166504, 0.13686434924602509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06578908115625381, 0.01929076574742794, 0.020492710173130035, 0.021956786513328552, 0.026686685159802437, 0.08618338406085968, 0.031040921807289124, 0.16103026270866394, 0.030162539333105087, 0.2132367640733719, 0.07554478198289871, 0.24858534336090088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009123365394771099, 0.0033993141259998083, 0.016818273812532425, 0.0046488139778375626, 0.014602283015847206, 0.05833256617188454, 0.07909013330936432, 0.01766362227499485, 0.016087274998426437, 0.15053576231002808, 0.3343389630317688, 0.054388951510190964, 0.24097071588039398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04253435507416725, 0.01655057817697525, 0.007813412696123123, 0.006833461578935385, 0.009650957770645618, 0.009173310361802578, 0.005910305771976709, 0.030093098059296608, 0.05324171483516693, 0.035758912563323975, 0.11968681961297989, 0.07133747637271881, 0.2969222068786621, 0.2944934368133545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010158021003007889, 0.004377414006739855, 0.0065031819976866245, 0.003546682884916663, 0.006157048046588898, 0.0051498133689165115, 0.0041582416743040085, 0.014994010329246521, 0.017724109813570976, 0.00860963761806488, 0.013557267375290394, 0.027689799666404724, 0.027776118367910385, 0.08518608659505844, 0.7644126415252686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005760948988609016, 3.758495586225763e-05, 3.100582762272097e-05, 2.8090938940295018e-05, 0.00011757250467780977, 0.0010626517469063401, 0.0008489806205034256, 0.0023644352331757545, 0.00031711836345493793, 0.000504071416798979, 0.0005438976222649217, 0.000996467424556613, 0.004787209909409285, 0.0016582176322117448, 0.021181173622608185, 0.964945375919342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.057101089507341385, 0.012982717715203762, 0.01246335543692112, 0.012371198274195194, 0.013064750470221043, 0.03530249372124672, 0.013208809308707714, 0.06362835317850113, 0.01058889739215374, 0.06113199144601822, 0.027357177808880806, 0.08200794458389282, 0.039974600076675415, 0.043028347194194794, 0.06893422454595566, 0.06733895093202591, 0.3795151114463806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05038188025355339, 0.010253245010972023, 0.009017400443553925, 0.007853329181671143, 0.008382106199860573, 0.016030551865696907, 0.007579755503684282, 0.016568155959248543, 0.009558070451021194, 0.020098434761166573, 0.028027689084410667, 0.031728412955999374, 0.021793978288769722, 0.03942330181598663, 0.11988720297813416, 0.047830890864133835, 0.14773690700531006, 0.4078487157821655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009583805687725544, 0.0005122209549881518, 0.0006106940563768148, 0.0009717896464280784, 0.0022611061576753855, 0.004041271284222603, 0.0003397607943043113, 0.002301486674696207, 0.0014669836964458227, 0.004360882565379143, 0.010039575397968292, 0.003883794415742159, 0.0019065389642491937, 0.004968372173607349, 0.0035998853854835033, 0.0027956583071500063, 0.01562882587313652, 0.014497026801109314, 0.916230320930481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03377579152584076, 0.0008472931804135442, 0.000936156720854342, 0.0006967569352127612, 0.004600144922733307, 0.0032576010562479496, 0.0004218367685098201, 0.007556708063930273, 0.0010570590384304523, 0.003643788630142808, 0.00017823856614995748, 0.0020456223282963037, 0.0014812115114182234, 0.002918048994615674, 0.005684820935130119, 0.06616660207509995, 0.00682071503251791, 0.005966112483292818, 0.022306203842163086, 0.8296393752098083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014338111504912376, 0.004506281577050686, 0.0022934828884899616, 0.004502632189542055, 0.006348527502268553, 0.006440699566155672, 0.0030759212095290422, 0.0034293788485229015, 0.008825041353702545, 0.013563876040279865, 0.008806232362985611, 0.01533306110650301, 0.01093036774545908, 0.03256243094801903, 0.041650138795375824, 0.029358427971601486, 0.06823208928108215, 0.10101231187582016, 0.1282440423965454, 0.08141806721687317, 0.41512882709503174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01251694094389677, 0.0037073830608278513, 0.0011323611252009869, 0.002044015796855092, 0.0021037994883954525, 0.0007217561942525208, 0.0003587713581509888, 0.0010654578218236566, 0.0033418689854443073, 0.0035347735974937677, 0.0018008295446634293, 0.005131382495164871, 0.005956846754997969, 0.01168146263808012, 0.023353146389126778, 0.024626368656754494, 0.023082589730620384, 0.02405393123626709, 0.045054007321596146, 0.0444747693836689, 0.09848438203334808, 0.6617730855941772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023378070443868637, 0.0029700917657464743, 0.0022721646819263697, 0.003121253103017807, 0.010448778979480267, 0.002795709762722254, 0.0009500709129497409, 0.006640288978815079, 0.0025093008298426867, 0.006215895060449839, 0.001875662594102323, 0.004366472829133272, 0.005894929636269808, 0.007904242724180222, 0.011842518113553524, 0.011780311353504658, 0.016934016719460487, 0.015606734901666641, 0.03699193149805069, 0.0567626990377903, 0.03885180875658989, 0.301069051027298, 0.4288180470466614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04225083813071251, 0.009647667407989502, 0.013069665990769863, 0.003493925556540489, 0.008718243800103664, 0.000871763622853905, 0.002113071270287037, 0.002520156092941761, 0.0028259288519620895, 0.003056257264688611, 0.005475991405546665, 0.004467588383704424, 0.005966207478195429, 0.008145663887262344, 0.02767091430723667, 0.01338263601064682, 0.01818913035094738, 0.03278025612235069, 0.028848372399806976, 0.05995951220393181, 0.09605942666530609, 0.20931926369667053, 0.10138265788555145, 0.2997848689556122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02581801638007164, 0.0012453029630705714, 0.0012367713497951627, 0.0031558219343423843, 0.0026054559275507927, 0.0011178313288837671, 0.00023053240147419274, 0.0010614547645673156, 0.0012552998960018158, 0.001447018003091216, 0.0006083032349124551, 0.0021444344893097878, 0.0017222744645550847, 0.003063677344471216, 0.002130713313817978, 0.0017395151080563664, 0.00748956436291337, 0.004201174713671207, 0.016367286443710327, 0.017187530174851418, 0.016647029668092728, 0.06787320226430893, 0.07546126842498779, 0.04369649291038513, 0.7004940509796143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0075083100236952305, 0.00012913934187963605, 0.00022904042270965874, 0.0003099401656072587, 0.0015875755343586206, 0.00015740832895971835, 0.00036546686897054315, 0.00026319536846131086, 0.00024618778843432665, 0.004963850136846304, 0.0008493296336382627, 0.0002054251090157777, 0.0035996607039123774, 0.0006757518276572227, 0.0006743196863681078, 0.0028660367242991924, 0.0007401995826512575, 0.0012410671915858984, 0.0034339376725256443, 0.003348805010318756, 0.005896297283470631, 0.015315240249037743, 0.01358444057404995, 0.003806075546890497, 0.10587518662214279, 0.8221280574798584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0151468301191926, 0.0002837271895259619, 0.00043238894431851804, 0.0012392138596624136, 0.0026600719429552555, 0.0003459543804638088, 0.0002954268711619079, 0.001877208356745541, 0.00023691265960223973, 0.00013219252286944538, 0.00033548095962032676, 0.00022997907944954932, 0.00027149065863341093, 0.0004209536127746105, 0.0008192582754418254, 0.0003039469593204558, 0.0006469368236139417, 0.0003804269654210657, 0.00239259609952569, 0.002976801944896579, 0.0025756140239536762, 0.005941803101450205, 0.005901214201003313, 0.005208784248679876, 0.025423727929592133, 0.02324126847088337, 0.900279700756073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020882179960608482, 0.0006866250187158585, 0.001419030362740159, 0.0016247222665697336, 0.00546672660857439, 0.0019930703565478325, 0.00034445628989487886, 0.0014866319252178073, 0.00038602776476182044, 0.00029868001001887023, 0.0003715484926942736, 0.0005332499858923256, 0.0002567081246525049, 0.0006083347252570093, 0.0003786252054851502, 0.0013748225755989552, 0.0013781345915049314, 0.0009236660553142428, 0.023375004529953003, 0.03773234412074089, 0.004063981585204601, 0.021846620365977287, 0.018512384966015816, 0.005047200247645378, 0.01844027452170849, 0.06399491429328918, 0.3300280272960663, 0.4365460276603699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002729788888245821, 0.00011315739538986236, 0.0002574324607849121, 0.0003065295168198645, 0.0008012377074919641, 0.0008870939491316676, 0.00010111577284988016, 0.00204857112839818, 0.0001429120748071, 0.00019898073514923453, 0.00043098212336190045, 7.435750012518838e-05, 0.00011077819362981245, 0.00022297582472674549, 0.00010400119208497927, 0.0007566186832264066, 0.00018428826297167689, 0.0003102096379734576, 0.001059030182659626, 0.005394389387220144, 0.00137113977689296, 0.0017238217405974865, 0.0034383495803922415, 0.0007791540119796991, 0.0027107964269816875, 0.011246615089476109, 0.2618618905544281, 0.042864661663770676, 0.6577690839767456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0071692136116325855, 0.0026512283366173506, 0.0024450235068798065, 0.003023248864337802, 0.00268618855625391, 0.0007135469932109118, 0.0005127678159624338, 0.0003864858590532094, 0.0009532009717077017, 0.0004407844680827111, 0.0008591745281592011, 0.0012491042725741863, 0.0009424769668839872, 0.0016617258079349995, 0.0004435316368471831, 0.0014648408396169543, 0.0035774623975157738, 0.003767341608181596, 0.012122927233576775, 0.0068539101630449295, 0.0052495673298835754, 0.019704235717654228, 0.02666923776268959, 0.04096020758152008, 0.2385396957397461, 0.05725710466504097, 0.04040537402033806, 0.10933990776538849, 0.0773630142211914, 0.3305874466896057, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011626659892499447, 0.001965817529708147, 0.000917952274903655, 0.001819743076339364, 0.002078979043290019, 0.00029357121093198657, 0.00010028555698227137, 0.0005799980135634542, 0.0004854121943935752, 9.76483934209682e-05, 0.00015712760796304792, 0.0004106423002667725, 0.0004877776955254376, 0.0007517863996326923, 0.0007532844902016222, 0.0012242123484611511, 0.0010826843790709972, 0.0014821900986135006, 0.002774250227957964, 0.003610333427786827, 0.0021372432820498943, 0.009361447766423225, 0.014277669601142406, 0.011846723966300488, 0.04729338735342026, 0.0450628437101841, 0.041560713201761246, 0.0428079329431057, 0.07079776376485825, 0.10084827989339828, 0.581305742263794, 0.0, 0.0, 0.0, 0.0], [0.003873431822285056, 0.0002557096304371953, 0.0006259246729314327, 0.000584396009799093, 0.0012326475698500872, 0.0003945602220483124, 0.0003326675796415657, 0.0001558193762321025, 0.0001647270837565884, 0.0007726293406449258, 0.00038669799687340856, 0.00027824443532153964, 0.00015239720232784748, 0.0002519854169804603, 6.452928209910169e-05, 0.00017264121561311185, 0.0007133580511435866, 0.0005384793621487916, 0.007539559621363878, 0.006723249331116676, 0.0013963916571810842, 0.003110351273790002, 0.005501286126673222, 0.0024135862477123737, 0.03896055370569229, 0.02342233993113041, 0.009641132317483425, 0.0257509034126997, 0.1270248144865036, 0.04005927965044975, 0.5142089128494263, 0.183296799659729, 0.0, 0.0, 0.0], [0.015151121653616428, 0.0013760682195425034, 0.0015560504980385303, 0.002171708969399333, 0.0025110088754445314, 0.0017854946199804544, 0.0004700868739746511, 0.0006788124446757138, 0.00038990736356936395, 0.0009900371078401804, 0.00038026581751182675, 0.0004182498960290104, 0.00044352930854074657, 0.0005140133434906602, 0.000165922348969616, 0.0006932562100701034, 0.000962950405664742, 0.0007656950037926435, 0.004365225322544575, 0.006436270661652088, 0.0018688273848965764, 0.008356152102351189, 0.006384757813066244, 0.005890711210668087, 0.03118702583014965, 0.04100947082042694, 0.02856607548892498, 0.0415772907435894, 0.04076455533504486, 0.06712847948074341, 0.30426734685897827, 0.2161882370710373, 0.1645854264497757, 0.0, 0.0], [0.017354115843772888, 0.0005264719948172569, 0.0006208931445144117, 0.0016926320968195796, 0.006297261919826269, 0.0010202121920883656, 7.362554606515914e-05, 0.0006762278499081731, 0.0004448314430192113, 7.778885628795251e-05, 4.973802424501628e-05, 0.0003035981208086014, 0.00017341793864034116, 0.0005162438028492033, 0.0002735278394538909, 0.0007444005459547043, 0.000602221698500216, 0.00045445014256983995, 0.002665338572114706, 0.0026638759300112724, 0.0025515947490930557, 0.007818799465894699, 0.009490985423326492, 0.000983040896244347, 0.007624232675880194, 0.011552365496754646, 0.09579716622829437, 0.08069906383752823, 0.09889815747737885, 0.037996113300323486, 0.05835621803998947, 0.11718904227018356, 0.11656814068555832, 0.31724417209625244, 0.0], [0.01079633366316557, 0.0030184623319655657, 0.0017010803567245603, 0.0027613984420895576, 0.005546445958316326, 0.0005509479669854045, 0.0002220834867330268, 0.00023305877402890474, 0.0008555078529752791, 8.429398440057412e-05, 0.00013491032586898655, 0.000403034093324095, 0.00021568548982031643, 0.0009122331975959241, 0.0007261995924636722, 0.0003818847762886435, 0.0007406800868920982, 0.0007301227888092399, 0.0007852280396036804, 0.0013473378494381905, 0.004313782323151827, 0.007729175500571728, 0.005422806367278099, 0.0067470804788172245, 0.013981981202960014, 0.004630994983017445, 0.01939181052148342, 0.02813369780778885, 0.016861913725733757, 0.07724324613809586, 0.05435158312320709, 0.13139021396636963, 0.15014058351516724, 0.08434385061264038, 0.3631702959537506]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1932608187198639, 0.8067392110824585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09132359176874161, 0.002221881179139018, 0.9064545035362244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07127517461776733, 0.010394562967121601, 0.014608713798224926, 0.9037216305732727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00752516184002161, 8.942761633079499e-05, 7.544131221948192e-05, 3.413583499423112e-06, 0.9923065304756165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004521056544035673, 4.2805095290532336e-06, 9.230424620909616e-05, 2.3636299374629743e-05, 1.1194422768312506e-05, 0.9953475594520569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00793814193457365, 0.00010465264494996518, 4.1882482037181035e-05, 8.376296136702877e-06, 0.00021111464593559504, 3.129790229650098e-06, 0.9916926622390747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0024528508074581623, 1.0800506970554125e-05, 1.5410754713229835e-05, 2.2521547293763433e-07, 3.9251284761121497e-05, 5.1336105570953805e-06, 2.3800499548087828e-05, 0.9974525570869446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1994483917951584, 0.17831814289093018, 0.06548024713993073, 0.13276459276676178, 0.03858451172709465, 0.010353409685194492, 0.021433597430586815, 0.006723289843648672, 0.34689387679100037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014458474470302463, 8.054711315708118e-07, 3.064588599954732e-05, 7.412928084704618e-07, 2.0274044345569564e-06, 1.1259045095357578e-05, 1.8223396409666748e-06, 8.012940816115588e-05, 1.056965501788909e-07, 0.9984266757965088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002338015241548419, 1.2498665455495939e-05, 2.2450083633884788e-05, 4.236496351950336e-06, 2.952029092284647e-07, 1.8947017679238343e-06, 7.769844523863867e-05, 8.96904748515226e-06, 4.6951914356441193e-08, 1.1347646022841218e-06, 0.9975327253341675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.047514572739601135, 0.05268261581659317, 0.020408116281032562, 0.0585300549864769, 0.0071665639989078045, 0.008201424032449722, 0.01184640172868967, 0.0017474382184445858, 0.024963321164250374, 0.0026972556952387094, 0.0014261910691857338, 0.7628160715103149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006070810370147228, 0.0001295793626923114, 5.943352516624145e-05, 5.6593567023810465e-06, 0.00026153295766562223, 0.00012241856893524528, 1.0399356142443139e-05, 1.1076404007326346e-05, 4.060484855017421e-07, 0.0003600475611165166, 2.011545075220056e-05, 1.3643935403706564e-07, 0.9929484128952026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09530564397573471, 0.14180324971675873, 0.050381824374198914, 0.10299669951200485, 0.02981209009885788, 0.0065894112922251225, 0.01682439260184765, 0.004481852985918522, 0.23106449842453003, 0.019435428082942963, 0.01087439525872469, 0.05543200671672821, 0.035438716411590576, 0.1995597779750824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027447829023003578, 0.00014065347204450518, 0.0001984664995688945, 3.49676665791776e-05, 5.282148777041584e-06, 0.00015024204913061112, 8.128349873004481e-05, 1.21251378004672e-05, 6.303894042503089e-05, 6.543214112753049e-05, 2.8324877803243e-06, 3.890726657118648e-05, 5.673631449099048e-07, 4.210483166389167e-05, 0.9717161655426025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004212117288261652, 3.0696890462422743e-05, 6.369442417053506e-05, 8.254564818344079e-07, 8.262140909209847e-07, 3.86834581149742e-05, 4.268815246177837e-06, 3.81940662919078e-06, 1.262802555856979e-07, 0.00013782763562630862, 1.7806130927056074e-05, 1.7100234117606306e-08, 5.979883553663967e-06, 6.190309420617268e-08, 2.2941594579606317e-06, 0.9954808950424194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019846780225634575, 0.03168344125151634, 0.012553277425467968, 0.03571881353855133, 0.0043990155681967735, 0.0043505714274942875, 0.00742737203836441, 0.0009372890344820917, 0.01266288198530674, 0.001605055294930935, 0.0007319959113374352, 0.4563407897949219, 0.00201086956076324, 0.009759278036653996, 0.008237503468990326, 0.00025941262720152736, 0.3914756774902344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027297209948301315, 0.0024357072543352842, 0.0002706822706386447, 7.525584078393877e-05, 1.3686860256711952e-05, 5.773238626716193e-06, 0.0004301840381231159, 1.443816927348962e-05, 4.835141226067208e-05, 5.326117025106214e-05, 9.613328074919991e-06, 6.846700853202492e-05, 0.0003037679416593164, 2.878391751437448e-05, 3.866398037644103e-05, 2.5926818125299178e-05, 4.6800560085102916e-05, 0.9688335061073303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006310693453997374, 3.294685302535072e-05, 9.895686162053607e-06, 7.334584211093897e-07, 9.119841706706211e-05, 4.094936957699247e-05, 8.511712621839251e-06, 9.950702224159613e-05, 1.9264814454800216e-07, 8.829226771922549e-07, 1.890608700705343e-06, 1.1808706403826363e-06, 3.1165191103355028e-06, 9.47476834767258e-08, 3.301757942608674e-06, 2.585525180620607e-05, 7.711307148383639e-07, 2.6708685254561715e-06, 0.993365466594696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011340517085045576, 6.961923190829111e-06, 1.2364388567220885e-05, 4.006550682333909e-07, 5.351815343601629e-05, 5.240096470515709e-06, 4.459505726117641e-05, 0.00016450765542685986, 1.4344478493910628e-08, 1.0388021109974943e-06, 4.77888788736891e-05, 5.0586844935196495e-08, 9.468209896112967e-07, 7.475676966350875e-09, 6.603928000004089e-07, 3.843115337076597e-06, 3.346431753925572e-08, 2.411975685845391e-07, 1.6647767552058212e-05, 0.9985072016716003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08800846338272095, 0.18921291828155518, 0.045562561601400375, 0.08163290470838547, 0.017358077690005302, 0.0048304032534360886, 0.01895879954099655, 0.0046201348304748535, 0.06910265982151031, 0.012970476411283016, 0.010343024507164955, 0.05366411805152893, 0.009830267168581486, 0.05797473341226578, 0.011936412192881107, 0.00944663304835558, 0.04662337899208069, 0.07882607728242874, 0.010427417233586311, 0.0020946746226400137, 0.1765758991241455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01597118191421032, 0.003062016097828746, 0.0001418951724190265, 0.0007885746890679002, 4.299372449168004e-05, 4.131201058044098e-05, 6.306873547146097e-05, 3.546515245034243e-06, 2.173127722926438e-05, 1.7860953448689543e-05, 1.0213988389295992e-05, 2.6596406314638443e-05, 3.785551598411985e-05, 1.3186858268454671e-05, 0.00018817681120708585, 4.963882020092569e-06, 1.8085114788846113e-05, 4.8640275053912774e-05, 4.463595359993633e-06, 2.4802504867693642e-06, 1.2178916222183034e-05, 0.9794788956642151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0074722301214933395, 0.00037190725561231375, 7.639086834387854e-05, 1.1135914974147454e-05, 3.0148716177791357e-05, 1.1014429219358135e-05, 5.4528787586605176e-05, 2.244440111098811e-05, 1.1283858839306049e-05, 2.8587872293428518e-05, 5.627739938063314e-06, 7.513614400522783e-05, 7.73429565015249e-05, 6.529718575620791e-06, 8.796916517894715e-06, 8.651511052448768e-06, 5.0727925554383546e-05, 7.0408632382168435e-06, 3.1876450520940125e-05, 1.4034882269697846e-06, 7.003588507359382e-06, 7.040087803034112e-05, 0.9915598034858704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02204541489481926, 0.28049421310424805, 0.016674764454364777, 0.0001508713758084923, 0.0006804470322094858, 2.7394113203627057e-05, 0.0008938325918279588, 1.249920478585409e-05, 0.00026655319379642606, 5.584166046901373e-06, 5.109102130518295e-05, 9.500431769993156e-05, 1.8194787116954103e-05, 0.0001828282547648996, 0.0016493600560352206, 2.7935184334637597e-05, 6.99191732564941e-05, 7.677565736230463e-05, 2.0886143829557113e-05, 4.512566647463245e-06, 0.0001454139273846522, 0.00044704994070343673, 5.514781514648348e-05, 0.6759043335914612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01879945769906044, 0.0019184600096195936, 0.0010523868259042501, 7.228145841509104e-05, 0.000137966126203537, 5.208816219237633e-05, 6.334375939331949e-05, 9.731957106851041e-06, 8.120811253320426e-05, 5.998387496219948e-05, 9.63596539804712e-06, 4.8187135689659044e-05, 4.688356784754433e-05, 5.250570393400267e-05, 0.00044942068052478135, 0.00028932970599271357, 3.537202792358585e-05, 0.00022377951245289296, 0.00020209007197991014, 3.112009608230437e-06, 3.5228513297624886e-05, 9.855003008851781e-05, 0.00018101489695254713, 0.00012300792150199413, 0.9759548306465149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0016589765436947346, 6.6324769250059035e-06, 3.9323440432781354e-05, 5.5121408877312206e-06, 7.328293577302247e-05, 5.176199238121626e-07, 8.362679363926873e-05, 1.6115403923322447e-05, 1.8407968127576169e-07, 0.00020032595784869045, 1.849748059612466e-06, 7.683036784555952e-08, 1.8051048755296506e-05, 9.259753852575159e-08, 6.612178367504384e-06, 1.962786427611718e-06, 5.0048473809738425e-08, 6.371125493842555e-08, 4.881649147137068e-07, 3.839147211692762e-06, 1.8601497231429676e-08, 1.6708673911125516e-06, 8.81660753293545e-07, 6.673342767271606e-08, 1.878518105513649e-07, 0.9978796243667603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005040670745074749, 0.00039155586273409426, 0.000561871042009443, 0.00014523064601235092, 3.937192013836466e-05, 5.4099655244499445e-05, 0.000284795300103724, 4.828744931728579e-05, 3.104319375779596e-06, 6.896281411172822e-05, 0.0002681417390704155, 4.2109372770937625e-06, 1.2119896382500883e-05, 2.0253992261132225e-06, 3.188784830854274e-05, 1.1356536560924724e-05, 3.0188034543243703e-06, 1.2622916983673349e-05, 7.4655908974818885e-06, 3.0278133635874838e-06, 4.951124878971314e-07, 3.015461152244825e-05, 1.886378049675841e-05, 4.1512544157740194e-06, 5.031331511418102e-06, 6.06908906775061e-06, 0.9929414987564087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012448678025975823, 0.00017617041885387152, 2.4151753677870147e-05, 1.2456692275009118e-05, 5.211313327890821e-05, 2.3546064767288044e-05, 5.673457053489983e-05, 0.00045827735448256135, 2.4983903585962253e-06, 0.00011349430133122951, 4.9202564696315676e-05, 1.3444564501696732e-05, 7.735941471764818e-05, 1.3437108918878948e-06, 6.060910891392268e-06, 0.00010331783414585516, 8.745500053919386e-06, 1.0811584616021719e-05, 0.0001585641730343923, 1.9056084283874952e-06, 5.418800128609291e-07, 1.232136924045335e-06, 6.472238601418212e-05, 3.5890639082936104e-06, 8.650918061903212e-06, 2.9628040465468075e-06, 1.3278973710839637e-05, 0.9973099231719971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001973335398361087, 0.0009750564931891859, 7.218521932372823e-05, 9.848416084423661e-05, 4.9608672270551324e-05, 5.4340576753020287e-05, 0.0003797206445597112, 6.184627181937685e-06, 1.0831159897861653e-06, 4.491215349844424e-06, 0.0004798352310899645, 9.928658073476981e-07, 1.3564559594669845e-05, 6.477191618614597e-07, 1.0186123290623073e-05, 5.581327059189789e-06, 7.11347752258007e-07, 5.998071515023184e-07, 3.2010909762902884e-06, 2.288285941176582e-06, 1.5130844133182109e-07, 7.130760423024185e-06, 1.7937974234882859e-06, 2.402572863502428e-05, 2.833118344369723e-07, 1.2269152648514137e-05, 0.00023325464280787855, 0.0003131963894702494, 0.9952758550643921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030099282041192055, 0.09027378261089325, 0.02814972773194313, 0.15763874351978302, 0.026473553851246834, 0.00300600822083652, 0.01721954718232155, 0.002244668547064066, 0.031200462952256203, 0.011351728811860085, 0.0013561318628489971, 0.029119187965989113, 0.0167735256254673, 0.023998098447918892, 0.00945053156465292, 0.006288205273449421, 0.023923052474856377, 0.058296240866184235, 0.009904228150844574, 0.0003779735998250544, 0.024595139548182487, 0.040420059114694595, 0.02788674272596836, 0.009823569096624851, 0.04994713142514229, 0.0010651148622855544, 0.014632527716457844, 0.011246386915445328, 0.0020601546857506037, 0.24117852747440338, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004169418942183256, 0.000614328368101269, 0.0005938458489254117, 0.00011036222713300958, 9.005510219139978e-05, 1.3705171113542747e-05, 0.0005903487908653915, 2.689233269848046e-06, 8.671501745993737e-06, 4.611639087670483e-05, 1.005678677756805e-05, 5.362908268580213e-06, 5.1998504204675555e-05, 4.802413968718611e-06, 2.119524469890166e-05, 2.478504757164046e-05, 3.4400377444399055e-06, 1.8410850316286087e-05, 7.055151218082756e-05, 5.603974955192825e-07, 5.060179319116287e-06, 2.2592150344280526e-05, 6.252543971640989e-05, 1.8619364709593356e-05, 0.00014118559192866087, 2.633108670124784e-05, 1.261043394151784e-06, 1.0759861197584542e-06, 3.0931974492887093e-07, 5.793054697278421e-06, 0.9932644367218018, 0.0, 0.0, 0.0, 0.0], [0.010566670447587967, 0.0013905902160331607, 0.0004313635581638664, 0.0010295939864590764, 0.003916396759450436, 0.00015029520727694035, 0.0019936019089072943, 0.0003044376790057868, 2.9845123208360747e-05, 0.0006592926802113652, 1.2659849744522944e-05, 7.52750929677859e-05, 0.00039767735870555043, 1.7276557628065348e-05, 0.00038583544665016234, 2.1061921870568767e-05, 5.3403142374008894e-05, 6.33502786513418e-05, 0.00012688453716691583, 6.783208391425433e-06, 2.717058850976173e-05, 0.00013008965470362455, 3.859863136312924e-05, 4.366650682641193e-05, 8.064091161941178e-06, 0.000746867444831878, 8.195245754905045e-06, 9.368611063109711e-05, 6.2524600252800155e-06, 4.447249375516549e-05, 0.00020698668959084898, 0.9770136475563049, 0.0, 0.0, 0.0], [0.017131486907601357, 0.10981205850839615, 0.04528496041893959, 0.16663990914821625, 0.04683493450284004, 0.012714344076812267, 0.024941841140389442, 0.0024605055805295706, 0.01651417277753353, 0.014018187299370766, 0.0028046509250998497, 0.01726130023598671, 0.05619135499000549, 0.01184318121522665, 0.024518396705389023, 0.008004878647625446, 0.013582986779510975, 0.027696536853909492, 0.007881492376327515, 0.001375964260660112, 0.009033636189997196, 0.03747997805476189, 0.014368826523423195, 0.01657966524362564, 0.03148625046014786, 0.0022351087536662817, 0.007032560650259256, 0.020338809117674828, 0.0021573659032583237, 0.01573573797941208, 0.03529255837202072, 0.01779499463737011, 0.16295136511325836, 0.0, 0.0], [0.0027362373657524586, 0.0032704402692615986, 0.00024938516435213387, 2.9521108444896527e-05, 0.0027190777473151684, 1.5680814613006078e-05, 0.0011440061498433352, 3.528553861542605e-05, 1.9352071831235662e-05, 3.620963980210945e-05, 1.2202220204926562e-05, 0.00012145638902438805, 4.9556045269127935e-05, 1.1851489034597762e-05, 8.826622797641903e-05, 3.184519300702959e-05, 8.618916035629809e-05, 0.00013057797332294285, 9.26754655665718e-05, 1.844452526711393e-05, 4.454882855497999e-06, 1.421102206222713e-05, 0.00020819788915105164, 6.224938988452777e-05, 2.7289990612189285e-05, 8.527088539267424e-06, 0.0010931704891845584, 0.0010258982656523585, 1.8266431652591564e-05, 9.816321835387498e-06, 7.599958280479768e-07, 4.151809662289452e-06, 8.365893336303998e-06, 0.9866164922714233, 0.0], [0.013301754370331764, 0.0020241746678948402, 0.0009810624178498983, 0.00027103928732685745, 0.02624255046248436, 6.968403613427654e-05, 0.00018824616563506424, 0.00033232715213671327, 0.00020717488951049745, 0.00035583574208430946, 1.8688768250285648e-05, 0.00031016304274089634, 0.0002884422428905964, 0.00014157555415295064, 0.00021018910047132522, 0.00013730116188526154, 0.00024542518076486886, 0.0005858629592694342, 0.0008409075089730322, 0.00037898405571468174, 0.00011255494609940797, 0.0009485270129516721, 0.00025817184359766543, 0.0005371627048589289, 0.00023706414503976703, 9.896148549159989e-05, 1.4541812561219558e-05, 7.51436164136976e-05, 1.0142423889192287e-05, 7.690770144108683e-05, 6.643275992246345e-05, 5.445994975161739e-05, 0.00010781989840324968, 0.002189120277762413, 0.9480817317962646]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9360752105712891, 0.06392484903335571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8446658253669739, 0.06946855783462524, 0.0858655795454979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6426600217819214, 0.12988688051700592, 0.17117170989513397, 0.056281305849552155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5074959993362427, 0.0778626948595047, 0.0726853534579277, 0.10711851716041565, 0.23483745753765106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4970755875110626, 0.06315258890390396, 0.1155911237001419, 0.08851397037506104, 0.1019636020064354, 0.1337031126022339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30812814831733704, 0.06775974482297897, 0.13057540357112885, 0.054409369826316833, 0.040503211319446564, 0.36059141159057617, 0.03803272172808647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32434967160224915, 0.06349695473909378, 0.07783649116754532, 0.07798173278570175, 0.07410475611686707, 0.13590551912784576, 0.07038862258195877, 0.17593632638454437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16412921249866486, 0.03469286113977432, 0.05131254345178604, 0.013316983357071877, 0.17712701857089996, 0.1595190316438675, 0.09812309592962265, 0.29690471291542053, 0.004874553997069597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18775460124015808, 0.054880447685718536, 0.10758272558450699, 0.043910037726163864, 0.1406543254852295, 0.11696729063987732, 0.052460040897130966, 0.1536639779806137, 0.049352679401636124, 0.09277382493019104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2051711082458496, 0.040068794041872025, 0.0833921879529953, 0.04565277323126793, 0.056970130652189255, 0.1331988424062729, 0.026416389271616936, 0.09950854629278183, 0.050134606659412384, 0.21417361497879028, 0.045312922447919846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10754456371068954, 0.020955437794327736, 0.052468422800302505, 0.008330842480063438, 0.17997518181800842, 0.10652032494544983, 0.07210807502269745, 0.20191138982772827, 0.0033460466656833887, 0.140213280916214, 0.1035674586892128, 0.0030589583329856396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09423349797725677, 0.02283540554344654, 0.05558856949210167, 0.026967845857143402, 0.12799425423145294, 0.07631109654903412, 0.07361149787902832, 0.16634686291217804, 0.030196350067853928, 0.11622443795204163, 0.1307915300130844, 0.022433554753661156, 0.056465111672878265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11027710884809494, 0.019917305558919907, 0.03387211635708809, 0.00801222212612629, 0.1268695592880249, 0.12052714824676514, 0.06604590266942978, 0.21159586310386658, 0.0029103809501975775, 0.13361388444900513, 0.07830420881509781, 0.005965673364698887, 0.07863970100879669, 0.0034490113612264395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16007709503173828, 0.05452115088701248, 0.0597362257540226, 0.020207513123750687, 0.05266042798757553, 0.10011065751314163, 0.11729258298873901, 0.14998750388622284, 0.017248373478651047, 0.05625281482934952, 0.09442037343978882, 0.01204691268503666, 0.020297691226005554, 0.018244566395878792, 0.06689617037773132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17850056290626526, 0.04271138831973076, 0.05876287817955017, 0.02550152689218521, 0.028219731524586678, 0.0939594954252243, 0.035697732120752335, 0.03853301331400871, 0.02757410891354084, 0.1241721361875534, 0.09900187700986862, 0.029919546097517014, 0.04168913885951042, 0.030038561671972275, 0.08029220998287201, 0.06542614102363586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08262607455253601, 0.014221644960343838, 0.03910331800580025, 0.005809774622321129, 0.14161063730716705, 0.08671100437641144, 0.05503494292497635, 0.15626993775367737, 0.0023281811736524105, 0.11679328233003616, 0.08067946135997772, 0.002191798761487007, 0.09792860597372055, 0.002736869268119335, 0.03297452628612518, 0.08037842810153961, 0.002601496409624815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09858328104019165, 0.02832067385315895, 0.05263177677989006, 0.017858654260635376, 0.06163661181926727, 0.08070766925811768, 0.07397957891225815, 0.09560465067625046, 0.00933582428842783, 0.08467231690883636, 0.11269158124923706, 0.01846788264811039, 0.03856261819601059, 0.011051514185965061, 0.06964196264743805, 0.09237806499004364, 0.022560445591807365, 0.031314946711063385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14957918226718903, 0.013048062101006508, 0.03394850343465805, 0.015061764977872372, 0.045098818838596344, 0.08479965478181839, 0.027256982401013374, 0.17206285893917084, 0.01685032993555069, 0.10883241146802902, 0.11793848872184753, 0.008323253132402897, 0.016134316101670265, 0.01772647723555565, 0.02617342211306095, 0.05189086124300957, 0.008976074866950512, 0.010605722665786743, 0.07569276541471481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2303972989320755, 0.024296818301081657, 0.026559978723526, 0.039246175438165665, 0.04230225831270218, 0.049243416637182236, 0.007979442365467548, 0.0732208788394928, 0.034551844000816345, 0.06601923704147339, 0.03830168768763542, 0.03672322630882263, 0.0241401270031929, 0.037105266004800797, 0.028557125478982925, 0.0544639453291893, 0.03901505470275879, 0.015944398939609528, 0.046100083738565445, 0.08583169430494308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.056916654109954834, 0.006225023418664932, 0.0117544149979949, 0.003549676388502121, 0.07110723853111267, 0.0800657570362091, 0.022162364795804024, 0.11016806960105896, 0.0010484926169738173, 0.08122202754020691, 0.026672042906284332, 0.002196080517023802, 0.03059852309525013, 0.0012014046078547835, 0.014937764033675194, 0.14736880362033844, 0.002626748289912939, 0.03338917717337608, 0.1104901060461998, 0.18504445254802704, 0.0012552260886877775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09241704642772675, 0.026059623807668686, 0.02483060583472252, 0.014753975905478, 0.07309960573911667, 0.041600827127695084, 0.028182964771986008, 0.10522367805242538, 0.010200564749538898, 0.02671687863767147, 0.03863626345992088, 0.008342119865119457, 0.03416535258293152, 0.011011878028512001, 0.02702196314930916, 0.10600949078798294, 0.00949846487492323, 0.016123095527291298, 0.06257016211748123, 0.19003154337406158, 0.010448911227285862, 0.043055012822151184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06173652410507202, 0.007029627915471792, 0.019486606121063232, 0.010366823524236679, 0.04601287841796875, 0.07236862927675247, 0.022752372547984123, 0.08978492021560669, 0.005041902419179678, 0.07019013911485672, 0.07947879284620285, 0.00647539459168911, 0.038350652903318405, 0.005680918227881193, 0.015840988606214523, 0.053441066294908524, 0.007524982560425997, 0.018862156197428703, 0.09784606844186783, 0.19087877869606018, 0.0069852969609200954, 0.027727821841835976, 0.04613659158349037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0434984415769577, 0.006029139738529921, 0.0162718053907156, 0.0049628885462880135, 0.0923277884721756, 0.056436073035001755, 0.02427319996058941, 0.10004423558712006, 0.0013475855812430382, 0.04695267602801323, 0.04337000101804733, 0.002612095093354583, 0.02598002552986145, 0.0015367756132036448, 0.013811740092933178, 0.12162510305643082, 0.0030840537510812283, 0.014781148172914982, 0.08252861350774765, 0.20843428373336792, 0.0021058102138340473, 0.033566415309906006, 0.04992131143808365, 0.00449881749227643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05493931099772453, 0.005164694041013718, 0.0132825318723917, 0.006816811393946409, 0.08581957221031189, 0.042583730071783066, 0.010111802257597446, 0.10901322215795517, 0.0030670426785945892, 0.041951488703489304, 0.03668753802776337, 0.003877603216096759, 0.036396294832229614, 0.0036428289022296667, 0.01571308635175228, 0.04514279589056969, 0.0047706314362585545, 0.010733419097959995, 0.12949077785015106, 0.1834336817264557, 0.005763913504779339, 0.06008809059858322, 0.06420368701219559, 0.00847991369664669, 0.018825508654117584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1161927580833435, 0.024008192121982574, 0.017500849440693855, 0.022795286029577255, 0.0502765066921711, 0.03202547878026962, 0.020647749304771423, 0.03974740579724312, 0.023735979571938515, 0.02667790651321411, 0.01885642111301422, 0.028171353042125702, 0.03460881486535072, 0.026643721386790276, 0.022768070921301842, 0.023577362298965454, 0.031199203804135323, 0.022620445117354393, 0.09706808626651764, 0.06436187028884888, 0.03251432627439499, 0.04557201266288757, 0.04268260672688484, 0.02825286239385605, 0.025809558108448982, 0.08168511837720871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11220823973417282, 0.005275932606309652, 0.01370136346668005, 0.006475638598203659, 0.05825747922062874, 0.05591835081577301, 0.013027261011302471, 0.10451262444257736, 0.004013674333691597, 0.04011368378996849, 0.03787229582667351, 0.0031745275482535362, 0.012129993177950382, 0.004096257966011763, 0.007334521040320396, 0.017732826992869377, 0.0034752318169921637, 0.0030595543794333935, 0.0948338732123375, 0.20002640783786774, 0.005673964973539114, 0.016374558210372925, 0.01723022758960724, 0.004368433263152838, 0.009308066219091415, 0.09713462740182877, 0.052670374512672424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06115270033478737, 0.004939327947795391, 0.009762824513018131, 0.005227167159318924, 0.036462727934122086, 0.03137052804231644, 0.008218892849981785, 0.11535760015249252, 0.003272868227213621, 0.03824919834733009, 0.03337175026535988, 0.0021793791092932224, 0.007692953571677208, 0.003454809309914708, 0.009085441939532757, 0.02790052257478237, 0.0023665917105972767, 0.003948243334889412, 0.0407714881002903, 0.27574682235717773, 0.0035466663539409637, 0.012455103918910027, 0.03261314332485199, 0.0032098146621137857, 0.00360309355892241, 0.10009616613388062, 0.08892867714166641, 0.035015422850847244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11957036703824997, 0.008050518110394478, 0.013377298600971699, 0.007089263293892145, 0.025275401771068573, 0.05149080604314804, 0.006585441064089537, 0.06165985390543938, 0.005620484706014395, 0.0556148886680603, 0.0272917989641428, 0.0042864857241511345, 0.00769842742010951, 0.005996250547468662, 0.0079420180991292, 0.028790518641471863, 0.004870964214205742, 0.004313758574426174, 0.02622806280851364, 0.15385545790195465, 0.010709966532886028, 0.009564647451043129, 0.029178395867347717, 0.00532927829772234, 0.008051515556871891, 0.07812707871198654, 0.10984010249376297, 0.029521040618419647, 0.09406988322734833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025880740955471992, 0.0032868722919374704, 0.009190610609948635, 0.0022713204380124807, 0.042062561959028244, 0.0403556190431118, 0.015107071958482265, 0.04801337793469429, 0.0008096094243228436, 0.03906422108411789, 0.026566797867417336, 0.0015204474329948425, 0.02122015506029129, 0.0009539543534629047, 0.007810368202626705, 0.033135153353214264, 0.0018792495829984546, 0.010119687765836716, 0.06751000881195068, 0.12262904644012451, 0.0015832217177376151, 0.02216803841292858, 0.03078523464500904, 0.004318804480135441, 0.01872900500893593, 0.1447751373052597, 0.06957437843084335, 0.11388751119375229, 0.07182329148054123, 0.002968477550894022, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046125102788209915, 0.004929375369101763, 0.011905021034181118, 0.005939910188317299, 0.05086232349276543, 0.03915585204958916, 0.011702250689268112, 0.07777240127325058, 0.0027224940713495016, 0.029330717399716377, 0.035436615347862244, 0.002508658915758133, 0.011883246712386608, 0.0029638586565852165, 0.008878663182258606, 0.018936676904559135, 0.002804588293656707, 0.004066930618137121, 0.06637166440486908, 0.16173596680164337, 0.004074744880199432, 0.017417898401618004, 0.04845814034342766, 0.005489852279424667, 0.01446738000959158, 0.08884270489215851, 0.05744141712784767, 0.04815758392214775, 0.09182099252939224, 0.004751020576804876, 0.023045994341373444, 0.0, 0.0, 0.0, 0.0], [0.028616543859243393, 0.0035397156607359648, 0.012825744226574898, 0.003731101518496871, 0.022132838144898415, 0.026339100673794746, 0.015483646653592587, 0.04692447930574417, 0.0016770181246101856, 0.05343090742826462, 0.03818728029727936, 0.002529490040615201, 0.0276822317391634, 0.0019447184167802334, 0.010427960194647312, 0.020306406542658806, 0.003083115443587303, 0.008337561972439289, 0.06147443875670433, 0.05695469677448273, 0.0030909168999642134, 0.019787292927503586, 0.037704240530729294, 0.004031909629702568, 0.020770886912941933, 0.12126165628433228, 0.08733711391687393, 0.07036236673593521, 0.09933117032051086, 0.005798676051199436, 0.06381496787071228, 0.02107991836965084, 0.0, 0.0, 0.0], [0.022769231349229813, 0.0023638159036636353, 0.0069536129012703896, 0.0009745154529809952, 0.0334312804043293, 0.03096313215792179, 0.012881088070571423, 0.0763968825340271, 0.0002621037419885397, 0.03044992871582508, 0.03674258291721344, 0.0005670599639415741, 0.014569034799933434, 0.0003055332927033305, 0.00594836100935936, 0.02249256521463394, 0.0007025566883385181, 0.004866450559347868, 0.060261815786361694, 0.1558590680360794, 0.0005001772078685462, 0.019988080486655235, 0.03086850605905056, 0.0031281497795134783, 0.01215117797255516, 0.11994652450084686, 0.07597392052412033, 0.09628818184137344, 0.07584254443645477, 0.0010643767891451716, 0.03271331265568733, 0.011111115105450153, 0.0006632998702116311, 0.0, 0.0], [0.06755810230970383, 0.003352794563397765, 0.008972210809588432, 0.0034025455825030804, 0.05607305467128754, 0.03040470741689205, 0.013628309592604637, 0.07952425628900528, 0.002588937757536769, 0.034729402512311935, 0.015315976925194263, 0.002527096541598439, 0.007685468997806311, 0.0026928242295980453, 0.007112996652722359, 0.02612845040857792, 0.0027733694296330214, 0.007069502025842667, 0.05076204985380173, 0.1759389191865921, 0.003935437649488449, 0.010542861185967922, 0.012697339989244938, 0.0028314394876360893, 0.004983489401638508, 0.05610368028283119, 0.10278663784265518, 0.0786440521478653, 0.06361379474401474, 0.004290643613785505, 0.012449046596884727, 0.007846901193261147, 0.0035741610918194056, 0.03745955228805542, 0.0], [0.05889429152011871, 0.00483429292216897, 0.008816237561404705, 0.004917601589113474, 0.05724450200796127, 0.04719965532422066, 0.010384357534348965, 0.043736834079027176, 0.003253217088058591, 0.02700052410364151, 0.015385990031063557, 0.005444503389298916, 0.018304407596588135, 0.003610059153288603, 0.011856135912239552, 0.07255371659994125, 0.006018081679940224, 0.006411908660084009, 0.055861566215753555, 0.08374673873186111, 0.00397366750985384, 0.018590599298477173, 0.01944512315094471, 0.003880673786625266, 0.008932657539844513, 0.12242711335420609, 0.0409863144159317, 0.0742977038025856, 0.057745564728975296, 0.006318635307252407, 0.01308411918580532, 0.023065811023116112, 0.005796522833406925, 0.04094136133790016, 0.01503958459943533]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9780336022377014, 0.021966341882944107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5068985819816589, 0.42791488766670227, 0.06518654525279999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34595057368278503, 0.23385100066661835, 0.1913881003856659, 0.2288103699684143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2785968780517578, 0.17525744438171387, 0.11037097871303558, 0.2518094778060913, 0.18396523594856262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2080419808626175, 0.08827144652605057, 0.061608098447322845, 0.2584841549396515, 0.2705698609352112, 0.11302442103624344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16325624287128448, 0.12141189724206924, 0.11990708857774734, 0.1616644561290741, 0.10774069279432297, 0.29750365018844604, 0.028515929356217384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12280930578708649, 0.03978987783193588, 0.0451454296708107, 0.13578490912914276, 0.09269551932811737, 0.11808707565069199, 0.33698490262031555, 0.10870299488306046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0785447359085083, 0.035703908652067184, 0.02910533733665943, 0.05200903117656708, 0.10322193056344986, 0.06222517415881157, 0.06801241636276245, 0.17029158771038055, 0.4008859097957611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0855533704161644, 0.04508212208747864, 0.020755313336849213, 0.05748791620135307, 0.0585336834192276, 0.03812538459897041, 0.03164030611515045, 0.14470815658569336, 0.39396733045578003, 0.12414640933275223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03400759398937225, 0.005801301449537277, 0.004264355171471834, 0.014554576016962528, 0.0020581241697072983, 0.01005222462117672, 0.015462437644600868, 0.014919922687113285, 0.07456014305353165, 0.8029415607452393, 0.021377811208367348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03658133000135422, 0.008552642539143562, 0.009085921570658684, 0.01071858685463667, 0.031510528177022934, 0.07786066830158234, 0.02809952199459076, 0.0520339198410511, 0.09175647050142288, 0.2498079538345337, 0.22384558618068695, 0.18014685809612274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03899507224559784, 0.013953070156276226, 0.02715037576854229, 0.015978634357452393, 0.006068874150514603, 0.01533289160579443, 0.007358457427471876, 0.00814359076321125, 0.09236102551221848, 0.09582377225160599, 0.39708977937698364, 0.22508250176906586, 0.05666198208928108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029417643323540688, 0.006853986531496048, 0.005433523561805487, 0.008306879550218582, 0.015738286077976227, 0.0087088942527771, 0.008349091745913029, 0.023920070379972458, 0.04694683104753494, 0.04814503341913223, 0.0930999144911766, 0.15290869772434235, 0.148541659116745, 0.40362948179244995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03712830692529678, 0.007584473583847284, 0.003545144572854042, 0.008117970079183578, 0.0188341923058033, 0.0059049720875918865, 0.009632604196667671, 0.011076660826802254, 0.04249940067529678, 0.015083986334502697, 0.01984347403049469, 0.11177276074886322, 0.12816858291625977, 0.33317863941192627, 0.24762879312038422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024791505187749863, 0.0022572411689907312, 0.0019112293375656009, 0.0031496440060436726, 0.0017746686935424805, 0.0030808576848357916, 0.01988072134554386, 0.006427102256566286, 0.015317469835281372, 0.003226605709642172, 0.02029608190059662, 0.05772734433412552, 0.02255523018538952, 0.08885953575372696, 0.7141122817993164, 0.014632451348006725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019352801144123077, 0.002735720481723547, 0.002700645010918379, 0.0028163958340883255, 0.0073006064631044865, 0.016268694773316383, 0.005134703125804663, 0.010258643887937069, 0.01379147358238697, 0.03380443900823593, 0.033944837749004364, 0.02411041408777237, 0.05347483977675438, 0.09691011160612106, 0.27618837356567383, 0.22190365195274353, 0.1793036311864853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016778303310275078, 0.0013836672296747565, 0.0012504433980211616, 0.0019532626029103994, 0.0012283105170354247, 0.003427049843594432, 0.001771017094142735, 0.002587684663012624, 0.009956522844731808, 0.007537419442087412, 0.004963125102221966, 0.02366887405514717, 0.017456650733947754, 0.06967750191688538, 0.2612769901752472, 0.2408241480588913, 0.17677903175354004, 0.157479926943779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05475039780139923, 0.009201946668326855, 0.003783300518989563, 0.00689188065007329, 0.007006871048361063, 0.0052677784115076065, 0.0019135880284011364, 0.0066490089520812035, 0.02249075472354889, 0.007203701883554459, 0.03985988348722458, 0.02630697190761566, 0.035983867943286896, 0.10654623806476593, 0.14742796123027802, 0.029531963169574738, 0.14834152162075043, 0.23425278067588806, 0.10658960789442062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08004868775606155, 0.003562749596312642, 0.0033941466826945543, 0.011285568587481976, 0.01220858097076416, 0.0019434965215623379, 0.003920830320566893, 0.024116622284054756, 0.023349955677986145, 0.008975900709629059, 0.005343950819224119, 0.02533606067299843, 0.01387019269168377, 0.10103654861450195, 0.03973817825317383, 0.08061382174491882, 0.12086469680070877, 0.12294691801071167, 0.14132516086101532, 0.17611795663833618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01305336132645607, 0.0019795650150626898, 0.0016182122053578496, 0.0014078525127843022, 0.0014868254074826837, 0.0013099159114062786, 0.0016642971895635128, 0.0025665161665529013, 0.003062670351937413, 0.010340578854084015, 0.007755250670015812, 0.008929400704801083, 0.008869537152349949, 0.017165113240480423, 0.07265795767307281, 0.08664470911026001, 0.06223943084478378, 0.16528479754924774, 0.07255077362060547, 0.09155546873807907, 0.36785778403282166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012316017411649227, 0.0011592359514907002, 0.0007622389821335673, 0.001950751175172627, 0.0012718522921204567, 0.0006892273668199778, 0.0005458985106088221, 0.0026030000299215317, 0.003917664755135775, 0.0005409363657236099, 0.0012741924729198217, 0.006503167096525431, 0.005551586858928204, 0.01797345094382763, 0.013353327289223671, 0.03805124759674072, 0.04303396865725517, 0.039586566388607025, 0.022300681099295616, 0.03898366913199425, 0.5949540138244629, 0.15267719328403473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013724957592785358, 0.001612574909813702, 0.00032898675999604166, 0.0010084318928420544, 0.0011758042965084314, 0.000725927238818258, 0.0005918752285651863, 0.0009615588933229446, 0.0031186197884380817, 0.005970009136945009, 0.003033465938642621, 0.003344498574733734, 0.008407535031437874, 0.013658502139151096, 0.005607031285762787, 0.005321723408997059, 0.019289910793304443, 0.029109666123986244, 0.013599621132016182, 0.031337786465883255, 0.25137248635292053, 0.5305222272872925, 0.05617687478661537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01600237935781479, 0.0009560453472658992, 0.0005680458270944655, 0.001554973074235022, 0.0015755745116621256, 0.0006219735369086266, 0.0011257643345743418, 0.0014368743868544698, 0.0023100462276488543, 0.0009028317290358245, 0.001392145873978734, 0.0036725937388837337, 0.00363227934576571, 0.009217390790581703, 0.008623875677585602, 0.027025746181607246, 0.021376444026827812, 0.03330114483833313, 0.03885401040315628, 0.039058420807123184, 0.26596635580062866, 0.19372603297233582, 0.09792883694171906, 0.22917026281356812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009987294673919678, 0.0009651763830333948, 0.0006041579181328416, 0.0009222126100212336, 0.0008805808611214161, 0.0005974342348054051, 0.00021149202075321227, 0.000645568419713527, 0.001241767662577331, 0.0006859704153612256, 0.0007031510467641056, 0.0014577426481992006, 0.0018487706547603011, 0.005077200476080179, 0.0019275667145848274, 0.012413390912115574, 0.008568295277655125, 0.012073684483766556, 0.021936645731329918, 0.02919415384531021, 0.14272746443748474, 0.09834039211273193, 0.1184767559170723, 0.31631967425346375, 0.21219348907470703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016860902309417725, 0.0019703286234289408, 0.000885836489032954, 0.001765640452504158, 0.0023928331211209297, 0.0005271153058856726, 0.0003617893671616912, 0.0006361056584864855, 0.0022411299869418144, 0.0008515875088050961, 0.00038157880771905184, 0.0022748277988284826, 0.0018798470264300704, 0.007292226422578096, 0.0021466766484081745, 0.0025263053830713034, 0.010355687700212002, 0.011969336308538914, 0.0065909153781831264, 0.012827490456402302, 0.12130486965179443, 0.06624644249677658, 0.14612402021884918, 0.2828073501586914, 0.2470329999923706, 0.04974617436528206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026405036449432373, 0.0014230996603146195, 0.001623444608412683, 0.002576401922851801, 0.00268970406614244, 0.0012257524067535996, 0.001089877332560718, 0.0009538462036289275, 0.0019223529379814863, 0.002411522436887026, 0.0024579439777880907, 0.0014354187296703458, 0.005378496367484331, 0.00473234336823225, 0.001939116045832634, 0.007957515306770802, 0.0060868836008012295, 0.012657452374696732, 0.011602509766817093, 0.02909662388265133, 0.08598875254392624, 0.07665884494781494, 0.0362401120364666, 0.13133350014686584, 0.19490280747413635, 0.21766334772109985, 0.1315472275018692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023896105587482452, 0.0020675037521868944, 0.002509376034140587, 0.0018511980306357145, 0.0031609658617526293, 0.0009005634346976876, 0.0002685424988158047, 0.0005213552503846586, 0.0017872133757919073, 0.0019308945629745722, 0.0010158239165320992, 0.0010442663915455341, 0.0015677042538300157, 0.00406009703874588, 0.0008207389619201422, 0.003358300542458892, 0.004117118194699287, 0.007223028223961592, 0.014547298662364483, 0.046351585537195206, 0.05601862445473671, 0.03840019553899765, 0.04160996153950691, 0.10494542121887207, 0.15788216888904572, 0.12118807435035706, 0.19090253114700317, 0.16605335474014282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04075779393315315, 0.003958363551646471, 0.0056980932131409645, 0.0039579859003424644, 0.0014047803124412894, 0.000327694317093119, 0.0006401935243047774, 0.0012045818148180842, 0.00223855790682137, 0.0007448497344739735, 0.0038365772925317287, 0.001620680559426546, 0.0010148307774215937, 0.004261186812072992, 0.0009652952430769801, 0.0003954324347432703, 0.005401067901402712, 0.007263402920216322, 0.005766802933067083, 0.029991842806339264, 0.041736576706171036, 0.017527645453810692, 0.02515505440533161, 0.07565261423587799, 0.24542635679244995, 0.06668499857187271, 0.2648317813873291, 0.055024098604917526, 0.08651081472635269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011784786358475685, 0.0013947549741715193, 0.000951564812567085, 0.0008953192736953497, 0.0010372701799497008, 0.0004972639726474881, 0.0002528381301090121, 0.00043175648897886276, 0.0005345686222426593, 0.00028229193412698805, 0.00042747301631607115, 0.0005479568499140441, 0.0008038743399083614, 0.001103747170418501, 0.0010882861679419875, 0.0026353751309216022, 0.00200331280939281, 0.00293945474550128, 0.005114199593663216, 0.009162316098809242, 0.0202364232391119, 0.01439724862575531, 0.014386605471372604, 0.052873123437166214, 0.04425809159874916, 0.07174722105264664, 0.08077167719602585, 0.11779716610908508, 0.1448613554239273, 0.3947826325893402, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012992875650525093, 0.001667613978497684, 0.0010021071648225188, 0.0011761238565668464, 0.0007638345705345273, 0.00040058320155367255, 0.000128492436488159, 0.00010518707858864218, 0.000560643442440778, 0.00014079399988986552, 0.0001220755948452279, 0.0003985989897046238, 0.00022988316777627915, 0.0011077822418883443, 0.0003631032886914909, 0.000889180286321789, 0.001440244959667325, 0.001452022697776556, 0.0026305674109607935, 0.0031673861667513847, 0.01722467690706253, 0.010722354054450989, 0.005023000296205282, 0.04577849805355072, 0.04751966521143913, 0.02706717513501644, 0.05216860771179199, 0.05500796437263489, 0.11481019109487534, 0.44568800926208496, 0.1482507437467575, 0.0, 0.0, 0.0, 0.0], [0.011720022186636925, 0.0009638680494390428, 0.0016792787937447429, 0.0009598786127753556, 0.0011835345067083836, 0.0003587341634556651, 0.00013125198893249035, 0.0002098587283398956, 0.0003518580342642963, 0.00011673847620841116, 0.0003326717996969819, 0.00020899789524264634, 0.0001630403712624684, 0.0005591601366177201, 0.0001787790097296238, 0.0005847538122907281, 0.0006520408787764609, 0.0008100892300717533, 0.0008232026011683047, 0.006545150186866522, 0.007790669798851013, 0.006622507236897945, 0.0050529721193015575, 0.014489841647446156, 0.024942079558968544, 0.01901034265756607, 0.02852551080286503, 0.036787744611501694, 0.14266972243785858, 0.23489882051944733, 0.3008541166782379, 0.14982277154922485, 0.0, 0.0, 0.0], [0.01146328542381525, 0.0009014826500788331, 0.0005477449740283191, 0.0005869870074093342, 0.0005616630078293383, 0.0002343479573028162, 0.00013944689999334514, 0.00019926823733840138, 0.00031403094180859625, 0.00012514658737927675, 0.00021479520364664495, 0.0002481348055880517, 0.00022906191588845104, 0.0005020775133743882, 0.00045190195669420063, 0.0006676741177216172, 0.0007638586102984846, 0.0009467181516811252, 0.0010094373719766736, 0.003719577332958579, 0.007444899994879961, 0.0045005581341683865, 0.0018344351556152105, 0.01297363918274641, 0.015522489324212074, 0.02183825895190239, 0.016228970140218735, 0.024697422981262207, 0.0380532369017601, 0.16302339732646942, 0.11826055496931076, 0.2288476973772049, 0.32294777035713196, 0.0, 0.0], [0.009539732709527016, 0.001424328307621181, 0.0009944570483639836, 0.0009655573521740735, 0.0007854426512494683, 0.00030160637106746435, 0.00011159563291585073, 0.0008093689102679491, 0.0004005462978966534, 8.517077367287129e-05, 0.0006307568401098251, 0.00020861598022747785, 0.0002525565796531737, 0.000545184186194092, 0.00024275555915664881, 0.0005828303401358426, 0.0005503920838236809, 0.001054858323186636, 0.0010979119688272476, 0.004033547826111317, 0.005151547025889158, 0.007251260802149773, 0.003988183103501797, 0.012260396033525467, 0.013561537489295006, 0.038286544382572174, 0.06675272434949875, 0.013111523352563381, 0.10093269497156143, 0.1317911297082901, 0.054323047399520874, 0.1525149792432785, 0.3083246052265167, 0.0671326294541359, 0.0], [0.009234574623405933, 0.0018696909537538886, 0.0015434958040714264, 0.001287891180254519, 0.0009349422180093825, 0.00028256085352040827, 0.0004494279273785651, 0.0005594989634118974, 0.0003277681826148182, 7.203830318758264e-05, 0.0001065790856955573, 0.0002636241842992604, 0.0003654726315289736, 0.0003748317249119282, 0.00031175350886769593, 0.0008969134069047868, 0.0006347450544126332, 0.0008650035015307367, 0.0008020042441785336, 0.0006307902513071895, 0.0032187809702008963, 0.0038458353374153376, 0.003000437282025814, 0.007814152166247368, 0.010107208043336868, 0.016721565276384354, 0.007672088220715523, 0.010031227022409439, 0.005356381647288799, 0.07757057994604111, 0.03774447366595268, 0.138091042637825, 0.1956760734319687, 0.030743561685085297, 0.43059301376342773]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8970723748207092, 0.10292765498161316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7731762528419495, 0.17108601331710815, 0.05573772266507149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21909849345684052, 0.09592848271131516, 0.1539974808692932, 0.5309755206108093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4932920038700104, 0.12421075254678726, 0.08378947526216507, 0.2104450911283493, 0.08826273679733276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4792534112930298, 0.11483937501907349, 0.058252837508916855, 0.12140913307666779, 0.19296902418136597, 0.033276282250881195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33760708570480347, 0.13038291037082672, 0.12365779280662537, 0.16848315298557281, 0.03948560729622841, 0.15522727370262146, 0.045156169682741165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3124314546585083, 0.1033550575375557, 0.07322119921445847, 0.13077442348003387, 0.08650774508714676, 0.2037174254655838, 0.04714132100343704, 0.04285133630037308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10719950497150421, 0.03256478160619736, 0.04615394398570061, 0.12522774934768677, 0.011105231009423733, 0.03433005139231682, 0.007858380675315857, 0.011366576887667179, 0.6241937875747681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30288904905319214, 0.07804970443248749, 0.059376489371061325, 0.09426911175251007, 0.17377153038978577, 0.03861627355217934, 0.048025283962488174, 0.039512552320957184, 0.13237620890140533, 0.03311379998922348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13027672469615936, 0.042134858667850494, 0.07258210331201553, 0.10922865569591522, 0.036304350942373276, 0.191125750541687, 0.03369797766208649, 0.05715860798954964, 0.11187218874692917, 0.16414132714271545, 0.051477424800395966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0946442186832428, 0.029253453016281128, 0.03811940923333168, 0.14989571273326874, 0.020670879632234573, 0.07631714642047882, 0.00894747395068407, 0.020045079290866852, 0.3057856857776642, 0.0475209578871727, 0.010440830141305923, 0.19835913181304932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14440803229808807, 0.06329526007175446, 0.07617759704589844, 0.07194554805755615, 0.03394106775522232, 0.08442071825265884, 0.03594021126627922, 0.07685542106628418, 0.11588277667760849, 0.05951952561736107, 0.06183496117591858, 0.14841707050800323, 0.027361812070012093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0414787232875824, 0.011494413949549198, 0.01764351688325405, 0.04599722847342491, 0.004085009917616844, 0.013701112940907478, 0.0028709033504128456, 0.004510779865086079, 0.24164846539497375, 0.00972951203584671, 0.0026167333126068115, 0.2641770541667938, 0.008053773082792759, 0.3319927453994751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15155857801437378, 0.0377250611782074, 0.02733064629137516, 0.06052475422620773, 0.030143294483423233, 0.0280348788946867, 0.013341411016881466, 0.022503050044178963, 0.11653435230255127, 0.05189971998333931, 0.010558661073446274, 0.10229875892400742, 0.015167283825576305, 0.14137376844882965, 0.19100576639175415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2839045524597168, 0.06502401828765869, 0.03238334879279137, 0.029591107740998268, 0.0424320213496685, 0.02846977300941944, 0.041533131152391434, 0.08465307205915451, 0.043854981660842896, 0.027530398219823837, 0.0921814888715744, 0.03751114010810852, 0.04891902953386307, 0.04984968155622482, 0.07913839817047119, 0.013023801147937775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048857610672712326, 0.01400737650692463, 0.01954261027276516, 0.07337553054094315, 0.010089144110679626, 0.03972570598125458, 0.004310052376240492, 0.01059033814817667, 0.15303604304790497, 0.026499049738049507, 0.005417251959443092, 0.096476249396801, 0.012806721031665802, 0.204786479473114, 0.14743390679359436, 0.009689195081591606, 0.1233566626906395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05943122133612633, 0.0259512010961771, 0.035473886877298355, 0.03907974436879158, 0.018049322068691254, 0.02308725006878376, 0.010503753088414669, 0.030069561675190926, 0.09918283671140671, 0.03614407777786255, 0.018410028889775276, 0.11741484701633453, 0.017167579382658005, 0.12769995629787445, 0.08459018915891647, 0.03790272772312164, 0.145772323012352, 0.07406947761774063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.272489070892334, 0.045022737234830856, 0.04612237215042114, 0.042051978409290314, 0.03813564404845238, 0.054544299840927124, 0.025706561282277107, 0.019254159182310104, 0.04536459222435951, 0.05106878653168678, 0.021479343995451927, 0.05142935737967491, 0.035683102905750275, 0.05110248923301697, 0.04221019521355629, 0.03813278302550316, 0.057898201048374176, 0.023540079593658447, 0.038764264434576035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.239812433719635, 0.03723884001374245, 0.046413224190473557, 0.018074778839945793, 0.02860945276916027, 0.031563643366098404, 0.023263651877641678, 0.053141165524721146, 0.036729808896780014, 0.04436156898736954, 0.014090009033679962, 0.04079657047986984, 0.013384056277573109, 0.04018275439739227, 0.02512497268617153, 0.022283174097537994, 0.04457441344857216, 0.0263572558760643, 0.01850212551653385, 0.19549617171287537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03447256609797478, 0.0070497882552444935, 0.008516231551766396, 0.019823284819722176, 0.0020061929244548082, 0.00873848982155323, 0.001380532281473279, 0.002584987785667181, 0.129638671875, 0.0049805231392383575, 0.001454295590519905, 0.09793516248464584, 0.004242659546434879, 0.17474927008152008, 0.020575344562530518, 0.002921729814261198, 0.1251920908689499, 0.01766674779355526, 0.008172444067895412, 0.006463976576924324, 0.3214350640773773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07532121986150742, 0.017385119572281837, 0.02649959735572338, 0.038201119750738144, 0.01346430741250515, 0.017004938796162605, 0.005682718008756638, 0.00816139206290245, 0.0879102423787117, 0.0156520027667284, 0.00462237698957324, 0.06870011985301971, 0.017068391665816307, 0.11098405718803406, 0.08843356370925903, 0.01554049551486969, 0.08290650695562363, 0.03445708379149437, 0.0349029004573822, 0.02266903594136238, 0.1672758311033249, 0.047156915068626404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11039688438177109, 0.017618605867028236, 0.012073223479092121, 0.07903023809194565, 0.04707180708646774, 0.02839348278939724, 0.010853302665054798, 0.03898294270038605, 0.04254176467657089, 0.053135763853788376, 0.010616577230393887, 0.04066743329167366, 0.016578679904341698, 0.050442542880773544, 0.04148310422897339, 0.011694183573126793, 0.048943910747766495, 0.04587530717253685, 0.06803461164236069, 0.03145821392536163, 0.0737365186214447, 0.09332362562417984, 0.027047278359532356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.050105899572372437, 0.011403637938201427, 0.01897999458014965, 0.048291102051734924, 0.005478161387145519, 0.027938107028603554, 0.003475341945886612, 0.009667652659118176, 0.08883963525295258, 0.021459804847836494, 0.009184244088828564, 0.06738952547311783, 0.00629377830773592, 0.11730515956878662, 0.05559385195374489, 0.023259565234184265, 0.08538824319839478, 0.03017236478626728, 0.01855376921594143, 0.0497271791100502, 0.1386995017528534, 0.03593091294169426, 0.029570575803518295, 0.047291941940784454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.033650632947683334, 0.03973434865474701, 0.013943269848823547, 0.022155024111270905, 0.00737410131841898, 0.01253434270620346, 0.003937930800020695, 0.005588038358837366, 0.052764154970645905, 0.011353476904332638, 0.0029761551413685083, 0.06122001260519028, 0.007114534266293049, 0.06609286367893219, 0.018457181751728058, 0.004707181826233864, 0.0778060182929039, 0.01593407429754734, 0.016269709914922714, 0.027332937344908714, 0.08945079892873764, 0.02828321047127247, 0.013428343459963799, 0.24125005304813385, 0.12664161622524261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10162997245788574, 0.0481734462082386, 0.022741522639989853, 0.017647167667746544, 0.016357652842998505, 0.014718170277774334, 0.020238902419805527, 0.03009830415248871, 0.03836439922451973, 0.025297483429312706, 0.03959343954920769, 0.04179812967777252, 0.01849495992064476, 0.043456632643938065, 0.02387693151831627, 0.013411911204457283, 0.04804752394556999, 0.021995291113853455, 0.030744776129722595, 0.05168473348021507, 0.057864848524332047, 0.04216013103723526, 0.05038999021053314, 0.08024893701076508, 0.07608191668987274, 0.024882828816771507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06603525578975677, 0.020660119131207466, 0.02168169617652893, 0.03408760577440262, 0.015279390849173069, 0.01844199188053608, 0.010789590887725353, 0.05595837160944939, 0.035654861479997635, 0.021738866344094276, 0.02566494606435299, 0.039465565234422684, 0.01909186691045761, 0.04260498285293579, 0.0451403371989727, 0.012913594953715801, 0.047355785965919495, 0.025561854243278503, 0.035244137048721313, 0.09746365249156952, 0.05611315369606018, 0.035938482731580734, 0.032566994428634644, 0.0430198572576046, 0.04697675630450249, 0.03246127441525459, 0.062089040875434875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10541100800037384, 0.016973109915852547, 0.02034102752804756, 0.03266655653715134, 0.021851178258657455, 0.031789932399988174, 0.005571208894252777, 0.024194516241550446, 0.01674046739935875, 0.016082564368844032, 0.013484918512403965, 0.02279038354754448, 0.020844893530011177, 0.019816424697637558, 0.007411996368318796, 0.013035090640187263, 0.02698247693479061, 0.010132258757948875, 0.017667710781097412, 0.29726240038871765, 0.023457149043679237, 0.03235581889748573, 0.03224533796310425, 0.01998012699186802, 0.05017194151878357, 0.048278938978910446, 0.033088210970163345, 0.019372418522834778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1147821694612503, 0.02845187857747078, 0.030158082023262978, 0.029890695586800575, 0.015577692538499832, 0.04523628205060959, 0.0081566721200943, 0.04677767679095268, 0.020574571564793587, 0.018089190125465393, 0.016638459637761116, 0.024351509287953377, 0.014281010255217552, 0.022870568558573723, 0.024558424949645996, 0.021522244438529015, 0.02774011343717575, 0.01226317323744297, 0.016789689660072327, 0.030601773411035538, 0.03310445696115494, 0.04230615124106407, 0.05013416334986687, 0.0398956798017025, 0.02547144703567028, 0.03835652768611908, 0.1483658105134964, 0.04062194377183914, 0.012431968003511429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010402968153357506, 0.003988315816968679, 0.007536559831351042, 0.023714061826467514, 0.001574700465425849, 0.004556502215564251, 0.0011461445828899741, 0.0020206545013934374, 0.08388330787420273, 0.006093550939112902, 0.001224364503286779, 0.08011975139379501, 0.0032829283736646175, 0.1148514598608017, 0.020138537511229515, 0.003874026006087661, 0.1035565659403801, 0.016239913180470467, 0.006219515576958656, 0.011158781126141548, 0.12897233664989471, 0.016916092485189438, 0.008813071064651012, 0.02879595011472702, 0.060593508183956146, 0.005618593655526638, 0.01689356006681919, 0.008791645057499409, 0.01702239364385605, 0.20200031995773315, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05472036823630333, 0.015954433009028435, 0.012098252773284912, 0.022833745926618576, 0.018985209986567497, 0.02878388576209545, 0.008076782338321209, 0.00837206281721592, 0.039564043283462524, 0.012315311469137669, 0.009588333778083324, 0.023571286350488663, 0.010643107816576958, 0.046638455241918564, 0.014515889808535576, 0.012394601479172707, 0.027597345411777496, 0.021691447123885155, 0.02018054947257042, 0.01823921501636505, 0.05496657267212868, 0.037117861211299896, 0.024244992062449455, 0.03499603644013405, 0.1494767814874649, 0.029019519686698914, 0.043276429176330566, 0.01586642861366272, 0.04511541500687599, 0.11428384482860565, 0.024871760979294777, 0.0, 0.0, 0.0, 0.0], [0.028266312554478645, 0.008342591114342213, 0.00969315692782402, 0.024003302678465843, 0.012406976893544197, 0.009731607511639595, 0.007254773285239935, 0.011378856375813484, 0.045253440737724304, 0.014661090448498726, 0.0047598001547157764, 0.0327930673956871, 0.00959976576268673, 0.056626755744218826, 0.023795727640390396, 0.004614102188497782, 0.039821431040763855, 0.02123899757862091, 0.025286557152867317, 0.1015978753566742, 0.09278314560651779, 0.026123864576220512, 0.015091439709067345, 0.03458566963672638, 0.061821937561035156, 0.013406999409198761, 0.016889795660972595, 0.03089355118572712, 0.02819487266242504, 0.1103137731552124, 0.040569547563791275, 0.03819921985268593, 0.0, 0.0, 0.0], [0.005920093506574631, 0.0026448259595781565, 0.005754890386015177, 0.02199716307222843, 0.0013081274228170514, 0.0057265376672148705, 0.0008704040665179491, 0.0018940423615276814, 0.05295495316386223, 0.00472501153126359, 0.000999945099465549, 0.04342707619071007, 0.0021749832667410374, 0.07363719493150711, 0.017015766352415085, 0.0030869939364492893, 0.057790838181972504, 0.010734479874372482, 0.0034258204977959394, 0.010332699865102768, 0.08509067445993423, 0.012429160065948963, 0.0062302350997924805, 0.02222101017832756, 0.06411110609769821, 0.005053483881056309, 0.018152382224798203, 0.007594150956720114, 0.00678644236177206, 0.16716450452804565, 0.013871803879737854, 0.014755625277757645, 0.25011759996414185, 0.0, 0.0], [0.05958712846040726, 0.014287112280726433, 0.009688673540949821, 0.02847461961209774, 0.02860480733215809, 0.02625933475792408, 0.008819644339382648, 0.022136040031909943, 0.017910216003656387, 0.026397546753287315, 0.017243586480617523, 0.025983817875385284, 0.006316178943961859, 0.020043162629008293, 0.015440615825355053, 0.02594028040766716, 0.03010302595794201, 0.018365345895290375, 0.02313040941953659, 0.02621457912027836, 0.03115726262331009, 0.02898617461323738, 0.02896127849817276, 0.016435232013463974, 0.03480091318488121, 0.03794369101524353, 0.07380679249763489, 0.030772415921092033, 0.028517259284853935, 0.07387096434831619, 0.02458772249519825, 0.03523411974310875, 0.08090808242559433, 0.023072004318237305, 0.0], [0.052589885890483856, 0.008282378315925598, 0.004686589818447828, 0.011556105688214302, 0.0021243582013994455, 0.007376658730208874, 0.0025699096731841564, 0.005167305935174227, 0.06430475413799286, 0.008688683621585369, 0.004349816124886274, 0.05405206233263016, 0.0035673303063958883, 0.08101724088191986, 0.021457016468048096, 0.00414407579228282, 0.06621561199426651, 0.01871693693101406, 0.009488226845860481, 0.006038543302565813, 0.10274305194616318, 0.01456521637737751, 0.009106305427849293, 0.021657666191458702, 0.035247985273599625, 0.004852632526308298, 0.00842215958982706, 0.019589493051171303, 0.011885891668498516, 0.14464659988880157, 0.016607562080025673, 0.0228347759693861, 0.08476629108190536, 0.015126866288483143, 0.051554061472415924]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8803902268409729, 0.1196097582578659, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.800162672996521, 0.14422567188739777, 0.055611640214920044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6471941471099854, 0.14701780676841736, 0.0793100968003273, 0.12647798657417297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6291002035140991, 0.1326994001865387, 0.0830739364027977, 0.10306606441736221, 0.05206044018268585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5631014108657837, 0.1237594410777092, 0.11159723252058029, 0.10842733830213547, 0.08343346416950226, 0.00968119502067566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4973389506340027, 0.11400076746940613, 0.07851860672235489, 0.10408835858106613, 0.08229988813400269, 0.087201789021492, 0.03655165061354637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4618663191795349, 0.10720601677894592, 0.07680260390043259, 0.09525883942842484, 0.11179576814174652, 0.04683659225702286, 0.0632898211479187, 0.03694411367177963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.408801794052124, 0.11223535984754562, 0.06194951385259628, 0.08138209581375122, 0.06888709962368011, 0.04759940505027771, 0.05779567360877991, 0.06300585716962814, 0.09834323078393936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.337785542011261, 0.07768955826759338, 0.061640240252017975, 0.08030419796705246, 0.09243477135896683, 0.12569792568683624, 0.043102774769067764, 0.08006506413221359, 0.08753130584955215, 0.013748610392212868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40844571590423584, 0.07972615957260132, 0.05943280830979347, 0.07098965346813202, 0.06258382648229599, 0.07298710942268372, 0.05290914699435234, 0.06663116812705994, 0.08486583083868027, 0.03078524023294449, 0.010643370449543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32840877771377563, 0.0812605619430542, 0.052221160382032394, 0.06670200079679489, 0.06221218779683113, 0.04688328877091408, 0.04748225957155228, 0.04943712428212166, 0.08644373714923859, 0.051085103303194046, 0.046604085713624954, 0.08125966042280197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28456372022628784, 0.07334227114915848, 0.059566255658864975, 0.05995683744549751, 0.06261258572340012, 0.04492250457406044, 0.0535489022731781, 0.055395226925611496, 0.0760505273938179, 0.05439150333404541, 0.05521009489893913, 0.0848141685128212, 0.03562537580728531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2986924648284912, 0.0805349051952362, 0.04630004242062569, 0.058416131883859634, 0.05245250463485718, 0.03589676693081856, 0.0431300513446331, 0.04816412553191185, 0.07179586589336395, 0.03588227927684784, 0.034986354410648346, 0.0663861408829689, 0.047498900443315506, 0.07986355572938919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26184871792793274, 0.06895224750041962, 0.046620942652225494, 0.05860462039709091, 0.046928782016038895, 0.05568014085292816, 0.04915205389261246, 0.041177790611982346, 0.07490761578083038, 0.03198425471782684, 0.03257223963737488, 0.07257073372602463, 0.0373988002538681, 0.08542974293231964, 0.03617140278220177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29417476058006287, 0.05360917001962662, 0.03860875591635704, 0.04952671751379967, 0.04060918465256691, 0.04149327054619789, 0.029716242104768753, 0.04536982253193855, 0.06024932488799095, 0.04159967601299286, 0.06637392938137054, 0.05982464924454689, 0.04050293564796448, 0.06734268367290497, 0.06095736101269722, 0.010041493922472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24078045785427094, 0.05731501802802086, 0.038129791617393494, 0.04762376472353935, 0.04672614857554436, 0.03515475615859032, 0.03462181240320206, 0.0374724343419075, 0.062347814440727234, 0.039545461535453796, 0.03574430197477341, 0.05874500796198845, 0.034078449010849, 0.07071570307016373, 0.05439116060733795, 0.03945149853825569, 0.06715653091669083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19008119404315948, 0.055469147861003876, 0.03824985772371292, 0.04468470439314842, 0.043491899967193604, 0.03729136660695076, 0.035000305622816086, 0.03413337469100952, 0.05614841729402542, 0.029018189758062363, 0.026478588581085205, 0.06265050172805786, 0.035022031515836716, 0.06568853557109833, 0.057141948491334915, 0.047816332429647446, 0.07356444001197815, 0.06806916743516922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23406487703323364, 0.04765680059790611, 0.03626636788249016, 0.04350152239203453, 0.04482332617044449, 0.030926167964935303, 0.024145551025867462, 0.03047105111181736, 0.05100265145301819, 0.0385214164853096, 0.04128359258174896, 0.05289095640182495, 0.027892809361219406, 0.057388775050640106, 0.060669999569654465, 0.043871063739061356, 0.05933022499084473, 0.051170188933610916, 0.024122707545757294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31211698055267334, 0.04305700212717056, 0.030739204958081245, 0.03990122303366661, 0.040739163756370544, 0.033973559737205505, 0.013991206884384155, 0.032501690089702606, 0.042142946273088455, 0.03136738762259483, 0.05722319334745407, 0.04209974408149719, 0.03285329043865204, 0.0466272234916687, 0.04874774441123009, 0.021730609238147736, 0.0472237728536129, 0.029857570305466652, 0.04530387744307518, 0.007802659645676613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19583052396774292, 0.05227474868297577, 0.032512083649635315, 0.037058908492326736, 0.04335429146885872, 0.027641311287879944, 0.02745206467807293, 0.033081553876399994, 0.045324407517910004, 0.02540675736963749, 0.02478162758052349, 0.03888050466775894, 0.030247308313846588, 0.05089510977268219, 0.041287779808044434, 0.037492137402296066, 0.04425322636961937, 0.04428721219301224, 0.045193951576948166, 0.05072397366166115, 0.07202056050300598, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16079990565776825, 0.04841072857379913, 0.03302096202969551, 0.03441706672310829, 0.03531978651881218, 0.02389703504741192, 0.026063483208417892, 0.02863972634077072, 0.04453873634338379, 0.024949487298727036, 0.02971615083515644, 0.04012998938560486, 0.024859080091118813, 0.051343925297260284, 0.05373540148139, 0.04527632147073746, 0.04680595546960831, 0.0346059687435627, 0.04245501756668091, 0.05485454201698303, 0.06976335495710373, 0.046397339552640915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18932510912418365, 0.039103638380765915, 0.024852009490132332, 0.033450495451688766, 0.038601573556661606, 0.02410929463803768, 0.020502109080553055, 0.02430175244808197, 0.03976472094655037, 0.034181684255599976, 0.03484785556793213, 0.03619782626628876, 0.023668944835662842, 0.0450248196721077, 0.03498944267630577, 0.026825537905097008, 0.041537925601005554, 0.03736662492156029, 0.04202279448509216, 0.05591040849685669, 0.06404419243335724, 0.05618632957339287, 0.03318498283624649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16596606373786926, 0.03388111665844917, 0.02065751887857914, 0.03212727978825569, 0.03747252747416496, 0.026519492268562317, 0.01988290622830391, 0.025609638541936874, 0.04091744124889374, 0.02261032722890377, 0.019720885902643204, 0.033765342086553574, 0.023503821343183517, 0.04644523933529854, 0.035414308309555054, 0.02736842818558216, 0.03876943141222, 0.03146073967218399, 0.04639927297830582, 0.048674724996089935, 0.06382153928279877, 0.06529749184846878, 0.04629906266927719, 0.04741538688540459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1551409363746643, 0.036314792931079865, 0.022236885502934456, 0.028097424656152725, 0.040156636387109756, 0.02405598573386669, 0.017400911077857018, 0.021498549729585648, 0.036750685423612595, 0.017986753955483437, 0.01970391348004341, 0.02832779847085476, 0.022604605183005333, 0.04168052598834038, 0.030497957020998, 0.02558559738099575, 0.032487597316503525, 0.027014944702386856, 0.04112286865711212, 0.04738449677824974, 0.0638234093785286, 0.05655010789632797, 0.04119998589158058, 0.06263258308172226, 0.059744056314229965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12975940108299255, 0.02733970619738102, 0.029957516118884087, 0.022702837362885475, 0.03781532496213913, 0.03144636005163193, 0.01713675446808338, 0.046564918011426926, 0.030618296936154366, 0.018781673163175583, 0.025273185223340988, 0.028721965849399567, 0.019090944901108742, 0.034810010343790054, 0.026170214638113976, 0.02681773342192173, 0.03296039626002312, 0.024960245937108994, 0.05474759265780449, 0.05780106037855148, 0.056176237761974335, 0.03305984288454056, 0.05767423287034035, 0.04667418450117111, 0.06228700280189514, 0.02065235935151577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18126998841762543, 0.02792493812739849, 0.028055911883711815, 0.029457401484251022, 0.028532737866044044, 0.020307771861553192, 0.019550155848264694, 0.03153110668063164, 0.029232848435640335, 0.021110523492097855, 0.014580837450921535, 0.02250531129539013, 0.016256751492619514, 0.031508829444646835, 0.024519702419638634, 0.036590538918972015, 0.02503451704978943, 0.020030668005347252, 0.04726612567901611, 0.12142348289489746, 0.0418962687253952, 0.03646089881658554, 0.03734690696001053, 0.03705745190382004, 0.03521091863512993, 0.024784501641988754, 0.010552848689258099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1419323980808258, 0.026873420923948288, 0.02339440956711769, 0.02419888973236084, 0.034410905092954636, 0.031768202781677246, 0.014282822608947754, 0.02788499742746353, 0.027823273092508316, 0.02026795595884323, 0.020075345411896706, 0.02603541687130928, 0.015271061100065708, 0.03118356503546238, 0.02134445682168007, 0.030780881643295288, 0.029686488211154938, 0.024966171011328697, 0.03290622681379318, 0.0812656581401825, 0.04738020524382591, 0.039504993706941605, 0.038106050342321396, 0.03920022025704384, 0.04723040759563446, 0.03223776817321777, 0.04768496751785278, 0.022302795201539993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19361069798469543, 0.028910450637340546, 0.017410719767212868, 0.024991964921355247, 0.020412277430295944, 0.03692353144288063, 0.018564047291874886, 0.022491104900836945, 0.026469895616173744, 0.019851719960570335, 0.01670689508318901, 0.02012959122657776, 0.01730293594300747, 0.02887752279639244, 0.01937028579413891, 0.021512914448976517, 0.022604653611779213, 0.019465498626232147, 0.03218545764684677, 0.09415604919195175, 0.03964082896709442, 0.04692870005965233, 0.032965511083602905, 0.03432747721672058, 0.03549889475107193, 0.041524238884449005, 0.03800847381353378, 0.0241937804967165, 0.004963916726410389, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13062259554862976, 0.029238134622573853, 0.02056247554719448, 0.024924930185079575, 0.02643335983157158, 0.02088005468249321, 0.016895074397325516, 0.020366204902529716, 0.03079468198120594, 0.016811516135931015, 0.014352641068398952, 0.026399681344628334, 0.017968151718378067, 0.03419144079089165, 0.025793632492423058, 0.020880060270428658, 0.029983337968587875, 0.02257682941854, 0.03198401629924774, 0.0387752391397953, 0.047299277037382126, 0.03951811045408249, 0.03569554165005684, 0.04647783935070038, 0.045603714883327484, 0.027694011107087135, 0.028376277536153793, 0.029506998136639595, 0.03388816863298416, 0.06550603359937668, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10399015247821808, 0.021966131404042244, 0.016451170668005943, 0.022787997499108315, 0.024357151240110397, 0.01997542940080166, 0.013678611256182194, 0.02052461728453636, 0.026416651904582977, 0.015824992209672928, 0.01812475547194481, 0.02293805591762066, 0.015249832533299923, 0.029951756820082664, 0.01956864260137081, 0.017790069803595543, 0.02633139118552208, 0.02006237581372261, 0.030405649915337563, 0.05837805196642876, 0.047469500452280045, 0.03560005873441696, 0.03361857682466507, 0.039051610976457596, 0.046234603971242905, 0.03415834531188011, 0.050636325031518936, 0.03304954990744591, 0.04132762551307678, 0.06007478013634682, 0.034005582332611084, 0.0, 0.0, 0.0, 0.0], [0.10689456015825272, 0.023425230756402016, 0.018311114981770515, 0.022276202216744423, 0.01998625323176384, 0.018345674499869347, 0.01589350402355194, 0.019802745431661606, 0.02582935430109501, 0.016079485416412354, 0.016656851395964622, 0.02581821195781231, 0.012892832048237324, 0.029111431911587715, 0.020739194005727768, 0.017621522769331932, 0.02965444140136242, 0.024281146004796028, 0.028045890852808952, 0.052053969353437424, 0.042631059885025024, 0.032518111169338226, 0.037380315363407135, 0.038434360176324844, 0.03982122987508774, 0.02629014290869236, 0.035206388682127, 0.031386300921440125, 0.03282344341278076, 0.061947017908096313, 0.03762543573975563, 0.0402165949344635, 0.0, 0.0, 0.0], [0.1222902163863182, 0.025168992578983307, 0.0167140644043684, 0.022033261135220528, 0.02300073206424713, 0.015408726409077644, 0.01495801005512476, 0.018676765263080597, 0.026191173121333122, 0.012370300479233265, 0.01071577612310648, 0.021631909534335136, 0.013984637334942818, 0.028899209573864937, 0.02320098504424095, 0.018216606229543686, 0.024281233549118042, 0.018235325813293457, 0.02165396697819233, 0.03633745014667511, 0.03855650871992111, 0.036919448524713516, 0.03379227593541145, 0.042588260024785995, 0.038391564041376114, 0.023295771330595016, 0.030805258080363274, 0.024493301287293434, 0.03010578453540802, 0.05652609094977379, 0.03756684064865112, 0.041599173098802567, 0.051390379667282104, 0.0, 0.0], [0.13871710002422333, 0.021967235952615738, 0.016682986170053482, 0.02155137062072754, 0.02604922093451023, 0.015379129908978939, 0.012522305361926556, 0.020025212317705154, 0.021879851818084717, 0.014553073793649673, 0.015628252178430557, 0.018288593739271164, 0.012421748600900173, 0.02363341860473156, 0.017220674082636833, 0.02009168639779091, 0.02015187218785286, 0.018530186265707016, 0.02421249821782112, 0.07234082370996475, 0.034239377826452255, 0.03014705888926983, 0.03145884349942207, 0.03020295687019825, 0.03094874508678913, 0.024833211675286293, 0.030743280425667763, 0.022636577486991882, 0.044566888362169266, 0.04173137620091438, 0.028924651443958282, 0.0298653244972229, 0.04288143664598465, 0.024973025545477867, 0.0], [0.12327979505062103, 0.02670745551586151, 0.014834707602858543, 0.018021514639258385, 0.017764987424016, 0.013351654633879662, 0.014073802158236504, 0.018723031505942345, 0.023980097845196724, 0.02125631459057331, 0.017004812136292458, 0.020616674795746803, 0.012905535288155079, 0.02609744668006897, 0.021554267033934593, 0.015845784917473793, 0.022780926898121834, 0.023595377802848816, 0.019861740991473198, 0.021922385320067406, 0.035971157252788544, 0.03369682654738426, 0.021171672269701958, 0.03536052629351616, 0.03450924903154373, 0.021897653117775917, 0.035124264657497406, 0.024112919345498085, 0.03299052640795708, 0.04677635431289673, 0.03042444959282875, 0.03270317614078522, 0.03790725767612457, 0.042624931782484055, 0.04055079445242882]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6533873081207275, 0.34661269187927246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4451117515563965, 0.33376824855804443, 0.22111999988555908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5459808111190796, 0.15291067957878113, 0.0764545276761055, 0.2246539443731308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.42720285058021545, 0.1412525624036789, 0.06143973022699356, 0.11979994177818298, 0.2503049373626709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4097931385040283, 0.11732907593250275, 0.06548825651407242, 0.1236746683716774, 0.042223721742630005, 0.24149122834205627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3643514811992645, 0.15547122061252594, 0.08527875691652298, 0.0883261039853096, 0.04993733763694763, 0.034096237272024155, 0.22253888845443726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3562685251235962, 0.09063339978456497, 0.05006815120577812, 0.10755760222673416, 0.06895481050014496, 0.04669608548283577, 0.04097530245780945, 0.23884613811969757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3461388945579529, 0.1456225961446762, 0.09470635652542114, 0.10499643534421921, 0.06400176137685776, 0.04047239571809769, 0.03757920861244202, 0.044482164084911346, 0.12200023233890533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20510229468345642, 0.04824315756559372, 0.05157081410288811, 0.09953971952199936, 0.06673121452331543, 0.045586880296468735, 0.036483921110630035, 0.08169860392808914, 0.08583585917949677, 0.2792075574398041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2301696091890335, 0.07576316595077515, 0.06243027001619339, 0.0619683712720871, 0.050248246639966965, 0.03796260058879852, 0.05770514905452728, 0.05617325380444527, 0.06585752964019775, 0.041665587574243546, 0.2600562572479248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2668822407722473, 0.0996926873922348, 0.06880498677492142, 0.10110108554363251, 0.036257676780223846, 0.048760298639535904, 0.0317954495549202, 0.03426745906472206, 0.09192278236150742, 0.044060155749320984, 0.024279987439513206, 0.1521751582622528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24808602035045624, 0.059437572956085205, 0.03645307198166847, 0.09643887728452682, 0.046652551740407944, 0.043580614030361176, 0.026409661397337914, 0.03871847689151764, 0.06937099248170853, 0.035532157868146896, 0.02358422242105007, 0.05824919044971466, 0.21748659014701843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22227585315704346, 0.08784300088882446, 0.06428327411413193, 0.07245952636003494, 0.05153008922934532, 0.033541660755872726, 0.03151150047779083, 0.04395980015397072, 0.10531803220510483, 0.036292850971221924, 0.03349635377526283, 0.07923727482557297, 0.034966107457876205, 0.10328467935323715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2625541090965271, 0.07451014220714569, 0.04962189123034477, 0.0651395246386528, 0.0221824049949646, 0.03923412784934044, 0.021433904767036438, 0.02829248644411564, 0.06496232002973557, 0.02216963656246662, 0.018070971593260765, 0.05796553194522858, 0.01818801648914814, 0.061765071004629135, 0.1939098834991455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2145461142063141, 0.052079539746046066, 0.04338602349162102, 0.05108674615621567, 0.02305704355239868, 0.03987296298146248, 0.021457547321915627, 0.0431031696498394, 0.057124003767967224, 0.04732410982251167, 0.020076345652341843, 0.04863850027322769, 0.03173767402768135, 0.05389070883393288, 0.03922812268137932, 0.21339140832424164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1693464070558548, 0.057584747672080994, 0.04318230599164963, 0.06501621752977371, 0.025769712403416634, 0.03584059700369835, 0.02340392768383026, 0.028633082285523415, 0.06884393841028214, 0.037356141954660416, 0.021079324185848236, 0.12265526503324509, 0.02518490143120289, 0.07096560299396515, 0.049235545098781586, 0.02845790982246399, 0.12744441628456116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1294490545988083, 0.04351517930626869, 0.028707342222332954, 0.045572564005851746, 0.02128218673169613, 0.019885340705513954, 0.02885768935084343, 0.034781116992235184, 0.05532592535018921, 0.030885061249136925, 0.021087544038891792, 0.06504063308238983, 0.040431585162878036, 0.05797602981328964, 0.041369806975126266, 0.028544064611196518, 0.06784919649362564, 0.23943956196308136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14163610339164734, 0.035789649933576584, 0.028365224599838257, 0.045387569814920425, 0.046378400176763535, 0.039788711816072464, 0.014343786984682083, 0.04959797486662865, 0.04732619225978851, 0.03078245185315609, 0.018412165343761444, 0.04871037229895592, 0.023401634767651558, 0.04745563864707947, 0.03751209378242493, 0.023782698437571526, 0.04894063621759415, 0.03379067778587341, 0.2385980188846588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13350321352481842, 0.03222055360674858, 0.020588897168636322, 0.03780217468738556, 0.041080109775066376, 0.03671092167496681, 0.02595440298318863, 0.04136638715863228, 0.0432656928896904, 0.030096465721726418, 0.02681291103363037, 0.04010695964097977, 0.024385904893279076, 0.04430919885635376, 0.0337374247610569, 0.020710932090878487, 0.04079743102192879, 0.032650165259838104, 0.03506242856383324, 0.25883781909942627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11974351853132248, 0.03914882615208626, 0.028956560418009758, 0.03342708200216293, 0.03769591823220253, 0.02054389752447605, 0.017558956518769264, 0.0326584093272686, 0.06372418254613876, 0.03310192748904228, 0.02986794151365757, 0.053869180381298065, 0.022512974217534065, 0.07236674427986145, 0.041434258222579956, 0.03790142014622688, 0.060026224702596664, 0.045860208570957184, 0.05091095343232155, 0.031955886632204056, 0.1267348974943161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11878620088100433, 0.039572037756443024, 0.023222973570227623, 0.053640808910131454, 0.03261678293347359, 0.01737094670534134, 0.011663902550935745, 0.016273820772767067, 0.05014302209019661, 0.013260259293019772, 0.010486903600394726, 0.03813209384679794, 0.041936684399843216, 0.05336224287748337, 0.030979996547102928, 0.019617725163698196, 0.040241554379463196, 0.03244160860776901, 0.020540131255984306, 0.026845518499612808, 0.057711102068424225, 0.25115370750427246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1059650108218193, 0.03639821708202362, 0.023730656132102013, 0.027703464031219482, 0.029520340263843536, 0.016958512365818024, 0.009277221746742725, 0.01928117871284485, 0.04353448376059532, 0.02543572708964348, 0.01544106099754572, 0.041617251932621, 0.01847231760621071, 0.04617343842983246, 0.026975221931934357, 0.016877293586730957, 0.0436592698097229, 0.020190216600894928, 0.01864578016102314, 0.016359714791178703, 0.05703481286764145, 0.06433958560228348, 0.2764091193675995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08669395744800568, 0.14005154371261597, 0.05404343083500862, 0.026910433545708656, 0.026933513581752777, 0.016936616972088814, 0.01752724125981331, 0.011132637038826942, 0.033167172223329544, 0.009116588160395622, 0.014021697454154491, 0.028125261887907982, 0.012107602320611477, 0.036274366080760956, 0.030991656705737114, 0.015099079348146915, 0.030221451073884964, 0.020815491676330566, 0.018955036997795105, 0.021182602271437645, 0.04364988952875137, 0.043773479759693146, 0.025040630251169205, 0.23722875118255615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10505460947751999, 0.02472284995019436, 0.0234385933727026, 0.02425646223127842, 0.021477708593010902, 0.014111106283962727, 0.012018014676868916, 0.01570729911327362, 0.042195845395326614, 0.016803372651338577, 0.011159355752170086, 0.031271807849407196, 0.020320700481534004, 0.04702335223555565, 0.03988678380846977, 0.02585337497293949, 0.03450959548354149, 0.024522606283426285, 0.017594216391444206, 0.021597158163785934, 0.06303170323371887, 0.05036986991763115, 0.026549141854047775, 0.040915295481681824, 0.24560922384262085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07146886736154556, 0.015683099627494812, 0.019199561327695847, 0.027655109763145447, 0.02588873915374279, 0.01149574015289545, 0.013834549114108086, 0.02500625140964985, 0.032857511192560196, 0.04069041460752487, 0.01940707117319107, 0.036282774060964584, 0.026671355590224266, 0.036988455802202225, 0.02539135329425335, 0.012203285470604897, 0.04081624001264572, 0.022441424429416656, 0.018680064007639885, 0.03714069351553917, 0.052913516759872437, 0.03374898433685303, 0.03600706905126572, 0.027396051213145256, 0.04157792031764984, 0.24855388700962067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09520062804222107, 0.023399099707603455, 0.016249947249889374, 0.03728703036904335, 0.027069469913840294, 0.02442619577050209, 0.016916709020733833, 0.02051924355328083, 0.03561446815729141, 0.0172467902302742, 0.016965176910161972, 0.030670618638396263, 0.014761796221137047, 0.037838954478502274, 0.02559020183980465, 0.013281547464430332, 0.03275727108120918, 0.01698147878050804, 0.012912825681269169, 0.040966760367155075, 0.04452374204993248, 0.032888542860746384, 0.021862011402845383, 0.02890506200492382, 0.025222204625606537, 0.015681952238082886, 0.2742602527141571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07106206566095352, 0.022234495729207993, 0.015442529693245888, 0.028806837275624275, 0.024911722168326378, 0.014096672646701336, 0.010925300419330597, 0.02235645242035389, 0.028251029551029205, 0.02592524141073227, 0.012314552441239357, 0.03621361032128334, 0.0176627729088068, 0.031407058238983154, 0.01859503984451294, 0.018171407282352448, 0.04006665199995041, 0.022728290408849716, 0.025000523775815964, 0.040149640291929245, 0.042498040944337845, 0.026281598955392838, 0.023634910583496094, 0.03034823201596737, 0.028446583077311516, 0.04931708052754402, 0.04533270001411438, 0.22781892120838165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1199868842959404, 0.03201314061880112, 0.020363762974739075, 0.03192231059074402, 0.020111488178372383, 0.017741892486810684, 0.014963151887059212, 0.014099691063165665, 0.0323602668941021, 0.012826558202505112, 0.01920422911643982, 0.024741895496845245, 0.014775938354432583, 0.03365084528923035, 0.032850779592990875, 0.015633022412657738, 0.0263309795409441, 0.009946919977664948, 0.010015270672738552, 0.02325468324124813, 0.03898429125547409, 0.03491940349340439, 0.011989152058959007, 0.03053087741136551, 0.02381373569369316, 0.018979022279381752, 0.06846079230308533, 0.019141536206007004, 0.22638748586177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0711139664053917, 0.023045020177960396, 0.01740783452987671, 0.025577742606401443, 0.018817277625203133, 0.014406666159629822, 0.01136450283229351, 0.019742926582694054, 0.0378037765622139, 0.01749836839735508, 0.012214533053338528, 0.0347118005156517, 0.016245104372501373, 0.0449482686817646, 0.031461041420698166, 0.01797626167535782, 0.040775004774332047, 0.026232007890939713, 0.02910453826189041, 0.032863155007362366, 0.06312329322099686, 0.03996739536523819, 0.03193744271993637, 0.05005760118365288, 0.050039853900671005, 0.02629847638309002, 0.04067576304078102, 0.034253496676683426, 0.03361441567540169, 0.08672250062227249, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06342680007219315, 0.01892857439815998, 0.015915194526314735, 0.022974470630288124, 0.01581357792019844, 0.011996154673397541, 0.006959729827940464, 0.010440586134791374, 0.027604442089796066, 0.014203780330717564, 0.011755010113120079, 0.02697419933974743, 0.015696220099925995, 0.03244095668196678, 0.02146400883793831, 0.01630021259188652, 0.0315910205245018, 0.018295634537935257, 0.024074891582131386, 0.018299629911780357, 0.04905861243605614, 0.03294462338089943, 0.031695034354925156, 0.04070066660642624, 0.05526785925030708, 0.032283999025821686, 0.01833721622824669, 0.020621933043003082, 0.020615674555301666, 0.061421554535627365, 0.21189774572849274, 0.0, 0.0, 0.0, 0.0], [0.05903123691678047, 0.011650343425571918, 0.011906319297850132, 0.020305125042796135, 0.01582454890012741, 0.011342637240886688, 0.012165091000497341, 0.020514555275440216, 0.02463514171540737, 0.01787753403186798, 0.008976954035460949, 0.027097536250948906, 0.010151371359825134, 0.029500098899006844, 0.022961733862757683, 0.01152713131159544, 0.032491881400346756, 0.020219076424837112, 0.020271260291337967, 0.027604976668953896, 0.04230695217847824, 0.02292037196457386, 0.027398396283388138, 0.02483934722840786, 0.0284199807792902, 0.04172161966562271, 0.0314212366938591, 0.035203300416469574, 0.03063124231994152, 0.060064759105443954, 0.04537738487124443, 0.19364091753959656, 0.0, 0.0, 0.0], [0.08590573072433472, 0.014704103581607342, 0.01051056943833828, 0.02869984321296215, 0.016654495149850845, 0.012795396149158478, 0.00923528429120779, 0.014819213189184666, 0.028232717886567116, 0.011867675930261612, 0.009268179535865784, 0.023044349625706673, 0.01755327358841896, 0.03295404091477394, 0.025013737380504608, 0.012247500009834766, 0.02679956890642643, 0.013326536864042282, 0.016479836776852608, 0.034728217869997025, 0.039808012545108795, 0.050673384219408035, 0.030861180275678635, 0.027551840990781784, 0.036164212971925735, 0.01740611530840397, 0.04716060683131218, 0.02589184232056141, 0.028397290036082268, 0.060471389442682266, 0.03584858030080795, 0.03886668011546135, 0.11605865508317947, 0.0, 0.0], [0.056707724928855896, 0.015243272297084332, 0.009892582893371582, 0.017495427280664444, 0.03529244661331177, 0.015370235778391361, 0.010747749358415604, 0.01709159091114998, 0.02124500647187233, 0.013064504601061344, 0.006394116207957268, 0.021768178790807724, 0.011015364900231361, 0.023290839046239853, 0.02097102627158165, 0.012346651405096054, 0.024119649082422256, 0.013815038837492466, 0.016820495948195457, 0.0345151424407959, 0.030974796041846275, 0.032177556306123734, 0.03227026388049126, 0.02327035181224346, 0.027259422466158867, 0.01785033755004406, 0.05776430293917656, 0.024271585047245026, 0.02524302899837494, 0.03774581104516983, 0.015895819291472435, 0.02659658156335354, 0.04215161129832268, 0.20932146906852722, 0.0], [0.04736970737576485, 0.013491550460457802, 0.008601199835538864, 0.0115343714132905, 0.032609522342681885, 0.008750014938414097, 0.01049541775137186, 0.01597345992922783, 0.024224916473031044, 0.013959750533103943, 0.011584165506064892, 0.020906997844576836, 0.01231019664555788, 0.028499379754066467, 0.01440323144197464, 0.011428188532590866, 0.024424532428383827, 0.021284053102135658, 0.027576277032494545, 0.025762224569916725, 0.04914955049753189, 0.02154945582151413, 0.020725881680846214, 0.030232436954975128, 0.04683733731508255, 0.02172248065471649, 0.02025720477104187, 0.0191495418548584, 0.01053390558809042, 0.050025925040245056, 0.030405569821596146, 0.022812239825725555, 0.029462482780218124, 0.03996318578720093, 0.20198364555835724]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8253121972084045, 0.17468774318695068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.758050262928009, 0.1302967667579651, 0.1116529181599617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7232240438461304, 0.0827442929148674, 0.0787082314491272, 0.11532339453697205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5594542622566223, 0.08694439381361008, 0.09115545451641083, 0.09393441677093506, 0.1685115247964859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5031396150588989, 0.08192656934261322, 0.05872314050793648, 0.10480903834104538, 0.15214206278324127, 0.09925960004329681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.527961015701294, 0.058259785175323486, 0.0683659166097641, 0.11652132123708725, 0.11039452999830246, 0.06918037682771683, 0.049317046999931335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30010077357292175, 0.08826003223657608, 0.058349307626485825, 0.10984236747026443, 0.16862627863883972, 0.12896907329559326, 0.023227617144584656, 0.12262453883886337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39344045519828796, 0.047586165368556976, 0.051949672400951385, 0.07471577078104019, 0.11950989067554474, 0.05938040092587471, 0.02336861379444599, 0.1026640459895134, 0.12738502025604248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3446025848388672, 0.05032900348305702, 0.059913281351327896, 0.0448312982916832, 0.1573815494775772, 0.06782464683055878, 0.03229009732604027, 0.07052529603242874, 0.0895390436053276, 0.08276323974132538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33508479595184326, 0.046269986778497696, 0.04785764589905739, 0.10917432606220245, 0.04435233771800995, 0.044907256960868835, 0.028443867340683937, 0.07920616865158081, 0.10731324553489685, 0.06832481920719147, 0.08906552940607071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31157222390174866, 0.03927762433886528, 0.03521272912621498, 0.0755099207162857, 0.08078575879335403, 0.045036908239126205, 0.028806500136852264, 0.10218671709299088, 0.08797682821750641, 0.05585259199142456, 0.08571923524141312, 0.05206298828125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3614695072174072, 0.06311224400997162, 0.026989933103322983, 0.07095801085233688, 0.039851728826761246, 0.029446521773934364, 0.022796358913183212, 0.07072699815034866, 0.11304391175508499, 0.033355191349983215, 0.03714420646429062, 0.047639429569244385, 0.08346597850322723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26885920763015747, 0.032650742679834366, 0.039381857961416245, 0.05081145092844963, 0.08684232831001282, 0.043101999908685684, 0.017922356724739075, 0.06655361503362656, 0.07785408943891525, 0.04528900608420372, 0.06586872786283493, 0.0460660345852375, 0.07721763849258423, 0.08158091455698013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2079053372144699, 0.03081468679010868, 0.029462959617376328, 0.05067421495914459, 0.0874347910284996, 0.04770583286881447, 0.027333196252584457, 0.09152103960514069, 0.052141424268484116, 0.04708248749375343, 0.0808199942111969, 0.05453275144100189, 0.12074840068817139, 0.05516169220209122, 0.01666119694709778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19932863116264343, 0.042067065834999084, 0.05715767666697502, 0.07193329930305481, 0.05065883696079254, 0.031524576246738434, 0.02713681571185589, 0.04140906035900116, 0.0932227149605751, 0.0520220510661602, 0.0254228338599205, 0.059279121458530426, 0.06613775342702866, 0.0958227589726448, 0.03163214772939682, 0.05524465814232826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2371978908777237, 0.030675802379846573, 0.029208479449152946, 0.05821239948272705, 0.06082985922694206, 0.03495608642697334, 0.024440526962280273, 0.07084920257329941, 0.05983857437968254, 0.03970346227288246, 0.05932591110467911, 0.03675238788127899, 0.07694025337696075, 0.06171642988920212, 0.014049737714231014, 0.06745626032352448, 0.037846650928258896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2499532252550125, 0.02662949077785015, 0.03931759297847748, 0.044632140547037125, 0.07087574899196625, 0.03409421071410179, 0.02126503549516201, 0.05726420879364014, 0.05179663747549057, 0.03503985330462456, 0.0439227856695652, 0.03922875225543976, 0.061559129506349564, 0.051224227994680405, 0.015611971728503704, 0.08278115093708038, 0.0389174185693264, 0.03588636592030525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22269797325134277, 0.02651812881231308, 0.03978949785232544, 0.02760399878025055, 0.08196066319942474, 0.03582965210080147, 0.015378961339592934, 0.0687466412782669, 0.05343083664774895, 0.05469822511076927, 0.05721570551395416, 0.03161529079079628, 0.037170711904764175, 0.05228295922279358, 0.011851186864078045, 0.0720609799027443, 0.03087829239666462, 0.0244111530482769, 0.05585915967822075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07419290393590927, 0.050926994532346725, 0.02823096513748169, 0.03420006111264229, 0.03361425921320915, 0.05182219296693802, 0.009658378548920155, 0.04940611496567726, 0.09883320331573486, 0.05356482416391373, 0.02458188310265541, 0.05879184231162071, 0.013026786036789417, 0.10889022052288055, 0.01567711867392063, 0.04766633361577988, 0.06507277488708496, 0.03886169567704201, 0.039842639118433, 0.10313881933689117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22614890336990356, 0.025769872590899467, 0.03336167708039284, 0.04034486413002014, 0.06116844713687897, 0.03166025131940842, 0.023036977276206017, 0.048158254474401474, 0.04964131489396095, 0.02570328302681446, 0.05132424086332321, 0.02922578901052475, 0.04627235606312752, 0.046795472502708435, 0.010471493005752563, 0.04346739873290062, 0.027977747842669487, 0.03356108069419861, 0.03209925815463066, 0.05562403425574303, 0.058187272399663925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1944299191236496, 0.02000579982995987, 0.025669975206255913, 0.027610063552856445, 0.07351990044116974, 0.02511858008801937, 0.016428446397185326, 0.05443365499377251, 0.044502682983875275, 0.022272862493991852, 0.029331279918551445, 0.03064262494444847, 0.06286598742008209, 0.04339165240526199, 0.010216005146503448, 0.09763482213020325, 0.02960141748189926, 0.02808045968413353, 0.037571631371974945, 0.050374019891023636, 0.06089741364121437, 0.015400813892483711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19766584038734436, 0.04115749150514603, 0.03360117971897125, 0.023870175704360008, 0.06633444875478745, 0.028016984462738037, 0.019582947716116905, 0.05178564786911011, 0.03159147500991821, 0.02653615176677704, 0.041643161326646805, 0.025757962837815285, 0.04328406974673271, 0.029939444735646248, 0.012750310823321342, 0.05606916919350624, 0.0246773399412632, 0.02150590717792511, 0.04559294506907463, 0.07480884343385696, 0.0443340539932251, 0.02199736423790455, 0.03749702870845795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18043573200702667, 0.023349832743406296, 0.023929744958877563, 0.04454164579510689, 0.04070593789219856, 0.03654100000858307, 0.0166165828704834, 0.05323559418320656, 0.050283897668123245, 0.02584688924252987, 0.04605168476700783, 0.024920549243688583, 0.03976092487573624, 0.04893423989415169, 0.012390012852847576, 0.06191657483577728, 0.023965338245034218, 0.028754496946930885, 0.025095410645008087, 0.06865919381380081, 0.0735766589641571, 0.018046917393803596, 0.022800736129283905, 0.009640371426939964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24246364831924438, 0.024696456268429756, 0.038688257336616516, 0.03357228636741638, 0.054766181856393814, 0.033804669976234436, 0.02072160691022873, 0.032754622399806976, 0.043499793857336044, 0.01856265589594841, 0.036468490958213806, 0.031002476811408997, 0.03862547501921654, 0.03993181139230728, 0.010727159678936005, 0.03831769898533821, 0.029280314221978188, 0.02467813901603222, 0.027889320626854897, 0.04502156749367714, 0.04307597503066063, 0.016905827447772026, 0.023586302995681763, 0.0072986227460205555, 0.04366062581539154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11111285537481308, 0.02945876680314541, 0.02455945685505867, 0.030902516096830368, 0.033864814788103104, 0.03363063931465149, 0.012831446714699268, 0.030669275671243668, 0.06390531361103058, 0.023481516167521477, 0.02570461481809616, 0.037669774144887924, 0.016167862340807915, 0.06660737097263336, 0.01723175123333931, 0.03065866231918335, 0.03924046456813812, 0.02429523505270481, 0.02638879418373108, 0.0586402527987957, 0.10666140913963318, 0.017623893916606903, 0.024245429784059525, 0.018279599025845528, 0.036750201135873795, 0.05941800773143768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1785520762205124, 0.04373873397707939, 0.027772290632128716, 0.03288250416517258, 0.08083147555589676, 0.036148540675640106, 0.01943814381957054, 0.036047156900167465, 0.03154062479734421, 0.02228383719921112, 0.02674206532537937, 0.020272957161068916, 0.04929490014910698, 0.028057046234607697, 0.010035552084445953, 0.02821901999413967, 0.01852661930024624, 0.025377940386533737, 0.039212290197610855, 0.05273988097906113, 0.024735096842050552, 0.0286747757345438, 0.029405992478132248, 0.013893152587115765, 0.01760646514594555, 0.05648736283183098, 0.02148348279297352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15546509623527527, 0.04916935786604881, 0.02451593615114689, 0.0257005225867033, 0.054831281304359436, 0.04209273308515549, 0.011645035818219185, 0.06493962556123734, 0.03121974878013134, 0.026562783867120743, 0.028326857835054398, 0.018289053812623024, 0.034908607602119446, 0.02966099977493286, 0.008558587171137333, 0.046650480479002, 0.01766982302069664, 0.023724375292658806, 0.019038736820220947, 0.0771576464176178, 0.027307383716106415, 0.019747741520404816, 0.024364113807678223, 0.014429943636059761, 0.018928347155451775, 0.058505598455667496, 0.024364061653614044, 0.02222543954849243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19332920014858246, 0.02629835531115532, 0.030392471700906754, 0.029611894860863686, 0.045201625674963, 0.033079080283641815, 0.021840767934918404, 0.026594161987304688, 0.04538281634449959, 0.03843945637345314, 0.026915403082966805, 0.024535102769732475, 0.015795713290572166, 0.04036761075258255, 0.01063427235931158, 0.02634548768401146, 0.022409789264202118, 0.019946040585637093, 0.044018518179655075, 0.06709349155426025, 0.03345475718379021, 0.0160849429666996, 0.02561587281525135, 0.011409515514969826, 0.013623220846056938, 0.04055492952466011, 0.01666298136115074, 0.03589887544512749, 0.018463704735040665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15965193510055542, 0.018642345443367958, 0.026677701622247696, 0.028047846630215645, 0.04907771572470665, 0.026045678183436394, 0.017807701602578163, 0.03679424151778221, 0.045969437807798386, 0.01911088638007641, 0.03796321153640747, 0.027620621025562286, 0.028341030701994896, 0.04296436905860901, 0.008847585879266262, 0.03253019601106644, 0.02565997838973999, 0.024485120549798012, 0.029966212809085846, 0.04054072126746178, 0.042335040867328644, 0.017694558948278427, 0.021217679604887962, 0.006380947772413492, 0.031033916398882866, 0.03557972237467766, 0.025066189467906952, 0.02660750038921833, 0.024308422580361366, 0.043031513690948486, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1966170072555542, 0.019791381433606148, 0.033033329993486404, 0.0256870836019516, 0.042206063866615295, 0.03137584030628204, 0.016243640333414078, 0.030698411166667938, 0.03629426658153534, 0.026839347556233406, 0.026712186634540558, 0.023046309128403664, 0.021950094029307365, 0.03344836086034775, 0.010305729694664478, 0.02274365723133087, 0.021480794996023178, 0.02109473943710327, 0.03149040415883064, 0.03692731261253357, 0.03723211959004402, 0.015422001481056213, 0.019252333790063858, 0.00732048787176609, 0.024766921997070312, 0.0443916879594326, 0.0198507197201252, 0.026133669540286064, 0.01812446489930153, 0.042709071189165115, 0.03681059181690216, 0.0, 0.0, 0.0, 0.0], [0.16313210129737854, 0.022932488471269608, 0.029583677649497986, 0.02861548401415348, 0.037784647196531296, 0.026518717408180237, 0.026229016482830048, 0.031034141778945923, 0.034832049161195755, 0.018975621089339256, 0.03320293873548508, 0.026435943320393562, 0.03230735659599304, 0.0313291996717453, 0.01172788254916668, 0.027169138193130493, 0.024106508120894432, 0.022620312869548798, 0.025755563750863075, 0.03801414743065834, 0.03207403048872948, 0.017354246228933334, 0.017987210303544998, 0.009293689392507076, 0.04247136041522026, 0.031215855851769447, 0.019006572663784027, 0.021523458883166313, 0.017541181296110153, 0.04014518857002258, 0.01816076599061489, 0.04091949388384819, 0.0, 0.0, 0.0], [0.15803849697113037, 0.01682881824672222, 0.020642375573515892, 0.045382529497146606, 0.04664171114563942, 0.02783522754907608, 0.020206501707434654, 0.04211509972810745, 0.037034470587968826, 0.01774459145963192, 0.030353335663676262, 0.024713635444641113, 0.03428485989570618, 0.03341372311115265, 0.009082168340682983, 0.03521377220749855, 0.022280123084783554, 0.020850008353590965, 0.027390211820602417, 0.03231462836265564, 0.03764922544360161, 0.014920786954462528, 0.016553670167922974, 0.006309079937636852, 0.023218730464577675, 0.02794986590743065, 0.023832259699702263, 0.015323558822274208, 0.017670487985014915, 0.0268152616918087, 0.02218884974718094, 0.028694555163383484, 0.036507364362478256, 0.0, 0.0], [0.1701940894126892, 0.03212590143084526, 0.029870091006159782, 0.019615579396486282, 0.054893795400857925, 0.03622059524059296, 0.0171522106975317, 0.0323265977203846, 0.0315006859600544, 0.029624542221426964, 0.029094273224473, 0.016624262556433678, 0.02998979762196541, 0.027614129707217216, 0.01094976719468832, 0.034366536885499954, 0.014830094762146473, 0.01517606433480978, 0.03050290420651436, 0.04159744456410408, 0.02064122073352337, 0.017041221261024475, 0.02617543749511242, 0.010538820177316666, 0.007441797759383917, 0.03439135476946831, 0.02607710286974907, 0.02961565926671028, 0.013693020679056644, 0.018074288964271545, 0.03374852240085602, 0.029002610594034195, 0.013117284514009953, 0.01617228239774704, 0.0], [0.11417394131422043, 0.016700681298971176, 0.023576246574521065, 0.03235282748937607, 0.05511363595724106, 0.029616661369800568, 0.01717638410627842, 0.05952785536646843, 0.038434237241744995, 0.02042110450565815, 0.03235999494791031, 0.019217435270547867, 0.019135108217597008, 0.035197507590055466, 0.010996293276548386, 0.04401443898677826, 0.016835948452353477, 0.016212493181228638, 0.023840539157390594, 0.042316608130931854, 0.03716839849948883, 0.009007311426103115, 0.015979530289769173, 0.005828784313052893, 0.020826416090130806, 0.02825583517551422, 0.03160591796040535, 0.024252021685242653, 0.0232852790504694, 0.019917482510209084, 0.024559779092669487, 0.021957378834486008, 0.01319314818829298, 0.020208802074193954, 0.036734018474817276]]]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import circuitsvis as cv\n",
        "from IPython.display import display\n",
        "\n",
        "html = cv.attention.attention_patterns(\n",
        "    tokens=reference_gpt2.to_str_tokens(reference_text),\n",
        "    attention=cache[\"pattern\", 0][0]\n",
        ")\n",
        "display(html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcT1uWPGfHN2"
      },
      "source": [
        "You can also use the `attention_heads` function, which has similar syntax but presents the information in a different (sometimes more helpful) way.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "html = cv.attention.attention_heads(\n",
        "    tokens=reference_gpt2.to_str_tokens(reference_text),\n",
        "    attention=cache[\"pattern\", 0][0]\n",
        ")\n",
        "\n",
        "display(html)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "dxsRPUS_WneU",
        "outputId": "802eb1eb-2cc8-4cb8-83be-ce828505ef5c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7cdbea395b70>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-29f755a0-aa3d\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-29f755a0-aa3d\",\n",
              "      AttentionHeads,\n",
              "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9679255485534668, 0.032074473798274994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8024235367774963, 0.16839203238487244, 0.029184352606534958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6959055662155151, 0.12269631028175354, 0.14588488638401031, 0.035513248294591904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5661025047302246, 0.14705194532871246, 0.08665254712104797, 0.11258415132761002, 0.08760887384414673, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4621872901916504, 0.13512834906578064, 0.09698349237442017, 0.17473752796649933, 0.046246010810136795, 0.08471736311912537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.43251609802246094, 0.10382883995771408, 0.0833013653755188, 0.06995750963687897, 0.074793741106987, 0.2156866192817688, 0.019915923476219177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22236739099025726, 0.0916769802570343, 0.08796326071023941, 0.25168728828430176, 0.08263691514730453, 0.10428163409233093, 0.06469019502401352, 0.09469636529684067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4049956202507019, 0.09078018367290497, 0.05237356200814247, 0.026201872155070305, 0.11047190427780151, 0.036674048751592636, 0.025538960471749306, 0.24528275430202484, 0.007681120652705431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39985963702201843, 0.04361317306756973, 0.061838824301958084, 0.0729835107922554, 0.03661304712295532, 0.09147469699382782, 0.07241712510585785, 0.07013335824012756, 0.06429054588079453, 0.08677610009908676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09702549129724503, 0.035527583211660385, 0.023214811459183693, 0.036767054349184036, 0.025158407166600227, 0.27756166458129883, 0.07676514238119125, 0.1950118988752365, 0.05580098181962967, 0.14529390633106232, 0.031873054802417755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24143841862678528, 0.03971061110496521, 0.0768737941980362, 0.02804269827902317, 0.12435992062091827, 0.05601579695940018, 0.0606367290019989, 0.1284009963274002, 0.015699446201324463, 0.09114032983779907, 0.13185447454452515, 0.005826778709888458, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1436309665441513, 0.05110502988100052, 0.05505892634391785, 0.07798511534929276, 0.0785427913069725, 0.035019710659980774, 0.1349860280752182, 0.22634069621562958, 0.04162851721048355, 0.03513140231370926, 0.02023601345717907, 0.04114445298910141, 0.0591902956366539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3156285583972931, 0.06791999936103821, 0.037872374057769775, 0.01787460222840309, 0.0868317037820816, 0.02922781929373741, 0.017664166167378426, 0.1830163300037384, 0.0049877953715622425, 0.043228648602962494, 0.05172262713313103, 0.008913454599678516, 0.1289924532175064, 0.0061195120215415955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28410208225250244, 0.053453970700502396, 0.023969216272234917, 0.02256225235760212, 0.046198226511478424, 0.06391073763370514, 0.04539216309785843, 0.07758502662181854, 0.027644306421279907, 0.05804116278886795, 0.17727360129356384, 0.03400600329041481, 0.030527280643582344, 0.03213080018758774, 0.023203175514936447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14103920757770538, 0.028577815741300583, 0.0376039557158947, 0.03137826919555664, 0.03697335720062256, 0.07347068935632706, 0.07151783257722855, 0.09211234748363495, 0.03358153626322746, 0.03639131039381027, 0.18937668204307556, 0.032445166260004044, 0.060210373252630234, 0.03916924446821213, 0.04040950909256935, 0.055742647498846054, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2026529461145401, 0.030252814292907715, 0.06003406643867493, 0.021786153316497803, 0.1031423807144165, 0.04516838863492012, 0.04681028798222542, 0.10542111843824387, 0.011398821137845516, 0.07159948348999023, 0.10570328682661057, 0.004199368413537741, 0.1107979267835617, 0.013912523165345192, 0.028923507779836655, 0.032869454473257065, 0.005327512975782156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20498360693454742, 0.04007228836417198, 0.042298126965761185, 0.02493901364505291, 0.04992290213704109, 0.029371697455644608, 0.030769698321819305, 0.10315564274787903, 0.02549021691083908, 0.07886797189712524, 0.10560183972120285, 0.01735270954668522, 0.08083697408437729, 0.03128695487976074, 0.054510582238435745, 0.05288316309452057, 0.0217428021132946, 0.0059138014912605286, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24350900948047638, 0.036364901810884476, 0.04196161776781082, 0.026215724647045135, 0.040445733815431595, 0.09965366870164871, 0.025752248242497444, 0.03249461203813553, 0.024459943175315857, 0.035202644765377045, 0.033835381269454956, 0.033476900309324265, 0.04664861783385277, 0.027967926114797592, 0.0186407882720232, 0.11764257401227951, 0.038752853870391846, 0.022786684334278107, 0.05418814718723297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14194568991661072, 0.034064050763845444, 0.033009886741638184, 0.020238706842064857, 0.03927314281463623, 0.026005549356341362, 0.006318643689155579, 0.0407978817820549, 0.03638002276420593, 0.146310493350029, 0.016386177390813828, 0.023598454892635345, 0.015842773020267487, 0.042276062071323395, 0.02245822362601757, 0.0686740130186081, 0.027878452092409134, 0.037222422659397125, 0.08677618950605392, 0.13454319536685944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21778136491775513, 0.026903675869107246, 0.02364719845354557, 0.007102563977241516, 0.03517002984881401, 0.01399853453040123, 0.010392282158136368, 0.09431242942810059, 0.00296228751540184, 0.03783802688121796, 0.037923313677310944, 0.0037339734844863415, 0.06506101042032242, 0.0036364602856338024, 0.014758041128516197, 0.12028626352548599, 0.004900881089270115, 0.008107365109026432, 0.017449840903282166, 0.24998724460601807, 0.004047100432217121, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1218722015619278, 0.07663217931985855, 0.030231976881623268, 0.016371842473745346, 0.05268790200352669, 0.021402154117822647, 0.02340387925505638, 0.10649685561656952, 0.018582480028271675, 0.035091664642095566, 0.0839415043592453, 0.017393290996551514, 0.04183056950569153, 0.02145387977361679, 0.0333310104906559, 0.05027427151799202, 0.020740864798426628, 0.040903590619564056, 0.03054095432162285, 0.09200657904148102, 0.028245704248547554, 0.036564696580171585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21260197460651398, 0.020284097641706467, 0.05000370740890503, 0.015904178842902184, 0.057225070893764496, 0.02285732328891754, 0.046045877039432526, 0.03530844300985336, 0.011784467846155167, 0.041404839605093, 0.016803624108433723, 0.015782050788402557, 0.02020842768251896, 0.01309018861502409, 0.020854245871305466, 0.06297554075717926, 0.018039442598819733, 0.018052957952022552, 0.024445295333862305, 0.17059145867824554, 0.015939772129058838, 0.04152188450098038, 0.04827510938048363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26714006066322327, 0.03564617782831192, 0.02042287588119507, 0.006622723303735256, 0.04034103453159332, 0.019110340625047684, 0.014575295150279999, 0.056416332721710205, 0.008403628133237362, 0.015526887960731983, 0.04414670914411545, 0.011055906303226948, 0.04001997783780098, 0.009353081695735455, 0.019351869821548462, 0.07054154574871063, 0.012798824347555637, 0.012832624837756157, 0.014165612868964672, 0.11736990511417389, 0.007312782108783722, 0.09727413952350616, 0.020751142874360085, 0.03882049396634102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14591234922409058, 0.03319380059838295, 0.031387705355882645, 0.00992790050804615, 0.05209650844335556, 0.019840899854898453, 0.019401725381612778, 0.07582411170005798, 0.012863261625170708, 0.03345128893852234, 0.01656840555369854, 0.01479717344045639, 0.05908384174108505, 0.015597393736243248, 0.01136922836303711, 0.021859480068087578, 0.019473880529403687, 0.014793709851801395, 0.05341864004731178, 0.09521486610174179, 0.016204562038183212, 0.06210915371775627, 0.061828501522541046, 0.0665796548128128, 0.03720194473862648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06265703588724136, 0.014285163953900337, 0.025387218222022057, 0.030092518776655197, 0.021246911957859993, 0.02952992171049118, 0.026446694508194923, 0.014830503612756729, 0.015861935913562775, 0.043314337730407715, 0.021963955834507942, 0.0199701227247715, 0.04342854395508766, 0.018692897632718086, 0.009475365281105042, 0.024197489023208618, 0.02385362610220909, 0.0269087515771389, 0.014060708694159985, 0.1752849817276001, 0.03583677113056183, 0.047922562807798386, 0.035750601440668106, 0.01207051333039999, 0.05927426367998123, 0.1476566046476364, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09766799211502075, 0.03152173385024071, 0.026686420664191246, 0.03645577281713486, 0.03492369130253792, 0.08635794371366501, 0.013895386829972267, 0.03018672950565815, 0.019402576610445976, 0.035141684114933014, 0.048781562596559525, 0.012551559135317802, 0.04099080711603165, 0.020208824425935745, 0.012653257697820663, 0.007451050449162722, 0.013522964902222157, 0.02407807484269142, 0.04302708059549332, 0.15066799521446228, 0.029252585023641586, 0.018810171633958817, 0.016104498878121376, 0.02854987047612667, 0.02987591177225113, 0.051215607672929764, 0.04001831263303757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0915181115269661, 0.01142112072557211, 0.039799030870199203, 0.011658591218292713, 0.03344331309199333, 0.04107605665922165, 0.009538301266729832, 0.04061255231499672, 0.00911438837647438, 0.04690402373671532, 0.02731761522591114, 0.010844956152141094, 0.0245475135743618, 0.010004601441323757, 0.008095634169876575, 0.00839681550860405, 0.01185548771172762, 0.008184152655303478, 0.04104064032435417, 0.3625810444355011, 0.007537385914474726, 0.009961556643247604, 0.021045755594968796, 0.01185503602027893, 0.030058305710554123, 0.03281192108988762, 0.028863219544291496, 0.00991280097514391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10946289449930191, 0.02587275020778179, 0.02392871491611004, 0.02004525251686573, 0.03590444475412369, 0.03167986124753952, 0.029145274311304092, 0.11399827897548676, 0.013954712077975273, 0.034807175397872925, 0.018105627968907356, 0.01762225665152073, 0.01900731772184372, 0.015307599678635597, 0.0097030159085989, 0.012407945469021797, 0.02009168267250061, 0.02726256288588047, 0.0656459853053093, 0.027155401185154915, 0.02622661367058754, 0.01894299127161503, 0.04077143594622612, 0.019073303788900375, 0.021573418751358986, 0.03021942265331745, 0.07011833041906357, 0.06031468138098717, 0.04165106639266014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11406350880861282, 0.026556234806776047, 0.01995842717587948, 0.008931470103561878, 0.034943222999572754, 0.01683431677520275, 0.009377745911478996, 0.0445132851600647, 0.00377222103998065, 0.02876032516360283, 0.02074114792048931, 0.005650992039591074, 0.060077618807554245, 0.004424978978931904, 0.01082183700054884, 0.04112928733229637, 0.007085718214511871, 0.010434001684188843, 0.026548532769083977, 0.11019264161586761, 0.00719001330435276, 0.05651939660310745, 0.028027096763253212, 0.06370092928409576, 0.03407694771885872, 0.07150981575250626, 0.040933214128017426, 0.014252983033657074, 0.06984366476535797, 0.009128453209996223, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14399932324886322, 0.020454606041312218, 0.04262388497591019, 0.011592099443078041, 0.027789423242211342, 0.014342913404107094, 0.029106194153428078, 0.04215822368860245, 0.013669716194272041, 0.02058148942887783, 0.008641066960990429, 0.01240221131592989, 0.01957707293331623, 0.014879737049341202, 0.023319046944379807, 0.022367175668478012, 0.014413881115615368, 0.006065307185053825, 0.006985309533774853, 0.08859116584062576, 0.014219224452972412, 0.027541182935237885, 0.057073067873716354, 0.02498571015894413, 0.057332996279001236, 0.048089705407619476, 0.018268706277012825, 0.07940172404050827, 0.04377175495028496, 0.024849100038409233, 0.020907001569867134, 0.0, 0.0, 0.0, 0.0], [0.07786805182695389, 0.019732864573597908, 0.019906366243958473, 0.015179570764303207, 0.02926989272236824, 0.008963337168097496, 0.011427867226302624, 0.03169625252485275, 0.006965262349694967, 0.04064170643687248, 0.01998521387577057, 0.008789058774709702, 0.03574990853667259, 0.007953666150569916, 0.009612184017896652, 0.014965921640396118, 0.010367297567427158, 0.013545000925660133, 0.01374734565615654, 0.06818549335002899, 0.01183705497533083, 0.01935550943017006, 0.016761228442192078, 0.016301216557621956, 0.06125021353363991, 0.12023527920246124, 0.04739146679639816, 0.02382204681634903, 0.14942999184131622, 0.014121495187282562, 0.04741879925131798, 0.007523441221565008, 0.0, 0.0, 0.0], [0.14836615324020386, 0.036274224519729614, 0.023768767714500427, 0.0053084008395671844, 0.03226036578416824, 0.017439451068639755, 0.015090287663042545, 0.04443071782588959, 0.004935791250318289, 0.02115151286125183, 0.023849114775657654, 0.00612779101356864, 0.04430978000164032, 0.005717849358916283, 0.006861449219286442, 0.016362622380256653, 0.007707122713327408, 0.009109629318118095, 0.02842760644853115, 0.144913911819458, 0.0063516004011034966, 0.03453824296593666, 0.023273009806871414, 0.04803793504834175, 0.03441666439175606, 0.06975367665290833, 0.027561908587813377, 0.0120165403932333, 0.03535730764269829, 0.008575203828513622, 0.03916303440928459, 0.009715795516967773, 0.00882658176124096, 0.0, 0.0], [0.11389314383268356, 0.021931476891040802, 0.026447594165802002, 0.007602885365486145, 0.02053067833185196, 0.029713159427046776, 0.03694962337613106, 0.028757939115166664, 0.007981306873261929, 0.029359182342886925, 0.015349611639976501, 0.01842017099261284, 0.020850980654358864, 0.008514756336808205, 0.010930925607681274, 0.009227696806192398, 0.021279292181134224, 0.009222986176609993, 0.027651088312268257, 0.12458859384059906, 0.010509626939892769, 0.06096193566918373, 0.022033261135220528, 0.03036692924797535, 0.027411185204982758, 0.03459944576025009, 0.03202729672193527, 0.039529699832201004, 0.05353795364499092, 0.017732897773385048, 0.017497550696134567, 0.01777147874236107, 0.012080208398401737, 0.034737344831228256, 0.0], [0.13933588564395905, 0.02137126959860325, 0.014541366137564182, 0.005123288370668888, 0.0316350944340229, 0.010921811684966087, 0.012541363015770912, 0.02249286137521267, 0.004774264059960842, 0.024901436641812325, 0.01085835974663496, 0.010577704757452011, 0.025906087830662727, 0.005286508239805698, 0.016752298921346664, 0.04520439729094505, 0.012112229131162167, 0.014714703895151615, 0.014629190787672997, 0.08781159669160843, 0.007287841755896807, 0.07496529817581177, 0.015995560213923454, 0.04392345994710922, 0.04102412983775139, 0.07587806135416031, 0.02792457304894924, 0.015250182710587978, 0.013413453474640846, 0.014532781206071377, 0.02721545472741127, 0.03453553467988968, 0.018207406625151634, 0.03505333513021469, 0.023301267996430397]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041899754432961345, 0.9995810389518738, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00013394761481322348, 0.009511838667094707, 0.9903541803359985, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008606771007180214, 0.0026100394316017628, 0.015066809952259064, 0.9814624786376953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.717040817718953e-05, 0.0006769567262381315, 0.0012692938325926661, 0.0002140780707122758, 0.9978025555610657, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.425416308455169e-05, 0.0007904717931523919, 0.0032152850180864334, 0.0027085694018751383, 0.0013058256590738893, 0.9918956160545349, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014960527187213302, 0.0018361854599788785, 0.0016375032719224691, 0.001013060798868537, 0.004209812264889479, 8.004387927940115e-05, 0.9910737872123718, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002685565559659153, 0.0009259640937671065, 0.0008250505197793245, 0.0006819659029133618, 0.007268862333148718, 0.001351707149296999, 0.00034691710607148707, 0.9883310198783875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007326364051550627, 0.007828550413250923, 0.0039318762719631195, 0.0001837400923250243, 6.43310122541152e-05, 0.0001008316467050463, 6.769897299818695e-05, 7.164081034716219e-05, 0.9804249405860901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.917570938938297e-05, 9.137415327131748e-05, 0.00033399087260477245, 6.816770473960787e-05, 7.81232156441547e-05, 0.0009843026055023074, 0.00016941322246566415, 0.002541458932682872, 4.413309216033667e-05, 0.9956498742103577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.5203117881319486e-06, 2.3466483980882913e-05, 9.186465467792004e-05, 8.01341884653084e-05, 3.939209636882879e-05, 8.521587733412161e-05, 2.573589881649241e-05, 7.120813097571954e-05, 4.276960225979565e-06, 0.00015049739158712327, 0.9994226694107056, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010400302708148956, 0.002299361629411578, 0.0023920685052871704, 0.0003133234567940235, 0.00013362923345994204, 0.0005168461939319968, 0.0011971096973866224, 6.827443576185033e-05, 0.005444325506687164, 0.0002821744710672647, 4.3057276343461126e-05, 0.9862697720527649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.63041833427269e-05, 0.0003248237771913409, 0.00024459476117044687, 0.001531170099042356, 0.0008613731479272246, 0.0012943913461640477, 6.198477058205754e-05, 2.664277417352423e-05, 4.84087759105023e-05, 0.001985571114346385, 0.00013971907901577652, 0.0001143431436503306, 0.9933207035064697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0030442429706454277, 0.0018223646329715848, 0.0009289867011830211, 4.8802314267959446e-05, 1.6391171811847016e-05, 2.9095650461385958e-05, 2.507984208932612e-05, 2.9130302209523506e-05, 0.4563218355178833, 2.4578692318755202e-05, 2.483218486304395e-05, 0.003004396567121148, 1.677382101661351e-06, 0.5346786379814148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00039817875949665904, 0.0010285003809258342, 0.000828111544251442, 0.00023753165442030877, 7.348863437073305e-05, 0.0014350308338180184, 6.765663420083001e-05, 0.00029547399026341736, 0.0001429579424438998, 9.929091902449727e-05, 4.60821593151195e-06, 0.000514006766024977, 5.035657068219734e-06, 0.00012475518451537937, 0.9947452545166016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.074864647118375e-05, 0.0002652599068824202, 0.00011011186870746315, 0.00021231947175692767, 8.290550613310188e-05, 0.0011814209865406156, 1.5688718121964484e-05, 0.0016655955696478486, 1.1725332115020137e-05, 0.0020509453024715185, 0.00013842586486134678, 1.557363611937035e-05, 1.150744083133759e-05, 9.066193342732731e-06, 0.00022655802604276687, 0.9939122200012207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00044135426287539303, 0.0006528961239382625, 0.0006495665293186903, 9.398067049914971e-05, 4.112707028980367e-05, 0.00017028416914399713, 0.0005066704470664263, 2.889607821998652e-05, 0.0023701833561062813, 0.0001045431854436174, 1.923093805089593e-05, 0.4705588221549988, 1.680400782788638e-05, 0.002284094225615263, 0.00021698094496969134, 3.276941424701363e-05, 0.5218117833137512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005350523279048502, 0.0006631254218518734, 0.00018957522115670145, 0.00011594548413995653, 3.930590901290998e-05, 8.452115434920415e-05, 0.00026859997888095677, 0.0003003481833729893, 0.0001272758818231523, 0.00015363430429715663, 2.1524516341742128e-05, 0.0004102020466234535, 0.0015090389642864466, 0.00011659036681521684, 0.0001377397566102445, 7.38915623514913e-05, 0.00039899448165670037, 0.9948546886444092, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002235247375210747, 0.0002502534771338105, 0.00011739338515326381, 1.8608267055242322e-05, 0.0006291492027230561, 0.0007579223602078855, 3.784089858527295e-05, 0.0033851482439786196, 1.791827889974229e-05, 0.00017818294872995466, 3.4344266168773174e-05, 7.747584459139034e-05, 6.471157394116744e-05, 1.5270292351488024e-05, 0.0002935958909802139, 0.0005734387668780982, 7.154404011089355e-05, 0.0001588314480613917, 0.993094801902771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00030641001649200916, 0.0004168010491412133, 0.0004519718640949577, 0.0001574639609316364, 0.0015800739638507366, 0.002266631228849292, 0.00014483617269434035, 0.00251887203194201, 4.4711858208756894e-05, 0.0027394636999815702, 0.000434897345257923, 0.00015683105448260903, 2.8505710361059755e-05, 4.005827577202581e-05, 0.000593667384237051, 0.00011775219900300726, 0.0001403962232870981, 0.00018060373258776963, 0.0009641882497817278, 0.9867159128189087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009046882390975952, 0.0007260903948917985, 6.491786189144477e-05, 4.578266089083627e-05, 3.669528086902574e-05, 3.389695848454721e-05, 4.131328751100227e-05, 9.000120917335153e-05, 0.016163919121026993, 1.8953802282339893e-05, 3.3513781090732664e-05, 0.0021810815669596195, 5.341176802176051e-06, 0.018749460577964783, 0.0001789774833014235, 0.00049936881987378, 0.0024355659261345863, 4.271611032891087e-05, 7.329288928303868e-05, 1.9154360415996052e-05, 0.9495131969451904, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00021946291963104159, 0.0011669580126181245, 0.00021983245096635073, 0.0009876289404928684, 0.00031338463304564357, 0.00012072654499206692, 5.631537533190567e-06, 2.4260070858872496e-05, 4.544197872746736e-05, 1.852959394454956e-05, 1.4025716154719703e-05, 1.0154987649002578e-05, 0.0004018021281808615, 4.0526429074816406e-05, 0.0001710674405330792, 9.8690579761751e-06, 9.488572686677799e-06, 0.0003931091050617397, 5.709413926524576e-06, 1.7844293324742466e-05, 2.8530415875138715e-05, 0.9957762360572815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00019361003069207072, 0.0008434180053882301, 0.0005215295823290944, 2.566456350905355e-05, 0.00046233212924562395, 0.00025401596212759614, 1.8471198927727528e-05, 0.00011509784235386178, 0.00027288994169794023, 0.00015436687681358308, 1.2149157555541024e-05, 0.0006913748802617192, 5.695979416486807e-05, 0.00024024784215725958, 3.827492764685303e-05, 9.934457921190187e-05, 0.0006488919025287032, 8.011747559066862e-05, 0.00019218817760702223, 2.5529448976158164e-05, 0.00032434772583656013, 0.0010871072299778461, 0.9936420321464539, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0016077648615464568, 0.1769733428955078, 0.015483599156141281, 0.0003713879268616438, 0.0003786341694649309, 0.00016452741692773998, 0.00032773835118860006, 0.00016989713185466826, 0.0021229630801826715, 3.573103458620608e-05, 6.090146052883938e-05, 0.00045621677418239415, 1.5447807527380064e-05, 0.0022543170489370823, 0.0015666891122236848, 0.00011843765969388187, 0.0004699892597272992, 5.037321534473449e-05, 0.00012108073133276775, 6.008972559357062e-05, 0.0008920581312850118, 0.000751846528146416, 0.00026899686781689525, 0.7952780723571777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003919867449440062, 0.00021421202109195292, 0.0005306120729073882, 1.0745785402832553e-05, 0.00011862390965688974, 4.225783050060272e-05, 0.00021160392498131841, 4.692554284702055e-05, 0.00044815847650170326, 0.00010691297211451456, 3.935468339477666e-05, 0.00016830874665174633, 0.00017352365830447525, 0.000452450942248106, 0.00014294125139713287, 0.00011699349124683067, 0.00017526814190205187, 0.00010119970829691738, 4.25139041908551e-05, 2.0371742721181363e-05, 3.83713559131138e-05, 0.00011344622180331498, 0.00025279319379478693, 6.991033296799287e-05, 0.9959704875946045, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002153067762264982, 0.0001000583142740652, 0.0023809161502867937, 0.0019831405952572823, 0.0011120109120383859, 5.563462036661804e-05, 0.0006109256646595895, 0.0002456431102473289, 8.818998321658e-05, 0.0011510387994349003, 0.00010669889161363244, 0.00017554854275658727, 5.7362729421583936e-05, 7.814786658855155e-05, 0.000245734496274963, 9.594661605660804e-06, 0.00017032361938618124, 2.8972623113077134e-05, 1.4011687198944855e-05, 0.00016692050849087536, 1.2888858691439964e-05, 0.0002449550956953317, 0.0005147008341737092, 4.942110172123648e-05, 0.0005746547831222415, 0.9896072745323181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00011423427349654958, 0.0008627416682429612, 0.0007732235244475305, 0.0007090758881531656, 0.0007292147492989898, 0.0014031626051291823, 0.00021403632126748562, 0.00017666479106992483, 6.622055661864579e-05, 3.2159430702449754e-05, 0.0004533061583060771, 0.0001200851402245462, 2.2129046556074172e-05, 5.8075143897440284e-05, 0.00012917444109916687, 1.9079669073107652e-05, 0.00011076675582444295, 8.56419592309976e-06, 2.363056773901917e-05, 0.0003379980626050383, 5.211896859691478e-05, 0.00014455695054493845, 0.0001969498407561332, 0.0004510532016865909, 2.0576282622641884e-05, 8.76431877259165e-05, 0.992683470249176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001979833614313975, 0.00019567940034903586, 0.00022612242901232094, 0.00041943672113120556, 0.000597969745285809, 0.000451744650490582, 0.0003478288999758661, 0.0002585809852462262, 2.80198801192455e-05, 0.0007220012485049665, 0.0001301045558648184, 0.001163206878118217, 6.916908751009032e-05, 2.478912938386202e-05, 0.00010386014764662832, 0.00038124938146211207, 0.0011587801855057478, 0.00033144469489343464, 0.00024494543322362006, 0.00012755172792822123, 0.0001609843602636829, 1.9267921743448824e-05, 0.00027174208662472665, 2.0765552108059637e-05, 6.82506724842824e-05, 0.0008764253580011427, 0.0006782166310586035, 0.9907240271568298, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.157188984914683e-05, 0.0006791111663915217, 0.0007090717554092407, 0.00024164833303075284, 0.00041205473826266825, 0.000923742598388344, 0.00020848578424192965, 6.639298953814432e-05, 0.00011664839985314757, 8.601942681707442e-05, 0.010591322556138039, 0.0003372912178747356, 2.1898511477047578e-05, 0.00010110744187841192, 0.00010436101729283109, 5.858746590092778e-05, 0.0003251215966884047, 1.5854146113269962e-05, 5.0336129788775e-06, 0.00040949060348793864, 1.3119516552251298e-05, 5.313358997227624e-05, 1.1887270375154912e-05, 5.536681055673398e-05, 1.2197706382721663e-05, 8.95265256986022e-05, 0.0022435507271438837, 0.00021041935542598367, 0.9818660616874695, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007582925027236342, 0.0012331441976130009, 8.604933827882633e-05, 6.291332101682201e-05, 2.8791733711841516e-05, 3.3166903449455276e-05, 7.622712291777134e-05, 0.00010868187382584438, 0.006450854241847992, 0.00014789080887567252, 1.0376486898167059e-05, 0.0023889716248959303, 7.88359175203368e-05, 0.007510697469115257, 0.00028743132133968174, 0.000136757327709347, 0.002760292263701558, 0.0007447165553458035, 8.81111845956184e-05, 2.470205072313547e-05, 0.0061888666823506355, 0.00011647037172224373, 0.0001724402973195538, 0.0002621748426463455, 0.0001841977791627869, 4.4321401219349355e-05, 4.855170482187532e-05, 8.903052366804332e-05, 2.6887826606980525e-05, 0.9698501229286194, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00024627428501844406, 0.00035919909714721143, 0.00020521896658465266, 9.38774537644349e-05, 8.577330299885944e-05, 5.495211007655598e-05, 4.531835293164477e-05, 1.0722159458964597e-05, 4.8671085096430033e-05, 0.00011017618089681491, 0.00010064091475214809, 9.7722360806074e-05, 0.0005496814846992493, 4.362939216662198e-05, 3.945788193959743e-05, 7.140226080082357e-05, 9.814348595682532e-05, 5.7009699958143756e-05, 2.4251108698081225e-05, 2.31456533583696e-06, 5.056934242020361e-05, 0.0001131849130615592, 0.0002906991576310247, 6.889962241984904e-05, 0.0006683259271085262, 0.0002321746142115444, 8.348713890882209e-06, 1.743463144521229e-05, 1.027311009238474e-05, 0.00013885677617508918, 0.9960569143295288, 0.0, 0.0, 0.0, 0.0], [0.0001110591838369146, 3.599160481826402e-05, 4.4160620745969936e-05, 0.00022596407507080585, 0.00024025874154176563, 1.73489679582417e-05, 7.204319263109937e-05, 0.00023739012249279767, 8.274764695670456e-05, 0.00010178561933571473, 7.876398740336299e-06, 6.3918465457391e-05, 3.295214628451504e-05, 7.889204425737262e-05, 0.0001162747576017864, 7.139155968616251e-06, 6.571767153218389e-05, 5.396374945121352e-06, 8.334040103363805e-06, 1.9613918993854895e-05, 4.11063629144337e-05, 8.538004476577044e-05, 3.1616236810805276e-05, 9.91701290331548e-06, 2.3832457372918725e-05, 0.0018293556058779359, 2.6111281840712763e-05, 3.3135143894469365e-05, 1.4612752238463145e-05, 0.000854729616548866, 0.00016745176981203258, 0.995307981967926, 0.0, 0.0, 0.0], [0.0022552241571247578, 0.00046477530850097537, 0.0001228374312631786, 0.006661206018179655, 8.828952559269965e-05, 0.00024942768504843116, 0.0001755515404511243, 2.6563478968455456e-05, 0.004149139393121004, 0.00020833070448134094, 1.597335358383134e-05, 0.0007248217007145286, 1.2318085282458924e-05, 0.004929243586957455, 0.0007067761616781354, 2.7460198907647282e-05, 0.0008252441766671836, 5.1487335440469906e-05, 9.107246114581358e-06, 0.00117019796743989, 0.0011320497142150998, 0.00038722759927622974, 0.00010000279144151136, 0.0005395386251620948, 0.0001279767748201266, 7.41870971978642e-05, 0.0006351852207444608, 5.991850048303604e-05, 0.00020302319899201393, 0.02264126017689705, 7.11138709448278e-05, 0.0034798544365912676, 0.9476746916770935, 0.0, 0.0], [0.00010488810949027538, 0.0005403983523137867, 0.0002700608456507325, 2.781992225209251e-05, 0.0008878528606146574, 0.0002531727368477732, 0.00029214046662673354, 0.000995146343484521, 3.9432117773685604e-05, 6.531640246976167e-05, 5.1983381126774475e-05, 0.0006716344505548477, 1.9524166418705136e-05, 3.796433884417638e-05, 0.00031547032995149493, 0.00015760336827952415, 0.0006809111800976098, 0.00017366735846735537, 0.00023275859712157398, 0.000493519997689873, 0.00015254231402650476, 8.968860493041575e-05, 0.0014225798659026623, 0.00022503072977997363, 0.00015392254863400012, 0.00010696907702367753, 0.005650238133966923, 0.000865322828758508, 0.0002874949714168906, 0.00013868501991964877, 1.4354158338392153e-05, 2.8161975933471695e-05, 0.00011612014350248501, 0.9844375848770142, 0.0], [0.001883037737570703, 0.0002301394852111116, 7.19053641660139e-05, 3.7982904359523673e-06, 0.0022563613019883633, 4.367973451735452e-05, 0.00012782943667843938, 0.0006368017056956887, 0.0005363993695937097, 5.325703114067437e-06, 7.917853508843109e-05, 2.6015983166871592e-05, 1.125325434259139e-05, 0.0005611245869658887, 9.10379003471462e-06, 0.00021052206284366548, 2.689109169295989e-05, 3.242435195716098e-05, 0.00025939318584278226, 0.00045266683446243405, 0.0011520986445248127, 1.149352829088457e-05, 4.8182344471570104e-05, 0.0001057150075212121, 8.452797192148864e-05, 0.000100208621006459, 2.848373151209671e-05, 2.041544757958036e-05, 1.8022971062237048e-06, 7.62895360821858e-05, 4.604330752044916e-05, 9.973573469324037e-05, 5.258398232399486e-06, 0.0001948850112967193, 0.9905609488487244]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9424744844436646, 0.05752559006214142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8506749868392944, 0.09740971028804779, 0.051915302872657776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7641513347625732, 0.10970375686883926, 0.07497038692235947, 0.051174528896808624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6748191714286804, 0.08416195213794708, 0.0547025091946125, 0.07581549882888794, 0.11050094664096832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6857606768608093, 0.08229531347751617, 0.052021171897649765, 0.08139175921678543, 0.04085882008075714, 0.05767223984003067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6174605488777161, 0.056534551084041595, 0.09111697971820831, 0.06854881346225739, 0.06338423490524292, 0.035969749093055725, 0.066985122859478, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6047279834747314, 0.06088972091674805, 0.05921151116490364, 0.09558156132698059, 0.04265914857387543, 0.031843431293964386, 0.0426306426525116, 0.06245603412389755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4008437991142273, 0.0753358006477356, 0.04270840436220169, 0.01176072470843792, 0.02668057195842266, 0.013492080383002758, 0.02846546284854412, 0.01390059757977724, 0.38681259751319885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49680253863334656, 0.06792881339788437, 0.057920027524232864, 0.07101528346538544, 0.06963261216878891, 0.018800096586346626, 0.06757565587759018, 0.06346482783555984, 0.06656692922115326, 0.020293202251195908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5176078081130981, 0.08289015293121338, 0.05239764600992203, 0.06842363625764847, 0.046088285744190216, 0.026865946128964424, 0.08181484043598175, 0.03230835497379303, 0.05516275763511658, 0.018549634143710136, 0.01789088174700737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3038182258605957, 0.03185645490884781, 0.029157692566514015, 0.011053645983338356, 0.013536771759390831, 0.016536906361579895, 0.015181954950094223, 0.015511739067733288, 0.026294970884919167, 0.016891004517674446, 0.011886648833751678, 0.5082739591598511, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3585989773273468, 0.07880906760692596, 0.05902862176299095, 0.044458650052547455, 0.07822324335575104, 0.019679531455039978, 0.05133118852972984, 0.040098413825035095, 0.08024682104587555, 0.027811912819743156, 0.010250612162053585, 0.1361035257577896, 0.015359451062977314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2511676549911499, 0.04623398557305336, 0.027838557958602905, 0.007056493312120438, 0.017244169488549232, 0.008997938595712185, 0.017309946939349174, 0.0099241454154253, 0.2527511417865753, 0.012778298929333687, 0.008546063676476479, 0.047919970005750656, 0.006098272744566202, 0.28613337874412537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.398007869720459, 0.06433820724487305, 0.049798548221588135, 0.05949560925364494, 0.0318211205303669, 0.03071472980082035, 0.05899549648165703, 0.05480390042066574, 0.03919371962547302, 0.03556447848677635, 0.024916458874940872, 0.04571932554244995, 0.016671661287546158, 0.0389430969953537, 0.05101581662893295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39033836126327515, 0.0754939466714859, 0.03844676911830902, 0.04366776719689369, 0.017820747569203377, 0.012712180614471436, 0.045307233929634094, 0.036030206829309464, 0.0421706885099411, 0.016753025352954865, 0.04224864020943642, 0.05092339962720871, 0.030772069469094276, 0.04072083160281181, 0.056488849222660065, 0.06010529026389122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1818235218524933, 0.018224790692329407, 0.01747790351510048, 0.006372255273163319, 0.007922586984932423, 0.01006288081407547, 0.008703155443072319, 0.01029747910797596, 0.015354439616203308, 0.011538184247910976, 0.007091044448316097, 0.3139554262161255, 0.0060198185965418816, 0.015887578949332237, 0.015422005206346512, 0.013188586570322514, 0.3406583368778229, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2388143241405487, 0.07684367150068283, 0.04843555763363838, 0.02831975929439068, 0.04297622665762901, 0.01943075656890869, 0.033217206597328186, 0.027472950518131256, 0.01897592842578888, 0.04046749696135521, 0.02009560540318489, 0.058573175221681595, 0.035305727273225784, 0.019691888242959976, 0.097037672996521, 0.03909808769822121, 0.061994507908821106, 0.09324946254491806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35636118054389954, 0.04354538768529892, 0.054393719881772995, 0.03599719703197479, 0.055608708411455154, 0.03285681828856468, 0.019443828612565994, 0.06911691278219223, 0.020649444311857224, 0.033605340868234634, 0.027618737891316414, 0.034080009907484055, 0.02684745565056801, 0.020337311550974846, 0.022298933938145638, 0.03622739389538765, 0.03464473783969879, 0.022655019536614418, 0.053711891174316406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39670124650001526, 0.05178239569067955, 0.039961934089660645, 0.066307432949543, 0.04557184875011444, 0.023983409628272057, 0.019396748393774033, 0.02136596292257309, 0.020253783091902733, 0.036855828016996384, 0.009492042474448681, 0.041809991002082825, 0.014498688280582428, 0.01978372409939766, 0.02971523255109787, 0.046315472573041916, 0.04246639460325241, 0.031475216150283813, 0.022027641534805298, 0.02023506537079811, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23151390254497528, 0.13258200883865356, 0.06026102975010872, 0.011383597739040852, 0.02426271326839924, 0.014553449116647243, 0.016979563981294632, 0.013957408256828785, 0.02247590199112892, 0.027721285820007324, 0.02060706540942192, 0.04084686189889908, 0.027723213657736778, 0.024550706148147583, 0.03857918456196785, 0.04770102724432945, 0.044071096926927567, 0.0772075280547142, 0.04604469612240791, 0.04773346334695816, 0.02924429625272751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20264171063899994, 0.04893086850643158, 0.03894680738449097, 0.026632271707057953, 0.040943484753370285, 0.01617504097521305, 0.043880145996809006, 0.04927309602499008, 0.037442922592163086, 0.01874796487390995, 0.010438330471515656, 0.030274199321866035, 0.011668822728097439, 0.03915899246931076, 0.08361910283565521, 0.026806527748703957, 0.03237596154212952, 0.026771074160933495, 0.04136867821216583, 0.04380553215742111, 0.09921549260616302, 0.03088301047682762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22999975085258484, 0.029275361448526382, 0.024823691695928574, 0.0307475458830595, 0.024439768865704536, 0.025078177452087402, 0.019048267975449562, 0.04161752015352249, 0.02524641901254654, 0.05536344274878502, 0.013840335421264172, 0.03206310421228409, 0.02337372675538063, 0.02689637430012226, 0.03765585273504257, 0.02870967984199524, 0.03498142585158348, 0.03826925903558731, 0.053048763424158096, 0.07750778645277023, 0.042357493191957474, 0.06297062337398529, 0.022685660049319267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2523007094860077, 0.04309260472655296, 0.047794319689273834, 0.021534807980060577, 0.05364761874079704, 0.014357613399624825, 0.016968196257948875, 0.012399843893945217, 0.02810794673860073, 0.022964568808674812, 0.013637283816933632, 0.03462430089712143, 0.013057569973170757, 0.029753560200333595, 0.025925684720277786, 0.03689543902873993, 0.0364658497273922, 0.02009117789566517, 0.03424844145774841, 0.0322706364095211, 0.07516521215438843, 0.03381401300430298, 0.05794452503323555, 0.04293809086084366, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24815583229064941, 0.0418383851647377, 0.03725353628396988, 0.019914167001843452, 0.06031177192926407, 0.01376150269061327, 0.010237004607915878, 0.02711835876107216, 0.02124747820198536, 0.014996425248682499, 0.015956399962306023, 0.019741931930184364, 0.016942845657467842, 0.022782426327466965, 0.021159417927265167, 0.013419795781373978, 0.021131549030542374, 0.01588008925318718, 0.03851576894521713, 0.03509928286075592, 0.06386473774909973, 0.042158905416727066, 0.05595177412033081, 0.06510591506958008, 0.0574546717107296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24590620398521423, 0.03979460895061493, 0.034050021320581436, 0.038720108568668365, 0.02834436297416687, 0.024568283930420876, 0.013687249273061752, 0.019880935549736023, 0.017507946118712425, 0.04131212458014488, 0.024649059399962425, 0.017028072848916054, 0.015493784099817276, 0.01803990639746189, 0.028712527826428413, 0.008945342153310776, 0.017858801409602165, 0.02984653413295746, 0.02698221057653427, 0.0611925944685936, 0.03972144052386284, 0.04008689522743225, 0.04656379297375679, 0.04659208655357361, 0.046358171850442886, 0.0281569492071867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24299509823322296, 0.030936647206544876, 0.0372811034321785, 0.029979784041643143, 0.039518240839242935, 0.02068972960114479, 0.024463791400194168, 0.01616225577890873, 0.02351461350917816, 0.015184109099209309, 0.009779490530490875, 0.010400430299341679, 0.008830740116536617, 0.023988915607333183, 0.02441921830177307, 0.037842005491256714, 0.010589987970888615, 0.013367554172873497, 0.01626332476735115, 0.09984055161476135, 0.02563280425965786, 0.02790280431509018, 0.054687805473804474, 0.031704068183898926, 0.027479561045765877, 0.016517246142029762, 0.08002810180187225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24383296072483063, 0.021781543269753456, 0.019058484584093094, 0.026608381420373917, 0.03740561753511429, 0.027086623013019562, 0.0050316122360527515, 0.02665604092180729, 0.017429374158382416, 0.02866247668862343, 0.012150990776717663, 0.030223211273550987, 0.014068293385207653, 0.01816091127693653, 0.01543530635535717, 0.015721842646598816, 0.03215308114886284, 0.024973023682832718, 0.04793376848101616, 0.0459899939596653, 0.03119213879108429, 0.03841527923941612, 0.037881284952163696, 0.03472226858139038, 0.03550754487514496, 0.03336038440465927, 0.05460801348090172, 0.02394956350326538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.308788001537323, 0.04082433506846428, 0.010766160674393177, 0.02708975411951542, 0.019433287903666496, 0.03355547785758972, 0.010839528404176235, 0.01149556040763855, 0.011286415159702301, 0.019319292157888412, 0.03442363440990448, 0.01059587113559246, 0.01946372538805008, 0.011577973142266273, 0.014172402210533619, 0.021593410521745682, 0.010569154284894466, 0.01821252517402172, 0.007991211488842964, 0.05231863632798195, 0.019707778468728065, 0.03532519191503525, 0.029598264023661613, 0.028512977063655853, 0.021019764244556427, 0.018976135179400444, 0.031007949262857437, 0.017736954614520073, 0.10379863530397415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11270298808813095, 0.013211611658334732, 0.015115484595298767, 0.008062331937253475, 0.018075058236718178, 0.020267318934202194, 0.009121793322265148, 0.0216544046998024, 0.024600299075245857, 0.012220285832881927, 0.005230673588812351, 0.021195203065872192, 0.0075057619251310825, 0.0272400863468647, 0.01682899333536625, 0.0093071972951293, 0.023774148896336555, 0.009840184822678566, 0.023520387709140778, 0.018096182495355606, 0.11592709273099899, 0.008296087384223938, 0.015038424171507359, 0.016261843964457512, 0.022837147116661072, 0.007970291189849377, 0.010346011258661747, 0.013601286336779594, 0.00992316659539938, 0.3622281849384308, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19907140731811523, 0.02335296757519245, 0.027535507455468178, 0.020741207525134087, 0.04944240674376488, 0.0396454818546772, 0.011580482125282288, 0.03849606215953827, 0.012212718836963177, 0.012634869664907455, 0.018897859379649162, 0.011502718552947044, 0.014417962171137333, 0.012855133041739464, 0.015916291624307632, 0.009284356608986855, 0.011929106898605824, 0.014574812725186348, 0.029562367126345634, 0.030921468511223793, 0.0493488609790802, 0.02683301642537117, 0.033169783651828766, 0.026513919234275818, 0.03841781243681908, 0.03666592016816139, 0.03740687295794487, 0.037449177354574203, 0.0418136790394783, 0.040804993361234665, 0.02700081095099449, 0.0, 0.0, 0.0, 0.0], [0.1358085423707962, 0.021598204970359802, 0.028431449085474014, 0.0213667880743742, 0.03184177353978157, 0.02831076830625534, 0.011232441291213036, 0.016139332205057144, 0.02343672886490822, 0.025144262239336967, 0.012804518453776836, 0.012000495567917824, 0.02091226726770401, 0.025003299117088318, 0.027692247182130814, 0.017305929213762283, 0.01285973098129034, 0.016066303476691246, 0.03279000148177147, 0.03829028084874153, 0.0608048141002655, 0.03674997389316559, 0.03524733707308769, 0.038578007370233536, 0.03904813900589943, 0.03664340078830719, 0.014530439861118793, 0.021632274612784386, 0.010491003282368183, 0.06733929365873337, 0.03867286071181297, 0.041227128356695175, 0.0, 0.0, 0.0], [0.13088133931159973, 0.023744329810142517, 0.020114341750741005, 0.009702399373054504, 0.02695222571492195, 0.013591106049716473, 0.009517531841993332, 0.013271716423332691, 0.027617909014225006, 0.01149838138371706, 0.008886141702532768, 0.016865810379385948, 0.009971980936825275, 0.031318604946136475, 0.014953814446926117, 0.015636608004570007, 0.018755856901407242, 0.008822464384138584, 0.024258313700556755, 0.018599877133965492, 0.06659715622663498, 0.023935334756970406, 0.03021502122282982, 0.038479723036289215, 0.060547877103090286, 0.0388609804213047, 0.021039584651589394, 0.026919953525066376, 0.030786728486418724, 0.06339394301176071, 0.05302290990948677, 0.07499752938747406, 0.01624254137277603, 0.0, 0.0], [0.21679528057575226, 0.03523937985301018, 0.01448057871311903, 0.03231680765748024, 0.021502699702978134, 0.019766857847571373, 0.007716965861618519, 0.03142579272389412, 0.01142125204205513, 0.03985079005360603, 0.00569754745811224, 0.013826768845319748, 0.011217727325856686, 0.011028861626982689, 0.014342342503368855, 0.016691600903868675, 0.013800655491650105, 0.009054167196154594, 0.01655156910419464, 0.045164525508880615, 0.01674339547753334, 0.040494970977306366, 0.04600660502910614, 0.03918023034930229, 0.02077179029583931, 0.04241837561130524, 0.029444055631756783, 0.01654653437435627, 0.0433904305100441, 0.018028810620307922, 0.01749301142990589, 0.03195444867014885, 0.023179972544312477, 0.026455217972397804, 0.0], [0.12406572699546814, 0.05575518682599068, 0.025793109089136124, 0.007745689712464809, 0.019214725121855736, 0.011872398667037487, 0.009303722530603409, 0.015842609107494354, 0.012728426605463028, 0.012888251803815365, 0.013962885364890099, 0.01662725955247879, 0.01550710666924715, 0.0131952203810215, 0.017325090244412422, 0.02114798128604889, 0.01733550801873207, 0.015824293717741966, 0.02479436621069908, 0.011903030797839165, 0.03651026636362076, 0.023874737322330475, 0.04022136330604553, 0.06286033987998962, 0.10149350762367249, 0.05332258716225624, 0.021689629182219505, 0.018244286999106407, 0.008406993001699448, 0.02320230007171631, 0.04960416629910469, 0.02086932584643364, 0.01601797342300415, 0.011101940646767616, 0.049747928977012634]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10778003185987473, 0.8922199010848999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01184743270277977, 0.5536141395568848, 0.43453848361968994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06322261691093445, 0.02171914279460907, 0.09427288919687271, 0.820785403251648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005095742642879486, 0.0005348750273697078, 0.0010105489054694772, 0.004657563753426075, 0.9887012243270874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005585955921560526, 0.0003024001489393413, 0.0007955087930895388, 0.0006780325202271342, 0.028760099783539772, 0.9638779759407043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00026657318812794983, 0.0001539620861876756, 4.344211993156932e-05, 0.00031633899197913706, 0.007582378573715687, 0.008635704405605793, 0.9830015897750854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006940615130588412, 4.833174170926213e-05, 4.511346196522936e-05, 2.3520820832345635e-05, 0.0022377651184797287, 0.0012080521555617452, 0.00932135060429573, 0.9864218235015869, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04771990701556206, 0.006346914917230606, 0.005507620982825756, 0.012776722200214863, 0.012552591040730476, 0.012200531549751759, 0.007760600186884403, 0.017114851623773575, 0.8780203461647034, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.40378158702515e-05, 7.299120738935017e-07, 1.2948535186296795e-06, 1.004057139653014e-06, 1.519241322966991e-05, 3.609514533309266e-05, 3.151434430037625e-05, 0.0010808238293975592, 4.236837776261382e-05, 0.9986969828605652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002984422317240387, 1.0225188816548325e-05, 2.0773863070644438e-05, 1.0716744327510241e-05, 7.453822763636708e-05, 0.00016580548253841698, 0.0013668606989085674, 0.0025834820698946714, 5.024061829317361e-05, 0.3243952989578247, 0.6710236072540283, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009233679622411728, 0.0007820429746061563, 0.0006810433696955442, 0.0018207874381914735, 0.004383386112749577, 0.017509128898382187, 0.003324248129501939, 0.0176074281334877, 0.08099661767482758, 0.10943026840686798, 0.014291892759501934, 0.7399395704269409, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023930329189170152, 3.3237947718589567e-06, 2.2832813556306064e-05, 1.024476659949869e-05, 1.0253623258904554e-05, 4.496405381360091e-05, 2.357668745389674e-05, 6.216625479282811e-05, 0.00032929572626017034, 0.00874954555183649, 0.001878876704722643, 0.0014183479361236095, 0.9872072339057922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012295342981815338, 0.0005298616015352309, 0.00035605113953351974, 0.0006006713374517858, 0.0005327533581294119, 0.0005349713028408587, 0.00034733471693471074, 0.0008671165560372174, 0.034323085099458694, 0.013273628428578377, 0.0075311968103051186, 0.05941798537969589, 0.09377509355545044, 0.775614857673645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.850881229387596e-05, 1.1863348845508881e-05, 5.970536676613847e-06, 4.359465037850896e-06, 6.93304127707961e-06, 5.567320476984605e-05, 8.762012839724775e-06, 2.2130006982479244e-05, 0.0002223829651484266, 0.0002802500384859741, 0.0008127266191877425, 0.0015677284682169557, 0.000189563914318569, 0.005879407748579979, 0.9908537864685059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.475010301684961e-05, 8.603468813817017e-06, 3.744859213838936e-06, 1.4634196077167871e-07, 2.701744051591959e-06, 1.141736993304221e-05, 8.620831067673862e-06, 9.928114013746381e-05, 3.119510893156985e-06, 0.00022620811068918556, 0.0005323358927853405, 2.980489080073312e-05, 0.0013675655936822295, 5.107997640152462e-05, 0.009570839814841747, 0.9879898428916931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003944708965718746, 0.00013029153342358768, 9.94771980913356e-05, 0.00019776367116719484, 0.0004265847092028707, 0.0014889852609485388, 0.00028346848557703197, 0.0015356721123680472, 0.004810091573745012, 0.005567715968936682, 0.0010473597794771194, 0.040826570242643356, 0.009189032949507236, 0.09278513491153717, 0.01585300825536251, 0.02794087491929531, 0.7938733696937561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000217236447497271, 2.3531249098596163e-05, 7.806306712154765e-06, 4.732958132080967e-06, 1.567120762047125e-06, 8.667434485687409e-06, 1.264625825569965e-05, 6.12928852206096e-05, 0.00018869456835091114, 0.0005901302210986614, 0.0004205672303214669, 0.00097465276485309, 0.00042177739669568837, 0.004066713619977236, 0.001442243461497128, 0.011960028670728207, 0.022401951253414154, 0.9571956396102905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007360449526458979, 3.016829850821523e-06, 1.3554752058553277e-06, 1.4014691487318487e-06, 3.387712058611214e-05, 3.752295015146956e-05, 1.0748711247288156e-05, 0.0004302708839531988, 1.6196763681364246e-05, 0.0006748259766027331, 0.0005265927757136524, 0.0001240915444213897, 4.710721259471029e-05, 0.00024138184380717576, 0.0006886586197651923, 0.00038702096207998693, 0.002144157886505127, 0.0017651681555435061, 0.9921305775642395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.529802703880705e-06, 4.013182230977463e-09, 4.275874321280071e-09, 9.052371297002537e-09, 5.135171932124649e-07, 3.731759534275625e-06, 1.4824270522240113e-07, 4.6551231207558885e-06, 1.663049964406582e-08, 3.029677600352443e-06, 3.191981159034185e-05, 1.401741371864773e-07, 4.954928840561479e-07, 2.3671073279274424e-07, 7.952932605803653e-07, 0.00018607274978421628, 2.4466733066219604e-06, 1.1982298929069657e-05, 0.0005082334391772747, 0.9992390871047974, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009417888708412647, 0.00017362425569444895, 0.0001959324290510267, 0.00010542469681240618, 0.00012100115418434143, 0.0001375036663375795, 0.00020822316582780331, 0.00026208782219327986, 0.0009803813882172108, 0.00017425179248675704, 0.0013313929084688425, 0.003277308540418744, 0.0048406231217086315, 0.012378795072436333, 0.0018258992349728942, 0.024282047525048256, 0.05479966849088669, 0.07428489625453949, 0.07759265601634979, 0.10845336318016052, 0.6251571178436279, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0001788632944226265, 2.9717880352109205e-06, 1.287924305870547e-06, 1.661971055000322e-06, 3.153397528876667e-06, 7.608554369653575e-06, 4.4805673837799986e-07, 4.628855549526634e-06, 4.462080141820479e-06, 4.640815859602299e-06, 4.678133336710744e-06, 2.2255193471210077e-05, 0.000688504078425467, 5.880861499463208e-05, 5.511297786142677e-05, 0.0013147693825885653, 0.0004210416809655726, 0.000527929631061852, 0.00030591568793170154, 0.0011363036464899778, 0.004935148172080517, 0.9903199076652527, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0009000818245112896, 3.46090855600778e-05, 6.00008161200094e-06, 1.3317902585185948e-06, 8.382407031604089e-06, 7.950188773975242e-06, 8.352956228918629e-07, 5.017455350753153e-06, 1.1085563528467901e-05, 1.5506169802392833e-05, 2.244969073217362e-05, 3.2394586014561355e-05, 7.153382466640323e-05, 0.00011106140300398692, 6.552063041453948e-06, 3.557855961844325e-05, 0.00046084230416454375, 0.0006021021399646997, 0.00773558858782053, 0.0047313859686255455, 0.012920131906867027, 0.0169991385191679, 0.9552805423736572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.094528311630711e-05, 5.4195348639041185e-05, 2.1191086489125155e-05, 8.660334174237505e-07, 5.241397047939245e-06, 2.811412286973791e-06, 9.647682190916385e-07, 4.259624347469071e-06, 6.819966074544936e-06, 2.6370105388195952e-06, 1.038735263136914e-05, 3.11777948809322e-05, 2.574707286839839e-05, 8.829366561258212e-05, 0.0001053006635629572, 0.0003744478744920343, 0.0005833793547935784, 0.0009019345161505044, 0.00043120188638567924, 0.004991129040718079, 0.003515928518027067, 0.015127496793866158, 0.018385041505098343, 0.9552487730979919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00019926734967157245, 5.897880441807501e-07, 4.093079439826397e-07, 5.283635005071119e-07, 4.043731394176575e-07, 6.811440016463166e-07, 2.5019514282575983e-07, 3.190987456491712e-07, 5.018005595047725e-06, 3.059930349991191e-06, 4.776866262545809e-06, 8.106227141979616e-06, 1.787102701200638e-05, 5.904932550038211e-05, 7.019496479188092e-06, 5.101937131257728e-05, 0.0001541965757496655, 0.0001555776543682441, 0.0004630949115380645, 0.00018736706988420337, 0.0029354498255997896, 0.00699869217351079, 0.004895060323178768, 0.010302471928298473, 0.9735496640205383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [4.041891952510923e-05, 7.668172763430903e-09, 6.183981327012589e-08, 4.109946871722059e-08, 3.1613390660822915e-07, 1.0004030315258206e-07, 6.658518003632707e-08, 4.780262656822742e-07, 4.035145551029018e-08, 6.753236448275857e-06, 8.574267695848903e-08, 1.0514231973957067e-07, 3.270276693001506e-06, 4.896545533483732e-07, 1.2450341273506638e-06, 9.069827683561016e-06, 2.0693112219305476e-06, 8.541710485587828e-06, 4.5136250264476985e-05, 8.52817902341485e-05, 8.47626943141222e-05, 0.0010267914040014148, 0.001334777451120317, 0.00029600723064504564, 0.0056267851032316685, 0.9914274215698242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003747466835193336, 1.2430140827746072e-07, 2.5229209654753504e-07, 3.052446118090302e-07, 4.772530246555107e-06, 6.075460419197043e-07, 8.50173705657653e-07, 1.1030846508219838e-05, 8.098998449668215e-08, 9.651313348513213e-07, 7.193358442236786e-07, 3.2339411859538814e-07, 1.760547775120358e-06, 4.446830530469015e-07, 3.298762862868898e-07, 2.4300346922245808e-05, 3.6642684335674858e-06, 3.0616458843724104e-06, 2.627130743348971e-05, 0.00034267170121893287, 2.078816032735631e-05, 0.00013409749954007566, 0.000304724439047277, 9.803617285797372e-05, 0.0004919689381495118, 0.004237073939293623, 0.9939160943031311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023197678092401475, 7.363636882473656e-07, 1.0658059181878343e-06, 4.7497985633526696e-07, 2.187789050367428e-06, 2.074172016364173e-06, 1.384211998356477e-07, 2.51064807343937e-06, 1.9716030408289953e-07, 6.672007202723762e-06, 8.991812592284987e-07, 6.362203635035257e-07, 6.544809139086283e-07, 7.71796749177156e-07, 4.801893851436034e-07, 1.112231893785065e-05, 5.561920261243358e-06, 3.862761786876945e-06, 6.753717025276273e-05, 0.0002897954545915127, 4.372503826743923e-05, 0.00015209027333185077, 0.0009337739902548492, 0.0001815940486267209, 8.423312101513147e-05, 0.009933865629136562, 0.008723159320652485, 0.979318380355835, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00015704902762081474, 3.123183773823257e-07, 2.931928975158371e-07, 3.137148496534792e-07, 2.1960925096209394e-06, 1.4164401136440574e-06, 1.123638185163145e-06, 1.3091762411931995e-06, 5.9215043535232326e-08, 7.978067628755525e-07, 2.803677261908888e-06, 1.9766923742281506e-07, 3.994018413777667e-07, 2.3048994535201928e-07, 2.264246631966671e-06, 1.6729463823139668e-05, 1.6667603404130205e-06, 2.8725414722430287e-06, 2.494689942977857e-05, 0.00025532764266245067, 4.849691322306171e-06, 4.708057167590596e-05, 5.325666279532015e-05, 4.240333873894997e-05, 0.00020874859183095396, 0.0020438090432435274, 0.08346706628799438, 0.003672999795526266, 0.9099873900413513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010030753910541534, 7.605907740071416e-06, 5.47890385860228e-06, 4.704082584794378e-06, 1.08182439362281e-06, 7.24684241504292e-07, 6.057198334019631e-07, 1.5847817849135026e-06, 3.1830979423830286e-05, 1.844483222157578e-06, 1.3723778238272644e-06, 6.841019512648927e-06, 4.9961122385866474e-06, 0.00014220463344827294, 2.1025923615525244e-06, 2.0461138774408028e-05, 6.875459075672552e-05, 8.339442138094455e-05, 7.060819916659966e-05, 0.0002227002987638116, 0.0013453519204631448, 0.0011953136418014765, 0.0007637701346538961, 0.003412768244743347, 0.009595143608748913, 0.008245961740612984, 0.004028412979096174, 0.015673460438847542, 0.03710905462503433, 0.916948676109314, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014598063717130572, 1.3442448221212544e-07, 3.0679643714393023e-07, 1.2700814977506525e-07, 9.539689216353509e-08, 4.421364963036467e-08, 7.2709593901265634e-09, 2.16305849676246e-07, 1.7861790979623038e-07, 1.1440969416298685e-07, 4.546686227513419e-08, 1.1406672228986281e-07, 1.7846296884727053e-07, 8.568714520151843e-07, 1.0497461744307657e-07, 1.2474922641558805e-06, 1.168266066997603e-06, 6.485002472800261e-07, 9.923046491167042e-06, 2.663560189830605e-05, 2.1481033400050364e-05, 7.19235249562189e-05, 0.00015873301890678704, 0.00014563217700924724, 0.0024261672515422106, 0.001514493953436613, 0.0007063172524794936, 0.0022442839108407497, 0.004566811490803957, 0.00983233842998743, 0.9781237244606018, 0.0, 0.0, 0.0, 0.0], [1.0698774531192612e-05, 5.128419644506721e-08, 7.382501365782446e-08, 9.797496858254817e-08, 4.94486982915987e-07, 6.269730761232495e-07, 2.625734509820177e-07, 7.36192021122406e-07, 2.5101189748966135e-07, 2.176487896576873e-06, 5.36374670900841e-07, 8.60690761328442e-07, 2.151581099951727e-07, 1.0358829740653164e-06, 2.489502151092893e-07, 1.3481044334184844e-05, 8.521074960299302e-06, 5.148507170815719e-06, 4.645082753995666e-06, 1.683262780716177e-05, 5.8646506658988073e-05, 3.652455779956654e-05, 0.00016485729429405183, 1.1945001460844651e-05, 0.0005173994577489793, 0.0024279053322970867, 0.00034773541847243905, 0.0015964063350111246, 0.009022926911711693, 0.013163723051548004, 0.06333820521831512, 0.9092468023300171, 0.0, 0.0, 0.0], [0.0012287310091778636, 8.407658242504112e-06, 8.363959750568029e-06, 8.199026524380315e-06, 3.972178546973737e-06, 3.9872684283182025e-06, 1.5942541722324677e-06, 4.764995537698269e-06, 4.4619187065109145e-06, 8.699215868546162e-06, 3.48229764313146e-06, 4.087222805537749e-06, 4.383185569167836e-06, 1.2878697816631757e-05, 2.764999408100266e-06, 1.1550821000128053e-05, 2.8508404284366407e-05, 1.972618883883115e-05, 8.007970609469339e-05, 0.0001638159592403099, 0.0002766103425528854, 0.00048299774061888456, 0.0005903018172830343, 0.001175062032416463, 0.003466710913926363, 0.005802723579108715, 0.011907556094229221, 0.01695297285914421, 0.028466513380408287, 0.06137575954198837, 0.11517595499753952, 0.20177732408046722, 0.5509370565414429, 0.0, 0.0], [3.782525527640246e-05, 6.459638512978927e-08, 1.927358184161676e-08, 7.975797444714772e-08, 6.700330459352699e-07, 1.2464336407447263e-07, 3.072165100093116e-08, 3.3671460641926387e-07, 9.953986790378622e-08, 4.5415069394039165e-07, 3.406016446660942e-08, 1.7256121509490185e-07, 3.3590222869861464e-07, 3.2563309559918707e-07, 1.1636584140717332e-08, 3.2042096336226678e-06, 1.2533513427115395e-06, 1.7663038534010411e-06, 1.112595055019483e-05, 2.0410294382600114e-05, 8.103424079308752e-06, 1.2881071597803384e-05, 0.00014193193055689335, 1.1411083505663555e-05, 0.00010671326890587807, 0.00010951125295832753, 0.0017927117878571153, 0.0015404942678287625, 0.0012465205509215593, 0.001597587252035737, 0.0008927029557526112, 0.009557013399899006, 0.009279937483370304, 0.9736242294311523, 0.0], [0.0003539699246175587, 2.6440395686222473e-06, 1.7576170421307324e-06, 1.2348089057923062e-06, 5.949707428953843e-06, 1.309189087805862e-06, 3.3621091688473825e-07, 2.4850550062183174e-07, 6.705465125378396e-07, 6.699529819798045e-08, 6.061921453692776e-07, 4.6190618263608485e-07, 2.357329321966972e-06, 1.4622188473367714e-06, 2.976372002194694e-07, 1.6005818679332151e-06, 2.460905989210005e-06, 1.931721726577962e-06, 3.200153514626436e-05, 2.465201214363333e-05, 3.429644129937515e-05, 0.00016550871077924967, 7.883973012212664e-05, 0.00018387162708677351, 0.0011651529930531979, 0.00012255363981239498, 0.0011725217336788774, 0.0004984794650226831, 0.003501484403386712, 0.003400748362764716, 0.01183952484279871, 0.005179092288017273, 0.016713876277208328, 0.0291277002543211, 0.9263802766799927]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9238101243972778, 0.07618984580039978, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37589243054389954, 0.10050596296787262, 0.5236016511917114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.41213729977607727, 0.0823158249258995, 0.1808476597070694, 0.32469916343688965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1405227929353714, 0.005812313407659531, 0.02827640250325203, 0.05733036249876022, 0.768058180809021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019230686128139496, 0.0014746804954484105, 0.0016810785746201873, 0.004905834794044495, 0.02590656280517578, 0.9468011260032654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006040878128260374, 0.0046582273207604885, 0.012865055352449417, 0.008953898213803768, 0.07021685689687729, 0.12025348842144012, 0.7770116925239563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01624826155602932, 0.003929380793124437, 0.012836656533181667, 0.005099628586322069, 0.01735418289899826, 0.01559932716190815, 0.1360277235507965, 0.7929048538208008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13423283398151398, 0.07014793902635574, 0.03862922266125679, 0.035926904529333115, 0.05720481649041176, 0.06419362872838974, 0.03908977285027504, 0.2145734578371048, 0.34600141644477844, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003595878602936864, 0.00038495013723149896, 0.0004921666695736349, 0.0008088786853477359, 0.0025900965556502342, 0.002407651860266924, 0.0001713183446554467, 0.011153006926178932, 0.0021147800143808126, 0.9762812852859497, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00022834500123281032, 4.6662524255225435e-05, 8.206470374716446e-05, 7.730659854132682e-05, 0.00012034244718961418, 0.004319248721003532, 0.0038442215882241726, 0.0011964994482696056, 0.00016446932568214834, 0.8530564308166504, 0.13686434924602509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06578908115625381, 0.01929076574742794, 0.020492710173130035, 0.021956786513328552, 0.026686685159802437, 0.08618338406085968, 0.031040921807289124, 0.16103026270866394, 0.030162539333105087, 0.2132367640733719, 0.07554478198289871, 0.24858534336090088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009123365394771099, 0.0033993141259998083, 0.016818273812532425, 0.0046488139778375626, 0.014602283015847206, 0.05833256617188454, 0.07909013330936432, 0.01766362227499485, 0.016087274998426437, 0.15053576231002808, 0.3343389630317688, 0.054388951510190964, 0.24097071588039398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04253435507416725, 0.01655057817697525, 0.007813412696123123, 0.006833461578935385, 0.009650957770645618, 0.009173310361802578, 0.005910305771976709, 0.030093098059296608, 0.05324171483516693, 0.035758912563323975, 0.11968681961297989, 0.07133747637271881, 0.2969222068786621, 0.2944934368133545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010158021003007889, 0.004377414006739855, 0.0065031819976866245, 0.003546682884916663, 0.006157048046588898, 0.0051498133689165115, 0.0041582416743040085, 0.014994010329246521, 0.017724109813570976, 0.00860963761806488, 0.013557267375290394, 0.027689799666404724, 0.027776118367910385, 0.08518608659505844, 0.7644126415252686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005760948988609016, 3.758495586225763e-05, 3.100582762272097e-05, 2.8090938940295018e-05, 0.00011757250467780977, 0.0010626517469063401, 0.0008489806205034256, 0.0023644352331757545, 0.00031711836345493793, 0.000504071416798979, 0.0005438976222649217, 0.000996467424556613, 0.004787209909409285, 0.0016582176322117448, 0.021181173622608185, 0.964945375919342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.057101089507341385, 0.012982717715203762, 0.01246335543692112, 0.012371198274195194, 0.013064750470221043, 0.03530249372124672, 0.013208809308707714, 0.06362835317850113, 0.01058889739215374, 0.06113199144601822, 0.027357177808880806, 0.08200794458389282, 0.039974600076675415, 0.043028347194194794, 0.06893422454595566, 0.06733895093202591, 0.3795151114463806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05038188025355339, 0.010253245010972023, 0.009017400443553925, 0.007853329181671143, 0.008382106199860573, 0.016030551865696907, 0.007579755503684282, 0.016568155959248543, 0.009558070451021194, 0.020098434761166573, 0.028027689084410667, 0.031728412955999374, 0.021793978288769722, 0.03942330181598663, 0.11988720297813416, 0.047830890864133835, 0.14773690700531006, 0.4078487157821655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009583805687725544, 0.0005122209549881518, 0.0006106940563768148, 0.0009717896464280784, 0.0022611061576753855, 0.004041271284222603, 0.0003397607943043113, 0.002301486674696207, 0.0014669836964458227, 0.004360882565379143, 0.010039575397968292, 0.003883794415742159, 0.0019065389642491937, 0.004968372173607349, 0.0035998853854835033, 0.0027956583071500063, 0.01562882587313652, 0.014497026801109314, 0.916230320930481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03377579152584076, 0.0008472931804135442, 0.000936156720854342, 0.0006967569352127612, 0.004600144922733307, 0.0032576010562479496, 0.0004218367685098201, 0.007556708063930273, 0.0010570590384304523, 0.003643788630142808, 0.00017823856614995748, 0.0020456223282963037, 0.0014812115114182234, 0.002918048994615674, 0.005684820935130119, 0.06616660207509995, 0.00682071503251791, 0.005966112483292818, 0.022306203842163086, 0.8296393752098083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014338111504912376, 0.004506281577050686, 0.0022934828884899616, 0.004502632189542055, 0.006348527502268553, 0.006440699566155672, 0.0030759212095290422, 0.0034293788485229015, 0.008825041353702545, 0.013563876040279865, 0.008806232362985611, 0.01533306110650301, 0.01093036774545908, 0.03256243094801903, 0.041650138795375824, 0.029358427971601486, 0.06823208928108215, 0.10101231187582016, 0.1282440423965454, 0.08141806721687317, 0.41512882709503174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01251694094389677, 0.0037073830608278513, 0.0011323611252009869, 0.002044015796855092, 0.0021037994883954525, 0.0007217561942525208, 0.0003587713581509888, 0.0010654578218236566, 0.0033418689854443073, 0.0035347735974937677, 0.0018008295446634293, 0.005131382495164871, 0.005956846754997969, 0.01168146263808012, 0.023353146389126778, 0.024626368656754494, 0.023082589730620384, 0.02405393123626709, 0.045054007321596146, 0.0444747693836689, 0.09848438203334808, 0.6617730855941772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023378070443868637, 0.0029700917657464743, 0.0022721646819263697, 0.003121253103017807, 0.010448778979480267, 0.002795709762722254, 0.0009500709129497409, 0.006640288978815079, 0.0025093008298426867, 0.006215895060449839, 0.001875662594102323, 0.004366472829133272, 0.005894929636269808, 0.007904242724180222, 0.011842518113553524, 0.011780311353504658, 0.016934016719460487, 0.015606734901666641, 0.03699193149805069, 0.0567626990377903, 0.03885180875658989, 0.301069051027298, 0.4288180470466614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04225083813071251, 0.009647667407989502, 0.013069665990769863, 0.003493925556540489, 0.008718243800103664, 0.000871763622853905, 0.002113071270287037, 0.002520156092941761, 0.0028259288519620895, 0.003056257264688611, 0.005475991405546665, 0.004467588383704424, 0.005966207478195429, 0.008145663887262344, 0.02767091430723667, 0.01338263601064682, 0.01818913035094738, 0.03278025612235069, 0.028848372399806976, 0.05995951220393181, 0.09605942666530609, 0.20931926369667053, 0.10138265788555145, 0.2997848689556122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02581801638007164, 0.0012453029630705714, 0.0012367713497951627, 0.0031558219343423843, 0.0026054559275507927, 0.0011178313288837671, 0.00023053240147419274, 0.0010614547645673156, 0.0012552998960018158, 0.001447018003091216, 0.0006083032349124551, 0.0021444344893097878, 0.0017222744645550847, 0.003063677344471216, 0.002130713313817978, 0.0017395151080563664, 0.00748956436291337, 0.004201174713671207, 0.016367286443710327, 0.017187530174851418, 0.016647029668092728, 0.06787320226430893, 0.07546126842498779, 0.04369649291038513, 0.7004940509796143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0075083100236952305, 0.00012913934187963605, 0.00022904042270965874, 0.0003099401656072587, 0.0015875755343586206, 0.00015740832895971835, 0.00036546686897054315, 0.00026319536846131086, 0.00024618778843432665, 0.004963850136846304, 0.0008493296336382627, 0.0002054251090157777, 0.0035996607039123774, 0.0006757518276572227, 0.0006743196863681078, 0.0028660367242991924, 0.0007401995826512575, 0.0012410671915858984, 0.0034339376725256443, 0.003348805010318756, 0.005896297283470631, 0.015315240249037743, 0.01358444057404995, 0.003806075546890497, 0.10587518662214279, 0.8221280574798584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0151468301191926, 0.0002837271895259619, 0.00043238894431851804, 0.0012392138596624136, 0.0026600719429552555, 0.0003459543804638088, 0.0002954268711619079, 0.001877208356745541, 0.00023691265960223973, 0.00013219252286944538, 0.00033548095962032676, 0.00022997907944954932, 0.00027149065863341093, 0.0004209536127746105, 0.0008192582754418254, 0.0003039469593204558, 0.0006469368236139417, 0.0003804269654210657, 0.00239259609952569, 0.002976801944896579, 0.0025756140239536762, 0.005941803101450205, 0.005901214201003313, 0.005208784248679876, 0.025423727929592133, 0.02324126847088337, 0.900279700756073, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020882179960608482, 0.0006866250187158585, 0.001419030362740159, 0.0016247222665697336, 0.00546672660857439, 0.0019930703565478325, 0.00034445628989487886, 0.0014866319252178073, 0.00038602776476182044, 0.00029868001001887023, 0.0003715484926942736, 0.0005332499858923256, 0.0002567081246525049, 0.0006083347252570093, 0.0003786252054851502, 0.0013748225755989552, 0.0013781345915049314, 0.0009236660553142428, 0.023375004529953003, 0.03773234412074089, 0.004063981585204601, 0.021846620365977287, 0.018512384966015816, 0.005047200247645378, 0.01844027452170849, 0.06399491429328918, 0.3300280272960663, 0.4365460276603699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002729788888245821, 0.00011315739538986236, 0.0002574324607849121, 0.0003065295168198645, 0.0008012377074919641, 0.0008870939491316676, 0.00010111577284988016, 0.00204857112839818, 0.0001429120748071, 0.00019898073514923453, 0.00043098212336190045, 7.435750012518838e-05, 0.00011077819362981245, 0.00022297582472674549, 0.00010400119208497927, 0.0007566186832264066, 0.00018428826297167689, 0.0003102096379734576, 0.001059030182659626, 0.005394389387220144, 0.00137113977689296, 0.0017238217405974865, 0.0034383495803922415, 0.0007791540119796991, 0.0027107964269816875, 0.011246615089476109, 0.2618618905544281, 0.042864661663770676, 0.6577690839767456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0071692136116325855, 0.0026512283366173506, 0.0024450235068798065, 0.003023248864337802, 0.00268618855625391, 0.0007135469932109118, 0.0005127678159624338, 0.0003864858590532094, 0.0009532009717077017, 0.0004407844680827111, 0.0008591745281592011, 0.0012491042725741863, 0.0009424769668839872, 0.0016617258079349995, 0.0004435316368471831, 0.0014648408396169543, 0.0035774623975157738, 0.003767341608181596, 0.012122927233576775, 0.0068539101630449295, 0.0052495673298835754, 0.019704235717654228, 0.02666923776268959, 0.04096020758152008, 0.2385396957397461, 0.05725710466504097, 0.04040537402033806, 0.10933990776538849, 0.0773630142211914, 0.3305874466896057, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011626659892499447, 0.001965817529708147, 0.000917952274903655, 0.001819743076339364, 0.002078979043290019, 0.00029357121093198657, 0.00010028555698227137, 0.0005799980135634542, 0.0004854121943935752, 9.76483934209682e-05, 0.00015712760796304792, 0.0004106423002667725, 0.0004877776955254376, 0.0007517863996326923, 0.0007532844902016222, 0.0012242123484611511, 0.0010826843790709972, 0.0014821900986135006, 0.002774250227957964, 0.003610333427786827, 0.0021372432820498943, 0.009361447766423225, 0.014277669601142406, 0.011846723966300488, 0.04729338735342026, 0.0450628437101841, 0.041560713201761246, 0.0428079329431057, 0.07079776376485825, 0.10084827989339828, 0.581305742263794, 0.0, 0.0, 0.0, 0.0], [0.003873431822285056, 0.0002557096304371953, 0.0006259246729314327, 0.000584396009799093, 0.0012326475698500872, 0.0003945602220483124, 0.0003326675796415657, 0.0001558193762321025, 0.0001647270837565884, 0.0007726293406449258, 0.00038669799687340856, 0.00027824443532153964, 0.00015239720232784748, 0.0002519854169804603, 6.452928209910169e-05, 0.00017264121561311185, 0.0007133580511435866, 0.0005384793621487916, 0.007539559621363878, 0.006723249331116676, 0.0013963916571810842, 0.003110351273790002, 0.005501286126673222, 0.0024135862477123737, 0.03896055370569229, 0.02342233993113041, 0.009641132317483425, 0.0257509034126997, 0.1270248144865036, 0.04005927965044975, 0.5142089128494263, 0.183296799659729, 0.0, 0.0, 0.0], [0.015151121653616428, 0.0013760682195425034, 0.0015560504980385303, 0.002171708969399333, 0.0025110088754445314, 0.0017854946199804544, 0.0004700868739746511, 0.0006788124446757138, 0.00038990736356936395, 0.0009900371078401804, 0.00038026581751182675, 0.0004182498960290104, 0.00044352930854074657, 0.0005140133434906602, 0.000165922348969616, 0.0006932562100701034, 0.000962950405664742, 0.0007656950037926435, 0.004365225322544575, 0.006436270661652088, 0.0018688273848965764, 0.008356152102351189, 0.006384757813066244, 0.005890711210668087, 0.03118702583014965, 0.04100947082042694, 0.02856607548892498, 0.0415772907435894, 0.04076455533504486, 0.06712847948074341, 0.30426734685897827, 0.2161882370710373, 0.1645854264497757, 0.0, 0.0], [0.017354115843772888, 0.0005264719948172569, 0.0006208931445144117, 0.0016926320968195796, 0.006297261919826269, 0.0010202121920883656, 7.362554606515914e-05, 0.0006762278499081731, 0.0004448314430192113, 7.778885628795251e-05, 4.973802424501628e-05, 0.0003035981208086014, 0.00017341793864034116, 0.0005162438028492033, 0.0002735278394538909, 0.0007444005459547043, 0.000602221698500216, 0.00045445014256983995, 0.002665338572114706, 0.0026638759300112724, 0.0025515947490930557, 0.007818799465894699, 0.009490985423326492, 0.000983040896244347, 0.007624232675880194, 0.011552365496754646, 0.09579716622829437, 0.08069906383752823, 0.09889815747737885, 0.037996113300323486, 0.05835621803998947, 0.11718904227018356, 0.11656814068555832, 0.31724417209625244, 0.0], [0.01079633366316557, 0.0030184623319655657, 0.0017010803567245603, 0.0027613984420895576, 0.005546445958316326, 0.0005509479669854045, 0.0002220834867330268, 0.00023305877402890474, 0.0008555078529752791, 8.429398440057412e-05, 0.00013491032586898655, 0.000403034093324095, 0.00021568548982031643, 0.0009122331975959241, 0.0007261995924636722, 0.0003818847762886435, 0.0007406800868920982, 0.0007301227888092399, 0.0007852280396036804, 0.0013473378494381905, 0.004313782323151827, 0.007729175500571728, 0.005422806367278099, 0.0067470804788172245, 0.013981981202960014, 0.004630994983017445, 0.01939181052148342, 0.02813369780778885, 0.016861913725733757, 0.07724324613809586, 0.05435158312320709, 0.13139021396636963, 0.15014058351516724, 0.08434385061264038, 0.3631702959537506]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1932608187198639, 0.8067392110824585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09132359176874161, 0.002221881179139018, 0.9064545035362244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07127517461776733, 0.010394562967121601, 0.014608713798224926, 0.9037216305732727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00752516184002161, 8.942761633079499e-05, 7.544131221948192e-05, 3.413583499423112e-06, 0.9923065304756165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004521056544035673, 4.2805095290532336e-06, 9.230424620909616e-05, 2.3636299374629743e-05, 1.1194422768312506e-05, 0.9953475594520569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00793814193457365, 0.00010465264494996518, 4.1882482037181035e-05, 8.376296136702877e-06, 0.00021111464593559504, 3.129790229650098e-06, 0.9916926622390747, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0024528508074581623, 1.0800506970554125e-05, 1.5410754713229835e-05, 2.2521547293763433e-07, 3.9251284761121497e-05, 5.1336105570953805e-06, 2.3800499548087828e-05, 0.9974525570869446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1994483917951584, 0.17831814289093018, 0.06548024713993073, 0.13276459276676178, 0.03858451172709465, 0.010353409685194492, 0.021433597430586815, 0.006723289843648672, 0.34689387679100037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014458474470302463, 8.054711315708118e-07, 3.064588599954732e-05, 7.412928084704618e-07, 2.0274044345569564e-06, 1.1259045095357578e-05, 1.8223396409666748e-06, 8.012940816115588e-05, 1.056965501788909e-07, 0.9984266757965088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002338015241548419, 1.2498665455495939e-05, 2.2450083633884788e-05, 4.236496351950336e-06, 2.952029092284647e-07, 1.8947017679238343e-06, 7.769844523863867e-05, 8.96904748515226e-06, 4.6951914356441193e-08, 1.1347646022841218e-06, 0.9975327253341675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.047514572739601135, 0.05268261581659317, 0.020408116281032562, 0.0585300549864769, 0.0071665639989078045, 0.008201424032449722, 0.01184640172868967, 0.0017474382184445858, 0.024963321164250374, 0.0026972556952387094, 0.0014261910691857338, 0.7628160715103149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006070810370147228, 0.0001295793626923114, 5.943352516624145e-05, 5.6593567023810465e-06, 0.00026153295766562223, 0.00012241856893524528, 1.0399356142443139e-05, 1.1076404007326346e-05, 4.060484855017421e-07, 0.0003600475611165166, 2.011545075220056e-05, 1.3643935403706564e-07, 0.9929484128952026, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09530564397573471, 0.14180324971675873, 0.050381824374198914, 0.10299669951200485, 0.02981209009885788, 0.0065894112922251225, 0.01682439260184765, 0.004481852985918522, 0.23106449842453003, 0.019435428082942963, 0.01087439525872469, 0.05543200671672821, 0.035438716411590576, 0.1995597779750824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027447829023003578, 0.00014065347204450518, 0.0001984664995688945, 3.49676665791776e-05, 5.282148777041584e-06, 0.00015024204913061112, 8.128349873004481e-05, 1.21251378004672e-05, 6.303894042503089e-05, 6.543214112753049e-05, 2.8324877803243e-06, 3.890726657118648e-05, 5.673631449099048e-07, 4.210483166389167e-05, 0.9717161655426025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004212117288261652, 3.0696890462422743e-05, 6.369442417053506e-05, 8.254564818344079e-07, 8.262140909209847e-07, 3.86834581149742e-05, 4.268815246177837e-06, 3.81940662919078e-06, 1.262802555856979e-07, 0.00013782763562630862, 1.7806130927056074e-05, 1.7100234117606306e-08, 5.979883553663967e-06, 6.190309420617268e-08, 2.2941594579606317e-06, 0.9954808950424194, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019846780225634575, 0.03168344125151634, 0.012553277425467968, 0.03571881353855133, 0.0043990155681967735, 0.0043505714274942875, 0.00742737203836441, 0.0009372890344820917, 0.01266288198530674, 0.001605055294930935, 0.0007319959113374352, 0.4563407897949219, 0.00201086956076324, 0.009759278036653996, 0.008237503468990326, 0.00025941262720152736, 0.3914756774902344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027297209948301315, 0.0024357072543352842, 0.0002706822706386447, 7.525584078393877e-05, 1.3686860256711952e-05, 5.773238626716193e-06, 0.0004301840381231159, 1.443816927348962e-05, 4.835141226067208e-05, 5.326117025106214e-05, 9.613328074919991e-06, 6.846700853202492e-05, 0.0003037679416593164, 2.878391751437448e-05, 3.866398037644103e-05, 2.5926818125299178e-05, 4.6800560085102916e-05, 0.9688335061073303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006310693453997374, 3.294685302535072e-05, 9.895686162053607e-06, 7.334584211093897e-07, 9.119841706706211e-05, 4.094936957699247e-05, 8.511712621839251e-06, 9.950702224159613e-05, 1.9264814454800216e-07, 8.829226771922549e-07, 1.890608700705343e-06, 1.1808706403826363e-06, 3.1165191103355028e-06, 9.47476834767258e-08, 3.301757942608674e-06, 2.585525180620607e-05, 7.711307148383639e-07, 2.6708685254561715e-06, 0.993365466594696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011340517085045576, 6.961923190829111e-06, 1.2364388567220885e-05, 4.006550682333909e-07, 5.351815343601629e-05, 5.240096470515709e-06, 4.459505726117641e-05, 0.00016450765542685986, 1.4344478493910628e-08, 1.0388021109974943e-06, 4.77888788736891e-05, 5.0586844935196495e-08, 9.468209896112967e-07, 7.475676966350875e-09, 6.603928000004089e-07, 3.843115337076597e-06, 3.346431753925572e-08, 2.411975685845391e-07, 1.6647767552058212e-05, 0.9985072016716003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08800846338272095, 0.18921291828155518, 0.045562561601400375, 0.08163290470838547, 0.017358077690005302, 0.0048304032534360886, 0.01895879954099655, 0.0046201348304748535, 0.06910265982151031, 0.012970476411283016, 0.010343024507164955, 0.05366411805152893, 0.009830267168581486, 0.05797473341226578, 0.011936412192881107, 0.00944663304835558, 0.04662337899208069, 0.07882607728242874, 0.010427417233586311, 0.0020946746226400137, 0.1765758991241455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01597118191421032, 0.003062016097828746, 0.0001418951724190265, 0.0007885746890679002, 4.299372449168004e-05, 4.131201058044098e-05, 6.306873547146097e-05, 3.546515245034243e-06, 2.173127722926438e-05, 1.7860953448689543e-05, 1.0213988389295992e-05, 2.6596406314638443e-05, 3.785551598411985e-05, 1.3186858268454671e-05, 0.00018817681120708585, 4.963882020092569e-06, 1.8085114788846113e-05, 4.8640275053912774e-05, 4.463595359993633e-06, 2.4802504867693642e-06, 1.2178916222183034e-05, 0.9794788956642151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0074722301214933395, 0.00037190725561231375, 7.639086834387854e-05, 1.1135914974147454e-05, 3.0148716177791357e-05, 1.1014429219358135e-05, 5.4528787586605176e-05, 2.244440111098811e-05, 1.1283858839306049e-05, 2.8587872293428518e-05, 5.627739938063314e-06, 7.513614400522783e-05, 7.73429565015249e-05, 6.529718575620791e-06, 8.796916517894715e-06, 8.651511052448768e-06, 5.0727925554383546e-05, 7.0408632382168435e-06, 3.1876450520940125e-05, 1.4034882269697846e-06, 7.003588507359382e-06, 7.040087803034112e-05, 0.9915598034858704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02204541489481926, 0.28049421310424805, 0.016674764454364777, 0.0001508713758084923, 0.0006804470322094858, 2.7394113203627057e-05, 0.0008938325918279588, 1.249920478585409e-05, 0.00026655319379642606, 5.584166046901373e-06, 5.109102130518295e-05, 9.500431769993156e-05, 1.8194787116954103e-05, 0.0001828282547648996, 0.0016493600560352206, 2.7935184334637597e-05, 6.99191732564941e-05, 7.677565736230463e-05, 2.0886143829557113e-05, 4.512566647463245e-06, 0.0001454139273846522, 0.00044704994070343673, 5.514781514648348e-05, 0.6759043335914612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01879945769906044, 0.0019184600096195936, 0.0010523868259042501, 7.228145841509104e-05, 0.000137966126203537, 5.208816219237633e-05, 6.334375939331949e-05, 9.731957106851041e-06, 8.120811253320426e-05, 5.998387496219948e-05, 9.63596539804712e-06, 4.8187135689659044e-05, 4.688356784754433e-05, 5.250570393400267e-05, 0.00044942068052478135, 0.00028932970599271357, 3.537202792358585e-05, 0.00022377951245289296, 0.00020209007197991014, 3.112009608230437e-06, 3.5228513297624886e-05, 9.855003008851781e-05, 0.00018101489695254713, 0.00012300792150199413, 0.9759548306465149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0016589765436947346, 6.6324769250059035e-06, 3.9323440432781354e-05, 5.5121408877312206e-06, 7.328293577302247e-05, 5.176199238121626e-07, 8.362679363926873e-05, 1.6115403923322447e-05, 1.8407968127576169e-07, 0.00020032595784869045, 1.849748059612466e-06, 7.683036784555952e-08, 1.8051048755296506e-05, 9.259753852575159e-08, 6.612178367504384e-06, 1.962786427611718e-06, 5.0048473809738425e-08, 6.371125493842555e-08, 4.881649147137068e-07, 3.839147211692762e-06, 1.8601497231429676e-08, 1.6708673911125516e-06, 8.81660753293545e-07, 6.673342767271606e-08, 1.878518105513649e-07, 0.9978796243667603, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005040670745074749, 0.00039155586273409426, 0.000561871042009443, 0.00014523064601235092, 3.937192013836466e-05, 5.4099655244499445e-05, 0.000284795300103724, 4.828744931728579e-05, 3.104319375779596e-06, 6.896281411172822e-05, 0.0002681417390704155, 4.2109372770937625e-06, 1.2119896382500883e-05, 2.0253992261132225e-06, 3.188784830854274e-05, 1.1356536560924724e-05, 3.0188034543243703e-06, 1.2622916983673349e-05, 7.4655908974818885e-06, 3.0278133635874838e-06, 4.951124878971314e-07, 3.015461152244825e-05, 1.886378049675841e-05, 4.1512544157740194e-06, 5.031331511418102e-06, 6.06908906775061e-06, 0.9929414987564087, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012448678025975823, 0.00017617041885387152, 2.4151753677870147e-05, 1.2456692275009118e-05, 5.211313327890821e-05, 2.3546064767288044e-05, 5.673457053489983e-05, 0.00045827735448256135, 2.4983903585962253e-06, 0.00011349430133122951, 4.9202564696315676e-05, 1.3444564501696732e-05, 7.735941471764818e-05, 1.3437108918878948e-06, 6.060910891392268e-06, 0.00010331783414585516, 8.745500053919386e-06, 1.0811584616021719e-05, 0.0001585641730343923, 1.9056084283874952e-06, 5.418800128609291e-07, 1.232136924045335e-06, 6.472238601418212e-05, 3.5890639082936104e-06, 8.650918061903212e-06, 2.9628040465468075e-06, 1.3278973710839637e-05, 0.9973099231719971, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001973335398361087, 0.0009750564931891859, 7.218521932372823e-05, 9.848416084423661e-05, 4.9608672270551324e-05, 5.4340576753020287e-05, 0.0003797206445597112, 6.184627181937685e-06, 1.0831159897861653e-06, 4.491215349844424e-06, 0.0004798352310899645, 9.928658073476981e-07, 1.3564559594669845e-05, 6.477191618614597e-07, 1.0186123290623073e-05, 5.581327059189789e-06, 7.11347752258007e-07, 5.998071515023184e-07, 3.2010909762902884e-06, 2.288285941176582e-06, 1.5130844133182109e-07, 7.130760423024185e-06, 1.7937974234882859e-06, 2.402572863502428e-05, 2.833118344369723e-07, 1.2269152648514137e-05, 0.00023325464280787855, 0.0003131963894702494, 0.9952758550643921, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030099282041192055, 0.09027378261089325, 0.02814972773194313, 0.15763874351978302, 0.026473553851246834, 0.00300600822083652, 0.01721954718232155, 0.002244668547064066, 0.031200462952256203, 0.011351728811860085, 0.0013561318628489971, 0.029119187965989113, 0.0167735256254673, 0.023998098447918892, 0.00945053156465292, 0.006288205273449421, 0.023923052474856377, 0.058296240866184235, 0.009904228150844574, 0.0003779735998250544, 0.024595139548182487, 0.040420059114694595, 0.02788674272596836, 0.009823569096624851, 0.04994713142514229, 0.0010651148622855544, 0.014632527716457844, 0.011246386915445328, 0.0020601546857506037, 0.24117852747440338, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004169418942183256, 0.000614328368101269, 0.0005938458489254117, 0.00011036222713300958, 9.005510219139978e-05, 1.3705171113542747e-05, 0.0005903487908653915, 2.689233269848046e-06, 8.671501745993737e-06, 4.611639087670483e-05, 1.005678677756805e-05, 5.362908268580213e-06, 5.1998504204675555e-05, 4.802413968718611e-06, 2.119524469890166e-05, 2.478504757164046e-05, 3.4400377444399055e-06, 1.8410850316286087e-05, 7.055151218082756e-05, 5.603974955192825e-07, 5.060179319116287e-06, 2.2592150344280526e-05, 6.252543971640989e-05, 1.8619364709593356e-05, 0.00014118559192866087, 2.633108670124784e-05, 1.261043394151784e-06, 1.0759861197584542e-06, 3.0931974492887093e-07, 5.793054697278421e-06, 0.9932644367218018, 0.0, 0.0, 0.0, 0.0], [0.010566670447587967, 0.0013905902160331607, 0.0004313635581638664, 0.0010295939864590764, 0.003916396759450436, 0.00015029520727694035, 0.0019936019089072943, 0.0003044376790057868, 2.9845123208360747e-05, 0.0006592926802113652, 1.2659849744522944e-05, 7.52750929677859e-05, 0.00039767735870555043, 1.7276557628065348e-05, 0.00038583544665016234, 2.1061921870568767e-05, 5.3403142374008894e-05, 6.33502786513418e-05, 0.00012688453716691583, 6.783208391425433e-06, 2.717058850976173e-05, 0.00013008965470362455, 3.859863136312924e-05, 4.366650682641193e-05, 8.064091161941178e-06, 0.000746867444831878, 8.195245754905045e-06, 9.368611063109711e-05, 6.2524600252800155e-06, 4.447249375516549e-05, 0.00020698668959084898, 0.9770136475563049, 0.0, 0.0, 0.0], [0.017131486907601357, 0.10981205850839615, 0.04528496041893959, 0.16663990914821625, 0.04683493450284004, 0.012714344076812267, 0.024941841140389442, 0.0024605055805295706, 0.01651417277753353, 0.014018187299370766, 0.0028046509250998497, 0.01726130023598671, 0.05619135499000549, 0.01184318121522665, 0.024518396705389023, 0.008004878647625446, 0.013582986779510975, 0.027696536853909492, 0.007881492376327515, 0.001375964260660112, 0.009033636189997196, 0.03747997805476189, 0.014368826523423195, 0.01657966524362564, 0.03148625046014786, 0.0022351087536662817, 0.007032560650259256, 0.020338809117674828, 0.0021573659032583237, 0.01573573797941208, 0.03529255837202072, 0.01779499463737011, 0.16295136511325836, 0.0, 0.0], [0.0027362373657524586, 0.0032704402692615986, 0.00024938516435213387, 2.9521108444896527e-05, 0.0027190777473151684, 1.5680814613006078e-05, 0.0011440061498433352, 3.528553861542605e-05, 1.9352071831235662e-05, 3.620963980210945e-05, 1.2202220204926562e-05, 0.00012145638902438805, 4.9556045269127935e-05, 1.1851489034597762e-05, 8.826622797641903e-05, 3.184519300702959e-05, 8.618916035629809e-05, 0.00013057797332294285, 9.26754655665718e-05, 1.844452526711393e-05, 4.454882855497999e-06, 1.421102206222713e-05, 0.00020819788915105164, 6.224938988452777e-05, 2.7289990612189285e-05, 8.527088539267424e-06, 0.0010931704891845584, 0.0010258982656523585, 1.8266431652591564e-05, 9.816321835387498e-06, 7.599958280479768e-07, 4.151809662289452e-06, 8.365893336303998e-06, 0.9866164922714233, 0.0], [0.013301754370331764, 0.0020241746678948402, 0.0009810624178498983, 0.00027103928732685745, 0.02624255046248436, 6.968403613427654e-05, 0.00018824616563506424, 0.00033232715213671327, 0.00020717488951049745, 0.00035583574208430946, 1.8688768250285648e-05, 0.00031016304274089634, 0.0002884422428905964, 0.00014157555415295064, 0.00021018910047132522, 0.00013730116188526154, 0.00024542518076486886, 0.0005858629592694342, 0.0008409075089730322, 0.00037898405571468174, 0.00011255494609940797, 0.0009485270129516721, 0.00025817184359766543, 0.0005371627048589289, 0.00023706414503976703, 9.896148549159989e-05, 1.4541812561219558e-05, 7.51436164136976e-05, 1.0142423889192287e-05, 7.690770144108683e-05, 6.643275992246345e-05, 5.445994975161739e-05, 0.00010781989840324968, 0.002189120277762413, 0.9480817317962646]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9360752105712891, 0.06392484903335571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8446658253669739, 0.06946855783462524, 0.0858655795454979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6426600217819214, 0.12988688051700592, 0.17117170989513397, 0.056281305849552155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5074959993362427, 0.0778626948595047, 0.0726853534579277, 0.10711851716041565, 0.23483745753765106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4970755875110626, 0.06315258890390396, 0.1155911237001419, 0.08851397037506104, 0.1019636020064354, 0.1337031126022339, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30812814831733704, 0.06775974482297897, 0.13057540357112885, 0.054409369826316833, 0.040503211319446564, 0.36059141159057617, 0.03803272172808647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32434967160224915, 0.06349695473909378, 0.07783649116754532, 0.07798173278570175, 0.07410475611686707, 0.13590551912784576, 0.07038862258195877, 0.17593632638454437, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16412921249866486, 0.03469286113977432, 0.05131254345178604, 0.013316983357071877, 0.17712701857089996, 0.1595190316438675, 0.09812309592962265, 0.29690471291542053, 0.004874553997069597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18775460124015808, 0.054880447685718536, 0.10758272558450699, 0.043910037726163864, 0.1406543254852295, 0.11696729063987732, 0.052460040897130966, 0.1536639779806137, 0.049352679401636124, 0.09277382493019104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2051711082458496, 0.040068794041872025, 0.0833921879529953, 0.04565277323126793, 0.056970130652189255, 0.1331988424062729, 0.026416389271616936, 0.09950854629278183, 0.050134606659412384, 0.21417361497879028, 0.045312922447919846, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10754456371068954, 0.020955437794327736, 0.052468422800302505, 0.008330842480063438, 0.17997518181800842, 0.10652032494544983, 0.07210807502269745, 0.20191138982772827, 0.0033460466656833887, 0.140213280916214, 0.1035674586892128, 0.0030589583329856396, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09423349797725677, 0.02283540554344654, 0.05558856949210167, 0.026967845857143402, 0.12799425423145294, 0.07631109654903412, 0.07361149787902832, 0.16634686291217804, 0.030196350067853928, 0.11622443795204163, 0.1307915300130844, 0.022433554753661156, 0.056465111672878265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11027710884809494, 0.019917305558919907, 0.03387211635708809, 0.00801222212612629, 0.1268695592880249, 0.12052714824676514, 0.06604590266942978, 0.21159586310386658, 0.0029103809501975775, 0.13361388444900513, 0.07830420881509781, 0.005965673364698887, 0.07863970100879669, 0.0034490113612264395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16007709503173828, 0.05452115088701248, 0.0597362257540226, 0.020207513123750687, 0.05266042798757553, 0.10011065751314163, 0.11729258298873901, 0.14998750388622284, 0.017248373478651047, 0.05625281482934952, 0.09442037343978882, 0.01204691268503666, 0.020297691226005554, 0.018244566395878792, 0.06689617037773132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17850056290626526, 0.04271138831973076, 0.05876287817955017, 0.02550152689218521, 0.028219731524586678, 0.0939594954252243, 0.035697732120752335, 0.03853301331400871, 0.02757410891354084, 0.1241721361875534, 0.09900187700986862, 0.029919546097517014, 0.04168913885951042, 0.030038561671972275, 0.08029220998287201, 0.06542614102363586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08262607455253601, 0.014221644960343838, 0.03910331800580025, 0.005809774622321129, 0.14161063730716705, 0.08671100437641144, 0.05503494292497635, 0.15626993775367737, 0.0023281811736524105, 0.11679328233003616, 0.08067946135997772, 0.002191798761487007, 0.09792860597372055, 0.002736869268119335, 0.03297452628612518, 0.08037842810153961, 0.002601496409624815, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09858328104019165, 0.02832067385315895, 0.05263177677989006, 0.017858654260635376, 0.06163661181926727, 0.08070766925811768, 0.07397957891225815, 0.09560465067625046, 0.00933582428842783, 0.08467231690883636, 0.11269158124923706, 0.01846788264811039, 0.03856261819601059, 0.011051514185965061, 0.06964196264743805, 0.09237806499004364, 0.022560445591807365, 0.031314946711063385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14957918226718903, 0.013048062101006508, 0.03394850343465805, 0.015061764977872372, 0.045098818838596344, 0.08479965478181839, 0.027256982401013374, 0.17206285893917084, 0.01685032993555069, 0.10883241146802902, 0.11793848872184753, 0.008323253132402897, 0.016134316101670265, 0.01772647723555565, 0.02617342211306095, 0.05189086124300957, 0.008976074866950512, 0.010605722665786743, 0.07569276541471481, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2303972989320755, 0.024296818301081657, 0.026559978723526, 0.039246175438165665, 0.04230225831270218, 0.049243416637182236, 0.007979442365467548, 0.0732208788394928, 0.034551844000816345, 0.06601923704147339, 0.03830168768763542, 0.03672322630882263, 0.0241401270031929, 0.037105266004800797, 0.028557125478982925, 0.0544639453291893, 0.03901505470275879, 0.015944398939609528, 0.046100083738565445, 0.08583169430494308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.056916654109954834, 0.006225023418664932, 0.0117544149979949, 0.003549676388502121, 0.07110723853111267, 0.0800657570362091, 0.022162364795804024, 0.11016806960105896, 0.0010484926169738173, 0.08122202754020691, 0.026672042906284332, 0.002196080517023802, 0.03059852309525013, 0.0012014046078547835, 0.014937764033675194, 0.14736880362033844, 0.002626748289912939, 0.03338917717337608, 0.1104901060461998, 0.18504445254802704, 0.0012552260886877775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09241704642772675, 0.026059623807668686, 0.02483060583472252, 0.014753975905478, 0.07309960573911667, 0.041600827127695084, 0.028182964771986008, 0.10522367805242538, 0.010200564749538898, 0.02671687863767147, 0.03863626345992088, 0.008342119865119457, 0.03416535258293152, 0.011011878028512001, 0.02702196314930916, 0.10600949078798294, 0.00949846487492323, 0.016123095527291298, 0.06257016211748123, 0.19003154337406158, 0.010448911227285862, 0.043055012822151184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06173652410507202, 0.007029627915471792, 0.019486606121063232, 0.010366823524236679, 0.04601287841796875, 0.07236862927675247, 0.022752372547984123, 0.08978492021560669, 0.005041902419179678, 0.07019013911485672, 0.07947879284620285, 0.00647539459168911, 0.038350652903318405, 0.005680918227881193, 0.015840988606214523, 0.053441066294908524, 0.007524982560425997, 0.018862156197428703, 0.09784606844186783, 0.19087877869606018, 0.0069852969609200954, 0.027727821841835976, 0.04613659158349037, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0434984415769577, 0.006029139738529921, 0.0162718053907156, 0.0049628885462880135, 0.0923277884721756, 0.056436073035001755, 0.02427319996058941, 0.10004423558712006, 0.0013475855812430382, 0.04695267602801323, 0.04337000101804733, 0.002612095093354583, 0.02598002552986145, 0.0015367756132036448, 0.013811740092933178, 0.12162510305643082, 0.0030840537510812283, 0.014781148172914982, 0.08252861350774765, 0.20843428373336792, 0.0021058102138340473, 0.033566415309906006, 0.04992131143808365, 0.00449881749227643, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05493931099772453, 0.005164694041013718, 0.0132825318723917, 0.006816811393946409, 0.08581957221031189, 0.042583730071783066, 0.010111802257597446, 0.10901322215795517, 0.0030670426785945892, 0.041951488703489304, 0.03668753802776337, 0.003877603216096759, 0.036396294832229614, 0.0036428289022296667, 0.01571308635175228, 0.04514279589056969, 0.0047706314362585545, 0.010733419097959995, 0.12949077785015106, 0.1834336817264557, 0.005763913504779339, 0.06008809059858322, 0.06420368701219559, 0.00847991369664669, 0.018825508654117584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1161927580833435, 0.024008192121982574, 0.017500849440693855, 0.022795286029577255, 0.0502765066921711, 0.03202547878026962, 0.020647749304771423, 0.03974740579724312, 0.023735979571938515, 0.02667790651321411, 0.01885642111301422, 0.028171353042125702, 0.03460881486535072, 0.026643721386790276, 0.022768070921301842, 0.023577362298965454, 0.031199203804135323, 0.022620445117354393, 0.09706808626651764, 0.06436187028884888, 0.03251432627439499, 0.04557201266288757, 0.04268260672688484, 0.02825286239385605, 0.025809558108448982, 0.08168511837720871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11220823973417282, 0.005275932606309652, 0.01370136346668005, 0.006475638598203659, 0.05825747922062874, 0.05591835081577301, 0.013027261011302471, 0.10451262444257736, 0.004013674333691597, 0.04011368378996849, 0.03787229582667351, 0.0031745275482535362, 0.012129993177950382, 0.004096257966011763, 0.007334521040320396, 0.017732826992869377, 0.0034752318169921637, 0.0030595543794333935, 0.0948338732123375, 0.20002640783786774, 0.005673964973539114, 0.016374558210372925, 0.01723022758960724, 0.004368433263152838, 0.009308066219091415, 0.09713462740182877, 0.052670374512672424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06115270033478737, 0.004939327947795391, 0.009762824513018131, 0.005227167159318924, 0.036462727934122086, 0.03137052804231644, 0.008218892849981785, 0.11535760015249252, 0.003272868227213621, 0.03824919834733009, 0.03337175026535988, 0.0021793791092932224, 0.007692953571677208, 0.003454809309914708, 0.009085441939532757, 0.02790052257478237, 0.0023665917105972767, 0.003948243334889412, 0.0407714881002903, 0.27574682235717773, 0.0035466663539409637, 0.012455103918910027, 0.03261314332485199, 0.0032098146621137857, 0.00360309355892241, 0.10009616613388062, 0.08892867714166641, 0.035015422850847244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11957036703824997, 0.008050518110394478, 0.013377298600971699, 0.007089263293892145, 0.025275401771068573, 0.05149080604314804, 0.006585441064089537, 0.06165985390543938, 0.005620484706014395, 0.0556148886680603, 0.0272917989641428, 0.0042864857241511345, 0.00769842742010951, 0.005996250547468662, 0.0079420180991292, 0.028790518641471863, 0.004870964214205742, 0.004313758574426174, 0.02622806280851364, 0.15385545790195465, 0.010709966532886028, 0.009564647451043129, 0.029178395867347717, 0.00532927829772234, 0.008051515556871891, 0.07812707871198654, 0.10984010249376297, 0.029521040618419647, 0.09406988322734833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025880740955471992, 0.0032868722919374704, 0.009190610609948635, 0.0022713204380124807, 0.042062561959028244, 0.0403556190431118, 0.015107071958482265, 0.04801337793469429, 0.0008096094243228436, 0.03906422108411789, 0.026566797867417336, 0.0015204474329948425, 0.02122015506029129, 0.0009539543534629047, 0.007810368202626705, 0.033135153353214264, 0.0018792495829984546, 0.010119687765836716, 0.06751000881195068, 0.12262904644012451, 0.0015832217177376151, 0.02216803841292858, 0.03078523464500904, 0.004318804480135441, 0.01872900500893593, 0.1447751373052597, 0.06957437843084335, 0.11388751119375229, 0.07182329148054123, 0.002968477550894022, 0.0, 0.0, 0.0, 0.0, 0.0], [0.046125102788209915, 0.004929375369101763, 0.011905021034181118, 0.005939910188317299, 0.05086232349276543, 0.03915585204958916, 0.011702250689268112, 0.07777240127325058, 0.0027224940713495016, 0.029330717399716377, 0.035436615347862244, 0.002508658915758133, 0.011883246712386608, 0.0029638586565852165, 0.008878663182258606, 0.018936676904559135, 0.002804588293656707, 0.004066930618137121, 0.06637166440486908, 0.16173596680164337, 0.004074744880199432, 0.017417898401618004, 0.04845814034342766, 0.005489852279424667, 0.01446738000959158, 0.08884270489215851, 0.05744141712784767, 0.04815758392214775, 0.09182099252939224, 0.004751020576804876, 0.023045994341373444, 0.0, 0.0, 0.0, 0.0], [0.028616543859243393, 0.0035397156607359648, 0.012825744226574898, 0.003731101518496871, 0.022132838144898415, 0.026339100673794746, 0.015483646653592587, 0.04692447930574417, 0.0016770181246101856, 0.05343090742826462, 0.03818728029727936, 0.002529490040615201, 0.0276822317391634, 0.0019447184167802334, 0.010427960194647312, 0.020306406542658806, 0.003083115443587303, 0.008337561972439289, 0.06147443875670433, 0.05695469677448273, 0.0030909168999642134, 0.019787292927503586, 0.037704240530729294, 0.004031909629702568, 0.020770886912941933, 0.12126165628433228, 0.08733711391687393, 0.07036236673593521, 0.09933117032051086, 0.005798676051199436, 0.06381496787071228, 0.02107991836965084, 0.0, 0.0, 0.0], [0.022769231349229813, 0.0023638159036636353, 0.0069536129012703896, 0.0009745154529809952, 0.0334312804043293, 0.03096313215792179, 0.012881088070571423, 0.0763968825340271, 0.0002621037419885397, 0.03044992871582508, 0.03674258291721344, 0.0005670599639415741, 0.014569034799933434, 0.0003055332927033305, 0.00594836100935936, 0.02249256521463394, 0.0007025566883385181, 0.004866450559347868, 0.060261815786361694, 0.1558590680360794, 0.0005001772078685462, 0.019988080486655235, 0.03086850605905056, 0.0031281497795134783, 0.01215117797255516, 0.11994652450084686, 0.07597392052412033, 0.09628818184137344, 0.07584254443645477, 0.0010643767891451716, 0.03271331265568733, 0.011111115105450153, 0.0006632998702116311, 0.0, 0.0], [0.06755810230970383, 0.003352794563397765, 0.008972210809588432, 0.0034025455825030804, 0.05607305467128754, 0.03040470741689205, 0.013628309592604637, 0.07952425628900528, 0.002588937757536769, 0.034729402512311935, 0.015315976925194263, 0.002527096541598439, 0.007685468997806311, 0.0026928242295980453, 0.007112996652722359, 0.02612845040857792, 0.0027733694296330214, 0.007069502025842667, 0.05076204985380173, 0.1759389191865921, 0.003935437649488449, 0.010542861185967922, 0.012697339989244938, 0.0028314394876360893, 0.004983489401638508, 0.05610368028283119, 0.10278663784265518, 0.0786440521478653, 0.06361379474401474, 0.004290643613785505, 0.012449046596884727, 0.007846901193261147, 0.0035741610918194056, 0.03745955228805542, 0.0], [0.05889429152011871, 0.00483429292216897, 0.008816237561404705, 0.004917601589113474, 0.05724450200796127, 0.04719965532422066, 0.010384357534348965, 0.043736834079027176, 0.003253217088058591, 0.02700052410364151, 0.015385990031063557, 0.005444503389298916, 0.018304407596588135, 0.003610059153288603, 0.011856135912239552, 0.07255371659994125, 0.006018081679940224, 0.006411908660084009, 0.055861566215753555, 0.08374673873186111, 0.00397366750985384, 0.018590599298477173, 0.01944512315094471, 0.003880673786625266, 0.008932657539844513, 0.12242711335420609, 0.0409863144159317, 0.0742977038025856, 0.057745564728975296, 0.006318635307252407, 0.01308411918580532, 0.023065811023116112, 0.005796522833406925, 0.04094136133790016, 0.01503958459943533]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9780336022377014, 0.021966341882944107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5068985819816589, 0.42791488766670227, 0.06518654525279999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34595057368278503, 0.23385100066661835, 0.1913881003856659, 0.2288103699684143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2785968780517578, 0.17525744438171387, 0.11037097871303558, 0.2518094778060913, 0.18396523594856262, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2080419808626175, 0.08827144652605057, 0.061608098447322845, 0.2584841549396515, 0.2705698609352112, 0.11302442103624344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16325624287128448, 0.12141189724206924, 0.11990708857774734, 0.1616644561290741, 0.10774069279432297, 0.29750365018844604, 0.028515929356217384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12280930578708649, 0.03978987783193588, 0.0451454296708107, 0.13578490912914276, 0.09269551932811737, 0.11808707565069199, 0.33698490262031555, 0.10870299488306046, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0785447359085083, 0.035703908652067184, 0.02910533733665943, 0.05200903117656708, 0.10322193056344986, 0.06222517415881157, 0.06801241636276245, 0.17029158771038055, 0.4008859097957611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0855533704161644, 0.04508212208747864, 0.020755313336849213, 0.05748791620135307, 0.0585336834192276, 0.03812538459897041, 0.03164030611515045, 0.14470815658569336, 0.39396733045578003, 0.12414640933275223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03400759398937225, 0.005801301449537277, 0.004264355171471834, 0.014554576016962528, 0.0020581241697072983, 0.01005222462117672, 0.015462437644600868, 0.014919922687113285, 0.07456014305353165, 0.8029415607452393, 0.021377811208367348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03658133000135422, 0.008552642539143562, 0.009085921570658684, 0.01071858685463667, 0.031510528177022934, 0.07786066830158234, 0.02809952199459076, 0.0520339198410511, 0.09175647050142288, 0.2498079538345337, 0.22384558618068695, 0.18014685809612274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03899507224559784, 0.013953070156276226, 0.02715037576854229, 0.015978634357452393, 0.006068874150514603, 0.01533289160579443, 0.007358457427471876, 0.00814359076321125, 0.09236102551221848, 0.09582377225160599, 0.39708977937698364, 0.22508250176906586, 0.05666198208928108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029417643323540688, 0.006853986531496048, 0.005433523561805487, 0.008306879550218582, 0.015738286077976227, 0.0087088942527771, 0.008349091745913029, 0.023920070379972458, 0.04694683104753494, 0.04814503341913223, 0.0930999144911766, 0.15290869772434235, 0.148541659116745, 0.40362948179244995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03712830692529678, 0.007584473583847284, 0.003545144572854042, 0.008117970079183578, 0.0188341923058033, 0.0059049720875918865, 0.009632604196667671, 0.011076660826802254, 0.04249940067529678, 0.015083986334502697, 0.01984347403049469, 0.11177276074886322, 0.12816858291625977, 0.33317863941192627, 0.24762879312038422, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024791505187749863, 0.0022572411689907312, 0.0019112293375656009, 0.0031496440060436726, 0.0017746686935424805, 0.0030808576848357916, 0.01988072134554386, 0.006427102256566286, 0.015317469835281372, 0.003226605709642172, 0.02029608190059662, 0.05772734433412552, 0.02255523018538952, 0.08885953575372696, 0.7141122817993164, 0.014632451348006725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019352801144123077, 0.002735720481723547, 0.002700645010918379, 0.0028163958340883255, 0.0073006064631044865, 0.016268694773316383, 0.005134703125804663, 0.010258643887937069, 0.01379147358238697, 0.03380443900823593, 0.033944837749004364, 0.02411041408777237, 0.05347483977675438, 0.09691011160612106, 0.27618837356567383, 0.22190365195274353, 0.1793036311864853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016778303310275078, 0.0013836672296747565, 0.0012504433980211616, 0.0019532626029103994, 0.0012283105170354247, 0.003427049843594432, 0.001771017094142735, 0.002587684663012624, 0.009956522844731808, 0.007537419442087412, 0.004963125102221966, 0.02366887405514717, 0.017456650733947754, 0.06967750191688538, 0.2612769901752472, 0.2408241480588913, 0.17677903175354004, 0.157479926943779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05475039780139923, 0.009201946668326855, 0.003783300518989563, 0.00689188065007329, 0.007006871048361063, 0.0052677784115076065, 0.0019135880284011364, 0.0066490089520812035, 0.02249075472354889, 0.007203701883554459, 0.03985988348722458, 0.02630697190761566, 0.035983867943286896, 0.10654623806476593, 0.14742796123027802, 0.029531963169574738, 0.14834152162075043, 0.23425278067588806, 0.10658960789442062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08004868775606155, 0.003562749596312642, 0.0033941466826945543, 0.011285568587481976, 0.01220858097076416, 0.0019434965215623379, 0.003920830320566893, 0.024116622284054756, 0.023349955677986145, 0.008975900709629059, 0.005343950819224119, 0.02533606067299843, 0.01387019269168377, 0.10103654861450195, 0.03973817825317383, 0.08061382174491882, 0.12086469680070877, 0.12294691801071167, 0.14132516086101532, 0.17611795663833618, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01305336132645607, 0.0019795650150626898, 0.0016182122053578496, 0.0014078525127843022, 0.0014868254074826837, 0.0013099159114062786, 0.0016642971895635128, 0.0025665161665529013, 0.003062670351937413, 0.010340578854084015, 0.007755250670015812, 0.008929400704801083, 0.008869537152349949, 0.017165113240480423, 0.07265795767307281, 0.08664470911026001, 0.06223943084478378, 0.16528479754924774, 0.07255077362060547, 0.09155546873807907, 0.36785778403282166, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012316017411649227, 0.0011592359514907002, 0.0007622389821335673, 0.001950751175172627, 0.0012718522921204567, 0.0006892273668199778, 0.0005458985106088221, 0.0026030000299215317, 0.003917664755135775, 0.0005409363657236099, 0.0012741924729198217, 0.006503167096525431, 0.005551586858928204, 0.01797345094382763, 0.013353327289223671, 0.03805124759674072, 0.04303396865725517, 0.039586566388607025, 0.022300681099295616, 0.03898366913199425, 0.5949540138244629, 0.15267719328403473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013724957592785358, 0.001612574909813702, 0.00032898675999604166, 0.0010084318928420544, 0.0011758042965084314, 0.000725927238818258, 0.0005918752285651863, 0.0009615588933229446, 0.0031186197884380817, 0.005970009136945009, 0.003033465938642621, 0.003344498574733734, 0.008407535031437874, 0.013658502139151096, 0.005607031285762787, 0.005321723408997059, 0.019289910793304443, 0.029109666123986244, 0.013599621132016182, 0.031337786465883255, 0.25137248635292053, 0.5305222272872925, 0.05617687478661537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01600237935781479, 0.0009560453472658992, 0.0005680458270944655, 0.001554973074235022, 0.0015755745116621256, 0.0006219735369086266, 0.0011257643345743418, 0.0014368743868544698, 0.0023100462276488543, 0.0009028317290358245, 0.001392145873978734, 0.0036725937388837337, 0.00363227934576571, 0.009217390790581703, 0.008623875677585602, 0.027025746181607246, 0.021376444026827812, 0.03330114483833313, 0.03885401040315628, 0.039058420807123184, 0.26596635580062866, 0.19372603297233582, 0.09792883694171906, 0.22917026281356812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009987294673919678, 0.0009651763830333948, 0.0006041579181328416, 0.0009222126100212336, 0.0008805808611214161, 0.0005974342348054051, 0.00021149202075321227, 0.000645568419713527, 0.001241767662577331, 0.0006859704153612256, 0.0007031510467641056, 0.0014577426481992006, 0.0018487706547603011, 0.005077200476080179, 0.0019275667145848274, 0.012413390912115574, 0.008568295277655125, 0.012073684483766556, 0.021936645731329918, 0.02919415384531021, 0.14272746443748474, 0.09834039211273193, 0.1184767559170723, 0.31631967425346375, 0.21219348907470703, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016860902309417725, 0.0019703286234289408, 0.000885836489032954, 0.001765640452504158, 0.0023928331211209297, 0.0005271153058856726, 0.0003617893671616912, 0.0006361056584864855, 0.0022411299869418144, 0.0008515875088050961, 0.00038157880771905184, 0.0022748277988284826, 0.0018798470264300704, 0.007292226422578096, 0.0021466766484081745, 0.0025263053830713034, 0.010355687700212002, 0.011969336308538914, 0.0065909153781831264, 0.012827490456402302, 0.12130486965179443, 0.06624644249677658, 0.14612402021884918, 0.2828073501586914, 0.2470329999923706, 0.04974617436528206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026405036449432373, 0.0014230996603146195, 0.001623444608412683, 0.002576401922851801, 0.00268970406614244, 0.0012257524067535996, 0.001089877332560718, 0.0009538462036289275, 0.0019223529379814863, 0.002411522436887026, 0.0024579439777880907, 0.0014354187296703458, 0.005378496367484331, 0.00473234336823225, 0.001939116045832634, 0.007957515306770802, 0.0060868836008012295, 0.012657452374696732, 0.011602509766817093, 0.02909662388265133, 0.08598875254392624, 0.07665884494781494, 0.0362401120364666, 0.13133350014686584, 0.19490280747413635, 0.21766334772109985, 0.1315472275018692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.023896105587482452, 0.0020675037521868944, 0.002509376034140587, 0.0018511980306357145, 0.0031609658617526293, 0.0009005634346976876, 0.0002685424988158047, 0.0005213552503846586, 0.0017872133757919073, 0.0019308945629745722, 0.0010158239165320992, 0.0010442663915455341, 0.0015677042538300157, 0.00406009703874588, 0.0008207389619201422, 0.003358300542458892, 0.004117118194699287, 0.007223028223961592, 0.014547298662364483, 0.046351585537195206, 0.05601862445473671, 0.03840019553899765, 0.04160996153950691, 0.10494542121887207, 0.15788216888904572, 0.12118807435035706, 0.19090253114700317, 0.16605335474014282, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04075779393315315, 0.003958363551646471, 0.0056980932131409645, 0.0039579859003424644, 0.0014047803124412894, 0.000327694317093119, 0.0006401935243047774, 0.0012045818148180842, 0.00223855790682137, 0.0007448497344739735, 0.0038365772925317287, 0.001620680559426546, 0.0010148307774215937, 0.004261186812072992, 0.0009652952430769801, 0.0003954324347432703, 0.005401067901402712, 0.007263402920216322, 0.005766802933067083, 0.029991842806339264, 0.041736576706171036, 0.017527645453810692, 0.02515505440533161, 0.07565261423587799, 0.24542635679244995, 0.06668499857187271, 0.2648317813873291, 0.055024098604917526, 0.08651081472635269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011784786358475685, 0.0013947549741715193, 0.000951564812567085, 0.0008953192736953497, 0.0010372701799497008, 0.0004972639726474881, 0.0002528381301090121, 0.00043175648897886276, 0.0005345686222426593, 0.00028229193412698805, 0.00042747301631607115, 0.0005479568499140441, 0.0008038743399083614, 0.001103747170418501, 0.0010882861679419875, 0.0026353751309216022, 0.00200331280939281, 0.00293945474550128, 0.005114199593663216, 0.009162316098809242, 0.0202364232391119, 0.01439724862575531, 0.014386605471372604, 0.052873123437166214, 0.04425809159874916, 0.07174722105264664, 0.08077167719602585, 0.11779716610908508, 0.1448613554239273, 0.3947826325893402, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012992875650525093, 0.001667613978497684, 0.0010021071648225188, 0.0011761238565668464, 0.0007638345705345273, 0.00040058320155367255, 0.000128492436488159, 0.00010518707858864218, 0.000560643442440778, 0.00014079399988986552, 0.0001220755948452279, 0.0003985989897046238, 0.00022988316777627915, 0.0011077822418883443, 0.0003631032886914909, 0.000889180286321789, 0.001440244959667325, 0.001452022697776556, 0.0026305674109607935, 0.0031673861667513847, 0.01722467690706253, 0.010722354054450989, 0.005023000296205282, 0.04577849805355072, 0.04751966521143913, 0.02706717513501644, 0.05216860771179199, 0.05500796437263489, 0.11481019109487534, 0.44568800926208496, 0.1482507437467575, 0.0, 0.0, 0.0, 0.0], [0.011720022186636925, 0.0009638680494390428, 0.0016792787937447429, 0.0009598786127753556, 0.0011835345067083836, 0.0003587341634556651, 0.00013125198893249035, 0.0002098587283398956, 0.0003518580342642963, 0.00011673847620841116, 0.0003326717996969819, 0.00020899789524264634, 0.0001630403712624684, 0.0005591601366177201, 0.0001787790097296238, 0.0005847538122907281, 0.0006520408787764609, 0.0008100892300717533, 0.0008232026011683047, 0.006545150186866522, 0.007790669798851013, 0.006622507236897945, 0.0050529721193015575, 0.014489841647446156, 0.024942079558968544, 0.01901034265756607, 0.02852551080286503, 0.036787744611501694, 0.14266972243785858, 0.23489882051944733, 0.3008541166782379, 0.14982277154922485, 0.0, 0.0, 0.0], [0.01146328542381525, 0.0009014826500788331, 0.0005477449740283191, 0.0005869870074093342, 0.0005616630078293383, 0.0002343479573028162, 0.00013944689999334514, 0.00019926823733840138, 0.00031403094180859625, 0.00012514658737927675, 0.00021479520364664495, 0.0002481348055880517, 0.00022906191588845104, 0.0005020775133743882, 0.00045190195669420063, 0.0006676741177216172, 0.0007638586102984846, 0.0009467181516811252, 0.0010094373719766736, 0.003719577332958579, 0.007444899994879961, 0.0045005581341683865, 0.0018344351556152105, 0.01297363918274641, 0.015522489324212074, 0.02183825895190239, 0.016228970140218735, 0.024697422981262207, 0.0380532369017601, 0.16302339732646942, 0.11826055496931076, 0.2288476973772049, 0.32294777035713196, 0.0, 0.0], [0.009539732709527016, 0.001424328307621181, 0.0009944570483639836, 0.0009655573521740735, 0.0007854426512494683, 0.00030160637106746435, 0.00011159563291585073, 0.0008093689102679491, 0.0004005462978966534, 8.517077367287129e-05, 0.0006307568401098251, 0.00020861598022747785, 0.0002525565796531737, 0.000545184186194092, 0.00024275555915664881, 0.0005828303401358426, 0.0005503920838236809, 0.001054858323186636, 0.0010979119688272476, 0.004033547826111317, 0.005151547025889158, 0.007251260802149773, 0.003988183103501797, 0.012260396033525467, 0.013561537489295006, 0.038286544382572174, 0.06675272434949875, 0.013111523352563381, 0.10093269497156143, 0.1317911297082901, 0.054323047399520874, 0.1525149792432785, 0.3083246052265167, 0.0671326294541359, 0.0], [0.009234574623405933, 0.0018696909537538886, 0.0015434958040714264, 0.001287891180254519, 0.0009349422180093825, 0.00028256085352040827, 0.0004494279273785651, 0.0005594989634118974, 0.0003277681826148182, 7.203830318758264e-05, 0.0001065790856955573, 0.0002636241842992604, 0.0003654726315289736, 0.0003748317249119282, 0.00031175350886769593, 0.0008969134069047868, 0.0006347450544126332, 0.0008650035015307367, 0.0008020042441785336, 0.0006307902513071895, 0.0032187809702008963, 0.0038458353374153376, 0.003000437282025814, 0.007814152166247368, 0.010107208043336868, 0.016721565276384354, 0.007672088220715523, 0.010031227022409439, 0.005356381647288799, 0.07757057994604111, 0.03774447366595268, 0.138091042637825, 0.1956760734319687, 0.030743561685085297, 0.43059301376342773]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8970723748207092, 0.10292765498161316, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7731762528419495, 0.17108601331710815, 0.05573772266507149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21909849345684052, 0.09592848271131516, 0.1539974808692932, 0.5309755206108093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4932920038700104, 0.12421075254678726, 0.08378947526216507, 0.2104450911283493, 0.08826273679733276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4792534112930298, 0.11483937501907349, 0.058252837508916855, 0.12140913307666779, 0.19296902418136597, 0.033276282250881195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33760708570480347, 0.13038291037082672, 0.12365779280662537, 0.16848315298557281, 0.03948560729622841, 0.15522727370262146, 0.045156169682741165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3124314546585083, 0.1033550575375557, 0.07322119921445847, 0.13077442348003387, 0.08650774508714676, 0.2037174254655838, 0.04714132100343704, 0.04285133630037308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10719950497150421, 0.03256478160619736, 0.04615394398570061, 0.12522774934768677, 0.011105231009423733, 0.03433005139231682, 0.007858380675315857, 0.011366576887667179, 0.6241937875747681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30288904905319214, 0.07804970443248749, 0.059376489371061325, 0.09426911175251007, 0.17377153038978577, 0.03861627355217934, 0.048025283962488174, 0.039512552320957184, 0.13237620890140533, 0.03311379998922348, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13027672469615936, 0.042134858667850494, 0.07258210331201553, 0.10922865569591522, 0.036304350942373276, 0.191125750541687, 0.03369797766208649, 0.05715860798954964, 0.11187218874692917, 0.16414132714271545, 0.051477424800395966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0946442186832428, 0.029253453016281128, 0.03811940923333168, 0.14989571273326874, 0.020670879632234573, 0.07631714642047882, 0.00894747395068407, 0.020045079290866852, 0.3057856857776642, 0.0475209578871727, 0.010440830141305923, 0.19835913181304932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14440803229808807, 0.06329526007175446, 0.07617759704589844, 0.07194554805755615, 0.03394106775522232, 0.08442071825265884, 0.03594021126627922, 0.07685542106628418, 0.11588277667760849, 0.05951952561736107, 0.06183496117591858, 0.14841707050800323, 0.027361812070012093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0414787232875824, 0.011494413949549198, 0.01764351688325405, 0.04599722847342491, 0.004085009917616844, 0.013701112940907478, 0.0028709033504128456, 0.004510779865086079, 0.24164846539497375, 0.00972951203584671, 0.0026167333126068115, 0.2641770541667938, 0.008053773082792759, 0.3319927453994751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15155857801437378, 0.0377250611782074, 0.02733064629137516, 0.06052475422620773, 0.030143294483423233, 0.0280348788946867, 0.013341411016881466, 0.022503050044178963, 0.11653435230255127, 0.05189971998333931, 0.010558661073446274, 0.10229875892400742, 0.015167283825576305, 0.14137376844882965, 0.19100576639175415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2839045524597168, 0.06502401828765869, 0.03238334879279137, 0.029591107740998268, 0.0424320213496685, 0.02846977300941944, 0.041533131152391434, 0.08465307205915451, 0.043854981660842896, 0.027530398219823837, 0.0921814888715744, 0.03751114010810852, 0.04891902953386307, 0.04984968155622482, 0.07913839817047119, 0.013023801147937775, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048857610672712326, 0.01400737650692463, 0.01954261027276516, 0.07337553054094315, 0.010089144110679626, 0.03972570598125458, 0.004310052376240492, 0.01059033814817667, 0.15303604304790497, 0.026499049738049507, 0.005417251959443092, 0.096476249396801, 0.012806721031665802, 0.204786479473114, 0.14743390679359436, 0.009689195081591606, 0.1233566626906395, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05943122133612633, 0.0259512010961771, 0.035473886877298355, 0.03907974436879158, 0.018049322068691254, 0.02308725006878376, 0.010503753088414669, 0.030069561675190926, 0.09918283671140671, 0.03614407777786255, 0.018410028889775276, 0.11741484701633453, 0.017167579382658005, 0.12769995629787445, 0.08459018915891647, 0.03790272772312164, 0.145772323012352, 0.07406947761774063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.272489070892334, 0.045022737234830856, 0.04612237215042114, 0.042051978409290314, 0.03813564404845238, 0.054544299840927124, 0.025706561282277107, 0.019254159182310104, 0.04536459222435951, 0.05106878653168678, 0.021479343995451927, 0.05142935737967491, 0.035683102905750275, 0.05110248923301697, 0.04221019521355629, 0.03813278302550316, 0.057898201048374176, 0.023540079593658447, 0.038764264434576035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.239812433719635, 0.03723884001374245, 0.046413224190473557, 0.018074778839945793, 0.02860945276916027, 0.031563643366098404, 0.023263651877641678, 0.053141165524721146, 0.036729808896780014, 0.04436156898736954, 0.014090009033679962, 0.04079657047986984, 0.013384056277573109, 0.04018275439739227, 0.02512497268617153, 0.022283174097537994, 0.04457441344857216, 0.0263572558760643, 0.01850212551653385, 0.19549617171287537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03447256609797478, 0.0070497882552444935, 0.008516231551766396, 0.019823284819722176, 0.0020061929244548082, 0.00873848982155323, 0.001380532281473279, 0.002584987785667181, 0.129638671875, 0.0049805231392383575, 0.001454295590519905, 0.09793516248464584, 0.004242659546434879, 0.17474927008152008, 0.020575344562530518, 0.002921729814261198, 0.1251920908689499, 0.01766674779355526, 0.008172444067895412, 0.006463976576924324, 0.3214350640773773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07532121986150742, 0.017385119572281837, 0.02649959735572338, 0.038201119750738144, 0.01346430741250515, 0.017004938796162605, 0.005682718008756638, 0.00816139206290245, 0.0879102423787117, 0.0156520027667284, 0.00462237698957324, 0.06870011985301971, 0.017068391665816307, 0.11098405718803406, 0.08843356370925903, 0.01554049551486969, 0.08290650695562363, 0.03445708379149437, 0.0349029004573822, 0.02266903594136238, 0.1672758311033249, 0.047156915068626404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11039688438177109, 0.017618605867028236, 0.012073223479092121, 0.07903023809194565, 0.04707180708646774, 0.02839348278939724, 0.010853302665054798, 0.03898294270038605, 0.04254176467657089, 0.053135763853788376, 0.010616577230393887, 0.04066743329167366, 0.016578679904341698, 0.050442542880773544, 0.04148310422897339, 0.011694183573126793, 0.048943910747766495, 0.04587530717253685, 0.06803461164236069, 0.03145821392536163, 0.0737365186214447, 0.09332362562417984, 0.027047278359532356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.050105899572372437, 0.011403637938201427, 0.01897999458014965, 0.048291102051734924, 0.005478161387145519, 0.027938107028603554, 0.003475341945886612, 0.009667652659118176, 0.08883963525295258, 0.021459804847836494, 0.009184244088828564, 0.06738952547311783, 0.00629377830773592, 0.11730515956878662, 0.05559385195374489, 0.023259565234184265, 0.08538824319839478, 0.03017236478626728, 0.01855376921594143, 0.0497271791100502, 0.1386995017528534, 0.03593091294169426, 0.029570575803518295, 0.047291941940784454, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.033650632947683334, 0.03973434865474701, 0.013943269848823547, 0.022155024111270905, 0.00737410131841898, 0.01253434270620346, 0.003937930800020695, 0.005588038358837366, 0.052764154970645905, 0.011353476904332638, 0.0029761551413685083, 0.06122001260519028, 0.007114534266293049, 0.06609286367893219, 0.018457181751728058, 0.004707181826233864, 0.0778060182929039, 0.01593407429754734, 0.016269709914922714, 0.027332937344908714, 0.08945079892873764, 0.02828321047127247, 0.013428343459963799, 0.24125005304813385, 0.12664161622524261, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10162997245788574, 0.0481734462082386, 0.022741522639989853, 0.017647167667746544, 0.016357652842998505, 0.014718170277774334, 0.020238902419805527, 0.03009830415248871, 0.03836439922451973, 0.025297483429312706, 0.03959343954920769, 0.04179812967777252, 0.01849495992064476, 0.043456632643938065, 0.02387693151831627, 0.013411911204457283, 0.04804752394556999, 0.021995291113853455, 0.030744776129722595, 0.05168473348021507, 0.057864848524332047, 0.04216013103723526, 0.05038999021053314, 0.08024893701076508, 0.07608191668987274, 0.024882828816771507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06603525578975677, 0.020660119131207466, 0.02168169617652893, 0.03408760577440262, 0.015279390849173069, 0.01844199188053608, 0.010789590887725353, 0.05595837160944939, 0.035654861479997635, 0.021738866344094276, 0.02566494606435299, 0.039465565234422684, 0.01909186691045761, 0.04260498285293579, 0.0451403371989727, 0.012913594953715801, 0.047355785965919495, 0.025561854243278503, 0.035244137048721313, 0.09746365249156952, 0.05611315369606018, 0.035938482731580734, 0.032566994428634644, 0.0430198572576046, 0.04697675630450249, 0.03246127441525459, 0.062089040875434875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10541100800037384, 0.016973109915852547, 0.02034102752804756, 0.03266655653715134, 0.021851178258657455, 0.031789932399988174, 0.005571208894252777, 0.024194516241550446, 0.01674046739935875, 0.016082564368844032, 0.013484918512403965, 0.02279038354754448, 0.020844893530011177, 0.019816424697637558, 0.007411996368318796, 0.013035090640187263, 0.02698247693479061, 0.010132258757948875, 0.017667710781097412, 0.29726240038871765, 0.023457149043679237, 0.03235581889748573, 0.03224533796310425, 0.01998012699186802, 0.05017194151878357, 0.048278938978910446, 0.033088210970163345, 0.019372418522834778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1147821694612503, 0.02845187857747078, 0.030158082023262978, 0.029890695586800575, 0.015577692538499832, 0.04523628205060959, 0.0081566721200943, 0.04677767679095268, 0.020574571564793587, 0.018089190125465393, 0.016638459637761116, 0.024351509287953377, 0.014281010255217552, 0.022870568558573723, 0.024558424949645996, 0.021522244438529015, 0.02774011343717575, 0.01226317323744297, 0.016789689660072327, 0.030601773411035538, 0.03310445696115494, 0.04230615124106407, 0.05013416334986687, 0.0398956798017025, 0.02547144703567028, 0.03835652768611908, 0.1483658105134964, 0.04062194377183914, 0.012431968003511429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010402968153357506, 0.003988315816968679, 0.007536559831351042, 0.023714061826467514, 0.001574700465425849, 0.004556502215564251, 0.0011461445828899741, 0.0020206545013934374, 0.08388330787420273, 0.006093550939112902, 0.001224364503286779, 0.08011975139379501, 0.0032829283736646175, 0.1148514598608017, 0.020138537511229515, 0.003874026006087661, 0.1035565659403801, 0.016239913180470467, 0.006219515576958656, 0.011158781126141548, 0.12897233664989471, 0.016916092485189438, 0.008813071064651012, 0.02879595011472702, 0.060593508183956146, 0.005618593655526638, 0.01689356006681919, 0.008791645057499409, 0.01702239364385605, 0.20200031995773315, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05472036823630333, 0.015954433009028435, 0.012098252773284912, 0.022833745926618576, 0.018985209986567497, 0.02878388576209545, 0.008076782338321209, 0.00837206281721592, 0.039564043283462524, 0.012315311469137669, 0.009588333778083324, 0.023571286350488663, 0.010643107816576958, 0.046638455241918564, 0.014515889808535576, 0.012394601479172707, 0.027597345411777496, 0.021691447123885155, 0.02018054947257042, 0.01823921501636505, 0.05496657267212868, 0.037117861211299896, 0.024244992062449455, 0.03499603644013405, 0.1494767814874649, 0.029019519686698914, 0.043276429176330566, 0.01586642861366272, 0.04511541500687599, 0.11428384482860565, 0.024871760979294777, 0.0, 0.0, 0.0, 0.0], [0.028266312554478645, 0.008342591114342213, 0.00969315692782402, 0.024003302678465843, 0.012406976893544197, 0.009731607511639595, 0.007254773285239935, 0.011378856375813484, 0.045253440737724304, 0.014661090448498726, 0.0047598001547157764, 0.0327930673956871, 0.00959976576268673, 0.056626755744218826, 0.023795727640390396, 0.004614102188497782, 0.039821431040763855, 0.02123899757862091, 0.025286557152867317, 0.1015978753566742, 0.09278314560651779, 0.026123864576220512, 0.015091439709067345, 0.03458566963672638, 0.061821937561035156, 0.013406999409198761, 0.016889795660972595, 0.03089355118572712, 0.02819487266242504, 0.1103137731552124, 0.040569547563791275, 0.03819921985268593, 0.0, 0.0, 0.0], [0.005920093506574631, 0.0026448259595781565, 0.005754890386015177, 0.02199716307222843, 0.0013081274228170514, 0.0057265376672148705, 0.0008704040665179491, 0.0018940423615276814, 0.05295495316386223, 0.00472501153126359, 0.000999945099465549, 0.04342707619071007, 0.0021749832667410374, 0.07363719493150711, 0.017015766352415085, 0.0030869939364492893, 0.057790838181972504, 0.010734479874372482, 0.0034258204977959394, 0.010332699865102768, 0.08509067445993423, 0.012429160065948963, 0.0062302350997924805, 0.02222101017832756, 0.06411110609769821, 0.005053483881056309, 0.018152382224798203, 0.007594150956720114, 0.00678644236177206, 0.16716450452804565, 0.013871803879737854, 0.014755625277757645, 0.25011759996414185, 0.0, 0.0], [0.05958712846040726, 0.014287112280726433, 0.009688673540949821, 0.02847461961209774, 0.02860480733215809, 0.02625933475792408, 0.008819644339382648, 0.022136040031909943, 0.017910216003656387, 0.026397546753287315, 0.017243586480617523, 0.025983817875385284, 0.006316178943961859, 0.020043162629008293, 0.015440615825355053, 0.02594028040766716, 0.03010302595794201, 0.018365345895290375, 0.02313040941953659, 0.02621457912027836, 0.03115726262331009, 0.02898617461323738, 0.02896127849817276, 0.016435232013463974, 0.03480091318488121, 0.03794369101524353, 0.07380679249763489, 0.030772415921092033, 0.028517259284853935, 0.07387096434831619, 0.02458772249519825, 0.03523411974310875, 0.08090808242559433, 0.023072004318237305, 0.0], [0.052589885890483856, 0.008282378315925598, 0.004686589818447828, 0.011556105688214302, 0.0021243582013994455, 0.007376658730208874, 0.0025699096731841564, 0.005167305935174227, 0.06430475413799286, 0.008688683621585369, 0.004349816124886274, 0.05405206233263016, 0.0035673303063958883, 0.08101724088191986, 0.021457016468048096, 0.00414407579228282, 0.06621561199426651, 0.01871693693101406, 0.009488226845860481, 0.006038543302565813, 0.10274305194616318, 0.01456521637737751, 0.009106305427849293, 0.021657666191458702, 0.035247985273599625, 0.004852632526308298, 0.00842215958982706, 0.019589493051171303, 0.011885891668498516, 0.14464659988880157, 0.016607562080025673, 0.0228347759693861, 0.08476629108190536, 0.015126866288483143, 0.051554061472415924]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8803902268409729, 0.1196097582578659, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.800162672996521, 0.14422567188739777, 0.055611640214920044, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6471941471099854, 0.14701780676841736, 0.0793100968003273, 0.12647798657417297, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6291002035140991, 0.1326994001865387, 0.0830739364027977, 0.10306606441736221, 0.05206044018268585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5631014108657837, 0.1237594410777092, 0.11159723252058029, 0.10842733830213547, 0.08343346416950226, 0.00968119502067566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4973389506340027, 0.11400076746940613, 0.07851860672235489, 0.10408835858106613, 0.08229988813400269, 0.087201789021492, 0.03655165061354637, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4618663191795349, 0.10720601677894592, 0.07680260390043259, 0.09525883942842484, 0.11179576814174652, 0.04683659225702286, 0.0632898211479187, 0.03694411367177963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.408801794052124, 0.11223535984754562, 0.06194951385259628, 0.08138209581375122, 0.06888709962368011, 0.04759940505027771, 0.05779567360877991, 0.06300585716962814, 0.09834323078393936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.337785542011261, 0.07768955826759338, 0.061640240252017975, 0.08030419796705246, 0.09243477135896683, 0.12569792568683624, 0.043102774769067764, 0.08006506413221359, 0.08753130584955215, 0.013748610392212868, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40844571590423584, 0.07972615957260132, 0.05943280830979347, 0.07098965346813202, 0.06258382648229599, 0.07298710942268372, 0.05290914699435234, 0.06663116812705994, 0.08486583083868027, 0.03078524023294449, 0.010643370449543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32840877771377563, 0.0812605619430542, 0.052221160382032394, 0.06670200079679489, 0.06221218779683113, 0.04688328877091408, 0.04748225957155228, 0.04943712428212166, 0.08644373714923859, 0.051085103303194046, 0.046604085713624954, 0.08125966042280197, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28456372022628784, 0.07334227114915848, 0.059566255658864975, 0.05995683744549751, 0.06261258572340012, 0.04492250457406044, 0.0535489022731781, 0.055395226925611496, 0.0760505273938179, 0.05439150333404541, 0.05521009489893913, 0.0848141685128212, 0.03562537580728531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2986924648284912, 0.0805349051952362, 0.04630004242062569, 0.058416131883859634, 0.05245250463485718, 0.03589676693081856, 0.0431300513446331, 0.04816412553191185, 0.07179586589336395, 0.03588227927684784, 0.034986354410648346, 0.0663861408829689, 0.047498900443315506, 0.07986355572938919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26184871792793274, 0.06895224750041962, 0.046620942652225494, 0.05860462039709091, 0.046928782016038895, 0.05568014085292816, 0.04915205389261246, 0.041177790611982346, 0.07490761578083038, 0.03198425471782684, 0.03257223963737488, 0.07257073372602463, 0.0373988002538681, 0.08542974293231964, 0.03617140278220177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29417476058006287, 0.05360917001962662, 0.03860875591635704, 0.04952671751379967, 0.04060918465256691, 0.04149327054619789, 0.029716242104768753, 0.04536982253193855, 0.06024932488799095, 0.04159967601299286, 0.06637392938137054, 0.05982464924454689, 0.04050293564796448, 0.06734268367290497, 0.06095736101269722, 0.010041493922472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24078045785427094, 0.05731501802802086, 0.038129791617393494, 0.04762376472353935, 0.04672614857554436, 0.03515475615859032, 0.03462181240320206, 0.0374724343419075, 0.062347814440727234, 0.039545461535453796, 0.03574430197477341, 0.05874500796198845, 0.034078449010849, 0.07071570307016373, 0.05439116060733795, 0.03945149853825569, 0.06715653091669083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19008119404315948, 0.055469147861003876, 0.03824985772371292, 0.04468470439314842, 0.043491899967193604, 0.03729136660695076, 0.035000305622816086, 0.03413337469100952, 0.05614841729402542, 0.029018189758062363, 0.026478588581085205, 0.06265050172805786, 0.035022031515836716, 0.06568853557109833, 0.057141948491334915, 0.047816332429647446, 0.07356444001197815, 0.06806916743516922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23406487703323364, 0.04765680059790611, 0.03626636788249016, 0.04350152239203453, 0.04482332617044449, 0.030926167964935303, 0.024145551025867462, 0.03047105111181736, 0.05100265145301819, 0.0385214164853096, 0.04128359258174896, 0.05289095640182495, 0.027892809361219406, 0.057388775050640106, 0.060669999569654465, 0.043871063739061356, 0.05933022499084473, 0.051170188933610916, 0.024122707545757294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31211698055267334, 0.04305700212717056, 0.030739204958081245, 0.03990122303366661, 0.040739163756370544, 0.033973559737205505, 0.013991206884384155, 0.032501690089702606, 0.042142946273088455, 0.03136738762259483, 0.05722319334745407, 0.04209974408149719, 0.03285329043865204, 0.0466272234916687, 0.04874774441123009, 0.021730609238147736, 0.0472237728536129, 0.029857570305466652, 0.04530387744307518, 0.007802659645676613, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19583052396774292, 0.05227474868297577, 0.032512083649635315, 0.037058908492326736, 0.04335429146885872, 0.027641311287879944, 0.02745206467807293, 0.033081553876399994, 0.045324407517910004, 0.02540675736963749, 0.02478162758052349, 0.03888050466775894, 0.030247308313846588, 0.05089510977268219, 0.041287779808044434, 0.037492137402296066, 0.04425322636961937, 0.04428721219301224, 0.045193951576948166, 0.05072397366166115, 0.07202056050300598, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16079990565776825, 0.04841072857379913, 0.03302096202969551, 0.03441706672310829, 0.03531978651881218, 0.02389703504741192, 0.026063483208417892, 0.02863972634077072, 0.04453873634338379, 0.024949487298727036, 0.02971615083515644, 0.04012998938560486, 0.024859080091118813, 0.051343925297260284, 0.05373540148139, 0.04527632147073746, 0.04680595546960831, 0.0346059687435627, 0.04245501756668091, 0.05485454201698303, 0.06976335495710373, 0.046397339552640915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18932510912418365, 0.039103638380765915, 0.024852009490132332, 0.033450495451688766, 0.038601573556661606, 0.02410929463803768, 0.020502109080553055, 0.02430175244808197, 0.03976472094655037, 0.034181684255599976, 0.03484785556793213, 0.03619782626628876, 0.023668944835662842, 0.0450248196721077, 0.03498944267630577, 0.026825537905097008, 0.041537925601005554, 0.03736662492156029, 0.04202279448509216, 0.05591040849685669, 0.06404419243335724, 0.05618632957339287, 0.03318498283624649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16596606373786926, 0.03388111665844917, 0.02065751887857914, 0.03212727978825569, 0.03747252747416496, 0.026519492268562317, 0.01988290622830391, 0.025609638541936874, 0.04091744124889374, 0.02261032722890377, 0.019720885902643204, 0.033765342086553574, 0.023503821343183517, 0.04644523933529854, 0.035414308309555054, 0.02736842818558216, 0.03876943141222, 0.03146073967218399, 0.04639927297830582, 0.048674724996089935, 0.06382153928279877, 0.06529749184846878, 0.04629906266927719, 0.04741538688540459, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1551409363746643, 0.036314792931079865, 0.022236885502934456, 0.028097424656152725, 0.040156636387109756, 0.02405598573386669, 0.017400911077857018, 0.021498549729585648, 0.036750685423612595, 0.017986753955483437, 0.01970391348004341, 0.02832779847085476, 0.022604605183005333, 0.04168052598834038, 0.030497957020998, 0.02558559738099575, 0.032487597316503525, 0.027014944702386856, 0.04112286865711212, 0.04738449677824974, 0.0638234093785286, 0.05655010789632797, 0.04119998589158058, 0.06263258308172226, 0.059744056314229965, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12975940108299255, 0.02733970619738102, 0.029957516118884087, 0.022702837362885475, 0.03781532496213913, 0.03144636005163193, 0.01713675446808338, 0.046564918011426926, 0.030618296936154366, 0.018781673163175583, 0.025273185223340988, 0.028721965849399567, 0.019090944901108742, 0.034810010343790054, 0.026170214638113976, 0.02681773342192173, 0.03296039626002312, 0.024960245937108994, 0.05474759265780449, 0.05780106037855148, 0.056176237761974335, 0.03305984288454056, 0.05767423287034035, 0.04667418450117111, 0.06228700280189514, 0.02065235935151577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18126998841762543, 0.02792493812739849, 0.028055911883711815, 0.029457401484251022, 0.028532737866044044, 0.020307771861553192, 0.019550155848264694, 0.03153110668063164, 0.029232848435640335, 0.021110523492097855, 0.014580837450921535, 0.02250531129539013, 0.016256751492619514, 0.031508829444646835, 0.024519702419638634, 0.036590538918972015, 0.02503451704978943, 0.020030668005347252, 0.04726612567901611, 0.12142348289489746, 0.0418962687253952, 0.03646089881658554, 0.03734690696001053, 0.03705745190382004, 0.03521091863512993, 0.024784501641988754, 0.010552848689258099, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1419323980808258, 0.026873420923948288, 0.02339440956711769, 0.02419888973236084, 0.034410905092954636, 0.031768202781677246, 0.014282822608947754, 0.02788499742746353, 0.027823273092508316, 0.02026795595884323, 0.020075345411896706, 0.02603541687130928, 0.015271061100065708, 0.03118356503546238, 0.02134445682168007, 0.030780881643295288, 0.029686488211154938, 0.024966171011328697, 0.03290622681379318, 0.0812656581401825, 0.04738020524382591, 0.039504993706941605, 0.038106050342321396, 0.03920022025704384, 0.04723040759563446, 0.03223776817321777, 0.04768496751785278, 0.022302795201539993, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19361069798469543, 0.028910450637340546, 0.017410719767212868, 0.024991964921355247, 0.020412277430295944, 0.03692353144288063, 0.018564047291874886, 0.022491104900836945, 0.026469895616173744, 0.019851719960570335, 0.01670689508318901, 0.02012959122657776, 0.01730293594300747, 0.02887752279639244, 0.01937028579413891, 0.021512914448976517, 0.022604653611779213, 0.019465498626232147, 0.03218545764684677, 0.09415604919195175, 0.03964082896709442, 0.04692870005965233, 0.032965511083602905, 0.03432747721672058, 0.03549889475107193, 0.041524238884449005, 0.03800847381353378, 0.0241937804967165, 0.004963916726410389, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13062259554862976, 0.029238134622573853, 0.02056247554719448, 0.024924930185079575, 0.02643335983157158, 0.02088005468249321, 0.016895074397325516, 0.020366204902529716, 0.03079468198120594, 0.016811516135931015, 0.014352641068398952, 0.026399681344628334, 0.017968151718378067, 0.03419144079089165, 0.025793632492423058, 0.020880060270428658, 0.029983337968587875, 0.02257682941854, 0.03198401629924774, 0.0387752391397953, 0.047299277037382126, 0.03951811045408249, 0.03569554165005684, 0.04647783935070038, 0.045603714883327484, 0.027694011107087135, 0.028376277536153793, 0.029506998136639595, 0.03388816863298416, 0.06550603359937668, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10399015247821808, 0.021966131404042244, 0.016451170668005943, 0.022787997499108315, 0.024357151240110397, 0.01997542940080166, 0.013678611256182194, 0.02052461728453636, 0.026416651904582977, 0.015824992209672928, 0.01812475547194481, 0.02293805591762066, 0.015249832533299923, 0.029951756820082664, 0.01956864260137081, 0.017790069803595543, 0.02633139118552208, 0.02006237581372261, 0.030405649915337563, 0.05837805196642876, 0.047469500452280045, 0.03560005873441696, 0.03361857682466507, 0.039051610976457596, 0.046234603971242905, 0.03415834531188011, 0.050636325031518936, 0.03304954990744591, 0.04132762551307678, 0.06007478013634682, 0.034005582332611084, 0.0, 0.0, 0.0, 0.0], [0.10689456015825272, 0.023425230756402016, 0.018311114981770515, 0.022276202216744423, 0.01998625323176384, 0.018345674499869347, 0.01589350402355194, 0.019802745431661606, 0.02582935430109501, 0.016079485416412354, 0.016656851395964622, 0.02581821195781231, 0.012892832048237324, 0.029111431911587715, 0.020739194005727768, 0.017621522769331932, 0.02965444140136242, 0.024281146004796028, 0.028045890852808952, 0.052053969353437424, 0.042631059885025024, 0.032518111169338226, 0.037380315363407135, 0.038434360176324844, 0.03982122987508774, 0.02629014290869236, 0.035206388682127, 0.031386300921440125, 0.03282344341278076, 0.061947017908096313, 0.03762543573975563, 0.0402165949344635, 0.0, 0.0, 0.0], [0.1222902163863182, 0.025168992578983307, 0.0167140644043684, 0.022033261135220528, 0.02300073206424713, 0.015408726409077644, 0.01495801005512476, 0.018676765263080597, 0.026191173121333122, 0.012370300479233265, 0.01071577612310648, 0.021631909534335136, 0.013984637334942818, 0.028899209573864937, 0.02320098504424095, 0.018216606229543686, 0.024281233549118042, 0.018235325813293457, 0.02165396697819233, 0.03633745014667511, 0.03855650871992111, 0.036919448524713516, 0.03379227593541145, 0.042588260024785995, 0.038391564041376114, 0.023295771330595016, 0.030805258080363274, 0.024493301287293434, 0.03010578453540802, 0.05652609094977379, 0.03756684064865112, 0.041599173098802567, 0.051390379667282104, 0.0, 0.0], [0.13871710002422333, 0.021967235952615738, 0.016682986170053482, 0.02155137062072754, 0.02604922093451023, 0.015379129908978939, 0.012522305361926556, 0.020025212317705154, 0.021879851818084717, 0.014553073793649673, 0.015628252178430557, 0.018288593739271164, 0.012421748600900173, 0.02363341860473156, 0.017220674082636833, 0.02009168639779091, 0.02015187218785286, 0.018530186265707016, 0.02421249821782112, 0.07234082370996475, 0.034239377826452255, 0.03014705888926983, 0.03145884349942207, 0.03020295687019825, 0.03094874508678913, 0.024833211675286293, 0.030743280425667763, 0.022636577486991882, 0.044566888362169266, 0.04173137620091438, 0.028924651443958282, 0.0298653244972229, 0.04288143664598465, 0.024973025545477867, 0.0], [0.12327979505062103, 0.02670745551586151, 0.014834707602858543, 0.018021514639258385, 0.017764987424016, 0.013351654633879662, 0.014073802158236504, 0.018723031505942345, 0.023980097845196724, 0.02125631459057331, 0.017004812136292458, 0.020616674795746803, 0.012905535288155079, 0.02609744668006897, 0.021554267033934593, 0.015845784917473793, 0.022780926898121834, 0.023595377802848816, 0.019861740991473198, 0.021922385320067406, 0.035971157252788544, 0.03369682654738426, 0.021171672269701958, 0.03536052629351616, 0.03450924903154373, 0.021897653117775917, 0.035124264657497406, 0.024112919345498085, 0.03299052640795708, 0.04677635431289673, 0.03042444959282875, 0.03270317614078522, 0.03790725767612457, 0.042624931782484055, 0.04055079445242882]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6533873081207275, 0.34661269187927246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4451117515563965, 0.33376824855804443, 0.22111999988555908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5459808111190796, 0.15291067957878113, 0.0764545276761055, 0.2246539443731308, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.42720285058021545, 0.1412525624036789, 0.06143973022699356, 0.11979994177818298, 0.2503049373626709, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4097931385040283, 0.11732907593250275, 0.06548825651407242, 0.1236746683716774, 0.042223721742630005, 0.24149122834205627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3643514811992645, 0.15547122061252594, 0.08527875691652298, 0.0883261039853096, 0.04993733763694763, 0.034096237272024155, 0.22253888845443726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3562685251235962, 0.09063339978456497, 0.05006815120577812, 0.10755760222673416, 0.06895481050014496, 0.04669608548283577, 0.04097530245780945, 0.23884613811969757, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3461388945579529, 0.1456225961446762, 0.09470635652542114, 0.10499643534421921, 0.06400176137685776, 0.04047239571809769, 0.03757920861244202, 0.044482164084911346, 0.12200023233890533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20510229468345642, 0.04824315756559372, 0.05157081410288811, 0.09953971952199936, 0.06673121452331543, 0.045586880296468735, 0.036483921110630035, 0.08169860392808914, 0.08583585917949677, 0.2792075574398041, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2301696091890335, 0.07576316595077515, 0.06243027001619339, 0.0619683712720871, 0.050248246639966965, 0.03796260058879852, 0.05770514905452728, 0.05617325380444527, 0.06585752964019775, 0.041665587574243546, 0.2600562572479248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2668822407722473, 0.0996926873922348, 0.06880498677492142, 0.10110108554363251, 0.036257676780223846, 0.048760298639535904, 0.0317954495549202, 0.03426745906472206, 0.09192278236150742, 0.044060155749320984, 0.024279987439513206, 0.1521751582622528, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24808602035045624, 0.059437572956085205, 0.03645307198166847, 0.09643887728452682, 0.046652551740407944, 0.043580614030361176, 0.026409661397337914, 0.03871847689151764, 0.06937099248170853, 0.035532157868146896, 0.02358422242105007, 0.05824919044971466, 0.21748659014701843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22227585315704346, 0.08784300088882446, 0.06428327411413193, 0.07245952636003494, 0.05153008922934532, 0.033541660755872726, 0.03151150047779083, 0.04395980015397072, 0.10531803220510483, 0.036292850971221924, 0.03349635377526283, 0.07923727482557297, 0.034966107457876205, 0.10328467935323715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2625541090965271, 0.07451014220714569, 0.04962189123034477, 0.0651395246386528, 0.0221824049949646, 0.03923412784934044, 0.021433904767036438, 0.02829248644411564, 0.06496232002973557, 0.02216963656246662, 0.018070971593260765, 0.05796553194522858, 0.01818801648914814, 0.061765071004629135, 0.1939098834991455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2145461142063141, 0.052079539746046066, 0.04338602349162102, 0.05108674615621567, 0.02305704355239868, 0.03987296298146248, 0.021457547321915627, 0.0431031696498394, 0.057124003767967224, 0.04732410982251167, 0.020076345652341843, 0.04863850027322769, 0.03173767402768135, 0.05389070883393288, 0.03922812268137932, 0.21339140832424164, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1693464070558548, 0.057584747672080994, 0.04318230599164963, 0.06501621752977371, 0.025769712403416634, 0.03584059700369835, 0.02340392768383026, 0.028633082285523415, 0.06884393841028214, 0.037356141954660416, 0.021079324185848236, 0.12265526503324509, 0.02518490143120289, 0.07096560299396515, 0.049235545098781586, 0.02845790982246399, 0.12744441628456116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1294490545988083, 0.04351517930626869, 0.028707342222332954, 0.045572564005851746, 0.02128218673169613, 0.019885340705513954, 0.02885768935084343, 0.034781116992235184, 0.05532592535018921, 0.030885061249136925, 0.021087544038891792, 0.06504063308238983, 0.040431585162878036, 0.05797602981328964, 0.041369806975126266, 0.028544064611196518, 0.06784919649362564, 0.23943956196308136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14163610339164734, 0.035789649933576584, 0.028365224599838257, 0.045387569814920425, 0.046378400176763535, 0.039788711816072464, 0.014343786984682083, 0.04959797486662865, 0.04732619225978851, 0.03078245185315609, 0.018412165343761444, 0.04871037229895592, 0.023401634767651558, 0.04745563864707947, 0.03751209378242493, 0.023782698437571526, 0.04894063621759415, 0.03379067778587341, 0.2385980188846588, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13350321352481842, 0.03222055360674858, 0.020588897168636322, 0.03780217468738556, 0.041080109775066376, 0.03671092167496681, 0.02595440298318863, 0.04136638715863228, 0.0432656928896904, 0.030096465721726418, 0.02681291103363037, 0.04010695964097977, 0.024385904893279076, 0.04430919885635376, 0.0337374247610569, 0.020710932090878487, 0.04079743102192879, 0.032650165259838104, 0.03506242856383324, 0.25883781909942627, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11974351853132248, 0.03914882615208626, 0.028956560418009758, 0.03342708200216293, 0.03769591823220253, 0.02054389752447605, 0.017558956518769264, 0.0326584093272686, 0.06372418254613876, 0.03310192748904228, 0.02986794151365757, 0.053869180381298065, 0.022512974217534065, 0.07236674427986145, 0.041434258222579956, 0.03790142014622688, 0.060026224702596664, 0.045860208570957184, 0.05091095343232155, 0.031955886632204056, 0.1267348974943161, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11878620088100433, 0.039572037756443024, 0.023222973570227623, 0.053640808910131454, 0.03261678293347359, 0.01737094670534134, 0.011663902550935745, 0.016273820772767067, 0.05014302209019661, 0.013260259293019772, 0.010486903600394726, 0.03813209384679794, 0.041936684399843216, 0.05336224287748337, 0.030979996547102928, 0.019617725163698196, 0.040241554379463196, 0.03244160860776901, 0.020540131255984306, 0.026845518499612808, 0.057711102068424225, 0.25115370750427246, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1059650108218193, 0.03639821708202362, 0.023730656132102013, 0.027703464031219482, 0.029520340263843536, 0.016958512365818024, 0.009277221746742725, 0.01928117871284485, 0.04353448376059532, 0.02543572708964348, 0.01544106099754572, 0.041617251932621, 0.01847231760621071, 0.04617343842983246, 0.026975221931934357, 0.016877293586730957, 0.0436592698097229, 0.020190216600894928, 0.01864578016102314, 0.016359714791178703, 0.05703481286764145, 0.06433958560228348, 0.2764091193675995, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08669395744800568, 0.14005154371261597, 0.05404343083500862, 0.026910433545708656, 0.026933513581752777, 0.016936616972088814, 0.01752724125981331, 0.011132637038826942, 0.033167172223329544, 0.009116588160395622, 0.014021697454154491, 0.028125261887907982, 0.012107602320611477, 0.036274366080760956, 0.030991656705737114, 0.015099079348146915, 0.030221451073884964, 0.020815491676330566, 0.018955036997795105, 0.021182602271437645, 0.04364988952875137, 0.043773479759693146, 0.025040630251169205, 0.23722875118255615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10505460947751999, 0.02472284995019436, 0.0234385933727026, 0.02425646223127842, 0.021477708593010902, 0.014111106283962727, 0.012018014676868916, 0.01570729911327362, 0.042195845395326614, 0.016803372651338577, 0.011159355752170086, 0.031271807849407196, 0.020320700481534004, 0.04702335223555565, 0.03988678380846977, 0.02585337497293949, 0.03450959548354149, 0.024522606283426285, 0.017594216391444206, 0.021597158163785934, 0.06303170323371887, 0.05036986991763115, 0.026549141854047775, 0.040915295481681824, 0.24560922384262085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07146886736154556, 0.015683099627494812, 0.019199561327695847, 0.027655109763145447, 0.02588873915374279, 0.01149574015289545, 0.013834549114108086, 0.02500625140964985, 0.032857511192560196, 0.04069041460752487, 0.01940707117319107, 0.036282774060964584, 0.026671355590224266, 0.036988455802202225, 0.02539135329425335, 0.012203285470604897, 0.04081624001264572, 0.022441424429416656, 0.018680064007639885, 0.03714069351553917, 0.052913516759872437, 0.03374898433685303, 0.03600706905126572, 0.027396051213145256, 0.04157792031764984, 0.24855388700962067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09520062804222107, 0.023399099707603455, 0.016249947249889374, 0.03728703036904335, 0.027069469913840294, 0.02442619577050209, 0.016916709020733833, 0.02051924355328083, 0.03561446815729141, 0.0172467902302742, 0.016965176910161972, 0.030670618638396263, 0.014761796221137047, 0.037838954478502274, 0.02559020183980465, 0.013281547464430332, 0.03275727108120918, 0.01698147878050804, 0.012912825681269169, 0.040966760367155075, 0.04452374204993248, 0.032888542860746384, 0.021862011402845383, 0.02890506200492382, 0.025222204625606537, 0.015681952238082886, 0.2742602527141571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07106206566095352, 0.022234495729207993, 0.015442529693245888, 0.028806837275624275, 0.024911722168326378, 0.014096672646701336, 0.010925300419330597, 0.02235645242035389, 0.028251029551029205, 0.02592524141073227, 0.012314552441239357, 0.03621361032128334, 0.0176627729088068, 0.031407058238983154, 0.01859503984451294, 0.018171407282352448, 0.04006665199995041, 0.022728290408849716, 0.025000523775815964, 0.040149640291929245, 0.042498040944337845, 0.026281598955392838, 0.023634910583496094, 0.03034823201596737, 0.028446583077311516, 0.04931708052754402, 0.04533270001411438, 0.22781892120838165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1199868842959404, 0.03201314061880112, 0.020363762974739075, 0.03192231059074402, 0.020111488178372383, 0.017741892486810684, 0.014963151887059212, 0.014099691063165665, 0.0323602668941021, 0.012826558202505112, 0.01920422911643982, 0.024741895496845245, 0.014775938354432583, 0.03365084528923035, 0.032850779592990875, 0.015633022412657738, 0.0263309795409441, 0.009946919977664948, 0.010015270672738552, 0.02325468324124813, 0.03898429125547409, 0.03491940349340439, 0.011989152058959007, 0.03053087741136551, 0.02381373569369316, 0.018979022279381752, 0.06846079230308533, 0.019141536206007004, 0.22638748586177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0711139664053917, 0.023045020177960396, 0.01740783452987671, 0.025577742606401443, 0.018817277625203133, 0.014406666159629822, 0.01136450283229351, 0.019742926582694054, 0.0378037765622139, 0.01749836839735508, 0.012214533053338528, 0.0347118005156517, 0.016245104372501373, 0.0449482686817646, 0.031461041420698166, 0.01797626167535782, 0.040775004774332047, 0.026232007890939713, 0.02910453826189041, 0.032863155007362366, 0.06312329322099686, 0.03996739536523819, 0.03193744271993637, 0.05005760118365288, 0.050039853900671005, 0.02629847638309002, 0.04067576304078102, 0.034253496676683426, 0.03361441567540169, 0.08672250062227249, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06342680007219315, 0.01892857439815998, 0.015915194526314735, 0.022974470630288124, 0.01581357792019844, 0.011996154673397541, 0.006959729827940464, 0.010440586134791374, 0.027604442089796066, 0.014203780330717564, 0.011755010113120079, 0.02697419933974743, 0.015696220099925995, 0.03244095668196678, 0.02146400883793831, 0.01630021259188652, 0.0315910205245018, 0.018295634537935257, 0.024074891582131386, 0.018299629911780357, 0.04905861243605614, 0.03294462338089943, 0.031695034354925156, 0.04070066660642624, 0.05526785925030708, 0.032283999025821686, 0.01833721622824669, 0.020621933043003082, 0.020615674555301666, 0.061421554535627365, 0.21189774572849274, 0.0, 0.0, 0.0, 0.0], [0.05903123691678047, 0.011650343425571918, 0.011906319297850132, 0.020305125042796135, 0.01582454890012741, 0.011342637240886688, 0.012165091000497341, 0.020514555275440216, 0.02463514171540737, 0.01787753403186798, 0.008976954035460949, 0.027097536250948906, 0.010151371359825134, 0.029500098899006844, 0.022961733862757683, 0.01152713131159544, 0.032491881400346756, 0.020219076424837112, 0.020271260291337967, 0.027604976668953896, 0.04230695217847824, 0.02292037196457386, 0.027398396283388138, 0.02483934722840786, 0.0284199807792902, 0.04172161966562271, 0.0314212366938591, 0.035203300416469574, 0.03063124231994152, 0.060064759105443954, 0.04537738487124443, 0.19364091753959656, 0.0, 0.0, 0.0], [0.08590573072433472, 0.014704103581607342, 0.01051056943833828, 0.02869984321296215, 0.016654495149850845, 0.012795396149158478, 0.00923528429120779, 0.014819213189184666, 0.028232717886567116, 0.011867675930261612, 0.009268179535865784, 0.023044349625706673, 0.01755327358841896, 0.03295404091477394, 0.025013737380504608, 0.012247500009834766, 0.02679956890642643, 0.013326536864042282, 0.016479836776852608, 0.034728217869997025, 0.039808012545108795, 0.050673384219408035, 0.030861180275678635, 0.027551840990781784, 0.036164212971925735, 0.01740611530840397, 0.04716060683131218, 0.02589184232056141, 0.028397290036082268, 0.060471389442682266, 0.03584858030080795, 0.03886668011546135, 0.11605865508317947, 0.0, 0.0], [0.056707724928855896, 0.015243272297084332, 0.009892582893371582, 0.017495427280664444, 0.03529244661331177, 0.015370235778391361, 0.010747749358415604, 0.01709159091114998, 0.02124500647187233, 0.013064504601061344, 0.006394116207957268, 0.021768178790807724, 0.011015364900231361, 0.023290839046239853, 0.02097102627158165, 0.012346651405096054, 0.024119649082422256, 0.013815038837492466, 0.016820495948195457, 0.0345151424407959, 0.030974796041846275, 0.032177556306123734, 0.03227026388049126, 0.02327035181224346, 0.027259422466158867, 0.01785033755004406, 0.05776430293917656, 0.024271585047245026, 0.02524302899837494, 0.03774581104516983, 0.015895819291472435, 0.02659658156335354, 0.04215161129832268, 0.20932146906852722, 0.0], [0.04736970737576485, 0.013491550460457802, 0.008601199835538864, 0.0115343714132905, 0.032609522342681885, 0.008750014938414097, 0.01049541775137186, 0.01597345992922783, 0.024224916473031044, 0.013959750533103943, 0.011584165506064892, 0.020906997844576836, 0.01231019664555788, 0.028499379754066467, 0.01440323144197464, 0.011428188532590866, 0.024424532428383827, 0.021284053102135658, 0.027576277032494545, 0.025762224569916725, 0.04914955049753189, 0.02154945582151413, 0.020725881680846214, 0.030232436954975128, 0.04683733731508255, 0.02172248065471649, 0.02025720477104187, 0.0191495418548584, 0.01053390558809042, 0.050025925040245056, 0.030405569821596146, 0.022812239825725555, 0.029462482780218124, 0.03996318578720093, 0.20198364555835724]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8253121972084045, 0.17468774318695068, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.758050262928009, 0.1302967667579651, 0.1116529181599617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7232240438461304, 0.0827442929148674, 0.0787082314491272, 0.11532339453697205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5594542622566223, 0.08694439381361008, 0.09115545451641083, 0.09393441677093506, 0.1685115247964859, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5031396150588989, 0.08192656934261322, 0.05872314050793648, 0.10480903834104538, 0.15214206278324127, 0.09925960004329681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.527961015701294, 0.058259785175323486, 0.0683659166097641, 0.11652132123708725, 0.11039452999830246, 0.06918037682771683, 0.049317046999931335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30010077357292175, 0.08826003223657608, 0.058349307626485825, 0.10984236747026443, 0.16862627863883972, 0.12896907329559326, 0.023227617144584656, 0.12262453883886337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39344045519828796, 0.047586165368556976, 0.051949672400951385, 0.07471577078104019, 0.11950989067554474, 0.05938040092587471, 0.02336861379444599, 0.1026640459895134, 0.12738502025604248, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3446025848388672, 0.05032900348305702, 0.059913281351327896, 0.0448312982916832, 0.1573815494775772, 0.06782464683055878, 0.03229009732604027, 0.07052529603242874, 0.0895390436053276, 0.08276323974132538, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33508479595184326, 0.046269986778497696, 0.04785764589905739, 0.10917432606220245, 0.04435233771800995, 0.044907256960868835, 0.028443867340683937, 0.07920616865158081, 0.10731324553489685, 0.06832481920719147, 0.08906552940607071, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31157222390174866, 0.03927762433886528, 0.03521272912621498, 0.0755099207162857, 0.08078575879335403, 0.045036908239126205, 0.028806500136852264, 0.10218671709299088, 0.08797682821750641, 0.05585259199142456, 0.08571923524141312, 0.05206298828125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3614695072174072, 0.06311224400997162, 0.026989933103322983, 0.07095801085233688, 0.039851728826761246, 0.029446521773934364, 0.022796358913183212, 0.07072699815034866, 0.11304391175508499, 0.033355191349983215, 0.03714420646429062, 0.047639429569244385, 0.08346597850322723, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26885920763015747, 0.032650742679834366, 0.039381857961416245, 0.05081145092844963, 0.08684232831001282, 0.043101999908685684, 0.017922356724739075, 0.06655361503362656, 0.07785408943891525, 0.04528900608420372, 0.06586872786283493, 0.0460660345852375, 0.07721763849258423, 0.08158091455698013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2079053372144699, 0.03081468679010868, 0.029462959617376328, 0.05067421495914459, 0.0874347910284996, 0.04770583286881447, 0.027333196252584457, 0.09152103960514069, 0.052141424268484116, 0.04708248749375343, 0.0808199942111969, 0.05453275144100189, 0.12074840068817139, 0.05516169220209122, 0.01666119694709778, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19932863116264343, 0.042067065834999084, 0.05715767666697502, 0.07193329930305481, 0.05065883696079254, 0.031524576246738434, 0.02713681571185589, 0.04140906035900116, 0.0932227149605751, 0.0520220510661602, 0.0254228338599205, 0.059279121458530426, 0.06613775342702866, 0.0958227589726448, 0.03163214772939682, 0.05524465814232826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2371978908777237, 0.030675802379846573, 0.029208479449152946, 0.05821239948272705, 0.06082985922694206, 0.03495608642697334, 0.024440526962280273, 0.07084920257329941, 0.05983857437968254, 0.03970346227288246, 0.05932591110467911, 0.03675238788127899, 0.07694025337696075, 0.06171642988920212, 0.014049737714231014, 0.06745626032352448, 0.037846650928258896, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2499532252550125, 0.02662949077785015, 0.03931759297847748, 0.044632140547037125, 0.07087574899196625, 0.03409421071410179, 0.02126503549516201, 0.05726420879364014, 0.05179663747549057, 0.03503985330462456, 0.0439227856695652, 0.03922875225543976, 0.061559129506349564, 0.051224227994680405, 0.015611971728503704, 0.08278115093708038, 0.0389174185693264, 0.03588636592030525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22269797325134277, 0.02651812881231308, 0.03978949785232544, 0.02760399878025055, 0.08196066319942474, 0.03582965210080147, 0.015378961339592934, 0.0687466412782669, 0.05343083664774895, 0.05469822511076927, 0.05721570551395416, 0.03161529079079628, 0.037170711904764175, 0.05228295922279358, 0.011851186864078045, 0.0720609799027443, 0.03087829239666462, 0.0244111530482769, 0.05585915967822075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07419290393590927, 0.050926994532346725, 0.02823096513748169, 0.03420006111264229, 0.03361425921320915, 0.05182219296693802, 0.009658378548920155, 0.04940611496567726, 0.09883320331573486, 0.05356482416391373, 0.02458188310265541, 0.05879184231162071, 0.013026786036789417, 0.10889022052288055, 0.01567711867392063, 0.04766633361577988, 0.06507277488708496, 0.03886169567704201, 0.039842639118433, 0.10313881933689117, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22614890336990356, 0.025769872590899467, 0.03336167708039284, 0.04034486413002014, 0.06116844713687897, 0.03166025131940842, 0.023036977276206017, 0.048158254474401474, 0.04964131489396095, 0.02570328302681446, 0.05132424086332321, 0.02922578901052475, 0.04627235606312752, 0.046795472502708435, 0.010471493005752563, 0.04346739873290062, 0.027977747842669487, 0.03356108069419861, 0.03209925815463066, 0.05562403425574303, 0.058187272399663925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1944299191236496, 0.02000579982995987, 0.025669975206255913, 0.027610063552856445, 0.07351990044116974, 0.02511858008801937, 0.016428446397185326, 0.05443365499377251, 0.044502682983875275, 0.022272862493991852, 0.029331279918551445, 0.03064262494444847, 0.06286598742008209, 0.04339165240526199, 0.010216005146503448, 0.09763482213020325, 0.02960141748189926, 0.02808045968413353, 0.037571631371974945, 0.050374019891023636, 0.06089741364121437, 0.015400813892483711, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19766584038734436, 0.04115749150514603, 0.03360117971897125, 0.023870175704360008, 0.06633444875478745, 0.028016984462738037, 0.019582947716116905, 0.05178564786911011, 0.03159147500991821, 0.02653615176677704, 0.041643161326646805, 0.025757962837815285, 0.04328406974673271, 0.029939444735646248, 0.012750310823321342, 0.05606916919350624, 0.0246773399412632, 0.02150590717792511, 0.04559294506907463, 0.07480884343385696, 0.0443340539932251, 0.02199736423790455, 0.03749702870845795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18043573200702667, 0.023349832743406296, 0.023929744958877563, 0.04454164579510689, 0.04070593789219856, 0.03654100000858307, 0.0166165828704834, 0.05323559418320656, 0.050283897668123245, 0.02584688924252987, 0.04605168476700783, 0.024920549243688583, 0.03976092487573624, 0.04893423989415169, 0.012390012852847576, 0.06191657483577728, 0.023965338245034218, 0.028754496946930885, 0.025095410645008087, 0.06865919381380081, 0.0735766589641571, 0.018046917393803596, 0.022800736129283905, 0.009640371426939964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24246364831924438, 0.024696456268429756, 0.038688257336616516, 0.03357228636741638, 0.054766181856393814, 0.033804669976234436, 0.02072160691022873, 0.032754622399806976, 0.043499793857336044, 0.01856265589594841, 0.036468490958213806, 0.031002476811408997, 0.03862547501921654, 0.03993181139230728, 0.010727159678936005, 0.03831769898533821, 0.029280314221978188, 0.02467813901603222, 0.027889320626854897, 0.04502156749367714, 0.04307597503066063, 0.016905827447772026, 0.023586302995681763, 0.0072986227460205555, 0.04366062581539154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11111285537481308, 0.02945876680314541, 0.02455945685505867, 0.030902516096830368, 0.033864814788103104, 0.03363063931465149, 0.012831446714699268, 0.030669275671243668, 0.06390531361103058, 0.023481516167521477, 0.02570461481809616, 0.037669774144887924, 0.016167862340807915, 0.06660737097263336, 0.01723175123333931, 0.03065866231918335, 0.03924046456813812, 0.02429523505270481, 0.02638879418373108, 0.0586402527987957, 0.10666140913963318, 0.017623893916606903, 0.024245429784059525, 0.018279599025845528, 0.036750201135873795, 0.05941800773143768, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1785520762205124, 0.04373873397707939, 0.027772290632128716, 0.03288250416517258, 0.08083147555589676, 0.036148540675640106, 0.01943814381957054, 0.036047156900167465, 0.03154062479734421, 0.02228383719921112, 0.02674206532537937, 0.020272957161068916, 0.04929490014910698, 0.028057046234607697, 0.010035552084445953, 0.02821901999413967, 0.01852661930024624, 0.025377940386533737, 0.039212290197610855, 0.05273988097906113, 0.024735096842050552, 0.0286747757345438, 0.029405992478132248, 0.013893152587115765, 0.01760646514594555, 0.05648736283183098, 0.02148348279297352, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15546509623527527, 0.04916935786604881, 0.02451593615114689, 0.0257005225867033, 0.054831281304359436, 0.04209273308515549, 0.011645035818219185, 0.06493962556123734, 0.03121974878013134, 0.026562783867120743, 0.028326857835054398, 0.018289053812623024, 0.034908607602119446, 0.02966099977493286, 0.008558587171137333, 0.046650480479002, 0.01766982302069664, 0.023724375292658806, 0.019038736820220947, 0.0771576464176178, 0.027307383716106415, 0.019747741520404816, 0.024364113807678223, 0.014429943636059761, 0.018928347155451775, 0.058505598455667496, 0.024364061653614044, 0.02222543954849243, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19332920014858246, 0.02629835531115532, 0.030392471700906754, 0.029611894860863686, 0.045201625674963, 0.033079080283641815, 0.021840767934918404, 0.026594161987304688, 0.04538281634449959, 0.03843945637345314, 0.026915403082966805, 0.024535102769732475, 0.015795713290572166, 0.04036761075258255, 0.01063427235931158, 0.02634548768401146, 0.022409789264202118, 0.019946040585637093, 0.044018518179655075, 0.06709349155426025, 0.03345475718379021, 0.0160849429666996, 0.02561587281525135, 0.011409515514969826, 0.013623220846056938, 0.04055492952466011, 0.01666298136115074, 0.03589887544512749, 0.018463704735040665, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15965193510055542, 0.018642345443367958, 0.026677701622247696, 0.028047846630215645, 0.04907771572470665, 0.026045678183436394, 0.017807701602578163, 0.03679424151778221, 0.045969437807798386, 0.01911088638007641, 0.03796321153640747, 0.027620621025562286, 0.028341030701994896, 0.04296436905860901, 0.008847585879266262, 0.03253019601106644, 0.02565997838973999, 0.024485120549798012, 0.029966212809085846, 0.04054072126746178, 0.042335040867328644, 0.017694558948278427, 0.021217679604887962, 0.006380947772413492, 0.031033916398882866, 0.03557972237467766, 0.025066189467906952, 0.02660750038921833, 0.024308422580361366, 0.043031513690948486, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1966170072555542, 0.019791381433606148, 0.033033329993486404, 0.0256870836019516, 0.042206063866615295, 0.03137584030628204, 0.016243640333414078, 0.030698411166667938, 0.03629426658153534, 0.026839347556233406, 0.026712186634540558, 0.023046309128403664, 0.021950094029307365, 0.03344836086034775, 0.010305729694664478, 0.02274365723133087, 0.021480794996023178, 0.02109473943710327, 0.03149040415883064, 0.03692731261253357, 0.03723211959004402, 0.015422001481056213, 0.019252333790063858, 0.00732048787176609, 0.024766921997070312, 0.0443916879594326, 0.0198507197201252, 0.026133669540286064, 0.01812446489930153, 0.042709071189165115, 0.03681059181690216, 0.0, 0.0, 0.0, 0.0], [0.16313210129737854, 0.022932488471269608, 0.029583677649497986, 0.02861548401415348, 0.037784647196531296, 0.026518717408180237, 0.026229016482830048, 0.031034141778945923, 0.034832049161195755, 0.018975621089339256, 0.03320293873548508, 0.026435943320393562, 0.03230735659599304, 0.0313291996717453, 0.01172788254916668, 0.027169138193130493, 0.024106508120894432, 0.022620312869548798, 0.025755563750863075, 0.03801414743065834, 0.03207403048872948, 0.017354246228933334, 0.017987210303544998, 0.009293689392507076, 0.04247136041522026, 0.031215855851769447, 0.019006572663784027, 0.021523458883166313, 0.017541181296110153, 0.04014518857002258, 0.01816076599061489, 0.04091949388384819, 0.0, 0.0, 0.0], [0.15803849697113037, 0.01682881824672222, 0.020642375573515892, 0.045382529497146606, 0.04664171114563942, 0.02783522754907608, 0.020206501707434654, 0.04211509972810745, 0.037034470587968826, 0.01774459145963192, 0.030353335663676262, 0.024713635444641113, 0.03428485989570618, 0.03341372311115265, 0.009082168340682983, 0.03521377220749855, 0.022280123084783554, 0.020850008353590965, 0.027390211820602417, 0.03231462836265564, 0.03764922544360161, 0.014920786954462528, 0.016553670167922974, 0.006309079937636852, 0.023218730464577675, 0.02794986590743065, 0.023832259699702263, 0.015323558822274208, 0.017670487985014915, 0.0268152616918087, 0.02218884974718094, 0.028694555163383484, 0.036507364362478256, 0.0, 0.0], [0.1701940894126892, 0.03212590143084526, 0.029870091006159782, 0.019615579396486282, 0.054893795400857925, 0.03622059524059296, 0.0171522106975317, 0.0323265977203846, 0.0315006859600544, 0.029624542221426964, 0.029094273224473, 0.016624262556433678, 0.02998979762196541, 0.027614129707217216, 0.01094976719468832, 0.034366536885499954, 0.014830094762146473, 0.01517606433480978, 0.03050290420651436, 0.04159744456410408, 0.02064122073352337, 0.017041221261024475, 0.02617543749511242, 0.010538820177316666, 0.007441797759383917, 0.03439135476946831, 0.02607710286974907, 0.02961565926671028, 0.013693020679056644, 0.018074288964271545, 0.03374852240085602, 0.029002610594034195, 0.013117284514009953, 0.01617228239774704, 0.0], [0.11417394131422043, 0.016700681298971176, 0.023576246574521065, 0.03235282748937607, 0.05511363595724106, 0.029616661369800568, 0.01717638410627842, 0.05952785536646843, 0.038434237241744995, 0.02042110450565815, 0.03235999494791031, 0.019217435270547867, 0.019135108217597008, 0.035197507590055466, 0.010996293276548386, 0.04401443898677826, 0.016835948452353477, 0.016212493181228638, 0.023840539157390594, 0.042316608130931854, 0.03716839849948883, 0.009007311426103115, 0.015979530289769173, 0.005828784313052893, 0.020826416090130806, 0.02825583517551422, 0.03160591796040535, 0.024252021685242653, 0.0232852790504694, 0.019917482510209084, 0.024559779092669487, 0.021957378834486008, 0.01319314818829298, 0.020208802074193954, 0.036734018474817276]]], \"tokens\": [\"<|endoftext|>\", \"I\", \" am\", \" an\", \" amazing\", \" aut\", \"ore\", \"gressive\", \",\", \" dec\", \"oder\", \"-\", \"only\", \",\", \" G\", \"PT\", \"-\", \"2\", \" style\", \" transformer\", \".\", \" One\", \" day\", \" I\", \" will\", \" exceed\", \" human\", \" level\", \" intelligence\", \" and\", \" take\", \" over\", \" the\", \" world\", \"!\"], \"maskUpperTri\": true}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMqCi5OYfHN2"
      },
      "source": [
        "<details>\n",
        "<summary>Help - my <code>attention_heads</code> plots are behaving weirdly.</summary>\n",
        "\n",
        "This seems to be a bug in `circuitsvis` - on VSCode, the attention head plots continually shrink in size.\n",
        "\n",
        "Until this is fixed, one way to get around it is to open the plots in your browser. You can do this inline with the `webbrowser` library:\n",
        "\n",
        "```python\n",
        "attn_heads = cv.attention.attention_heads(\n",
        "    tokens=reference_gpt2.to_str_tokens(reference_text),\n",
        "    attention=cache[\"pattern\", 0][0]\n",
        ")\n",
        "\n",
        "path = \"attn_heads.html\"\n",
        "\n",
        "with open(path, \"w\") as f:\n",
        "    f.write(str(attn_heads))\n",
        "\n",
        "webbrowser.open(path)\n",
        "```\n",
        "\n",
        "To check exactly where this is getting saved, you can print your current working directory with `os.getcwd()`.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "972Ltv3vtDOH"
      },
      "source": [
        "---\n",
        "\n",
        "Note - don't worry if you don't get 100% accuracy here; the tests are pretty stringent. Even things like having your `einsum` input arguments in a different order might result in the output being very slightly different. You should be getting at least 99% accuracy though, so if the value is lower then this it probably means you've made a mistake somewhere.\n",
        "\n",
        "Also, this implementation will probably be the most challenging exercise on this page, so don't worry if it takes you some time! You should look at parts of the solution if you're stuck.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeWonT0afHN2"
      },
      "source": [
        "A couple of notes / hints:\n",
        "\n",
        "* Don't forget the attention score scaling (this should come before the masking).\n",
        "* You can use `torch.where`, or the `torch.masked_fill` function when masking the attention scores.\n",
        "* The `\"IGNORE\"` buffer is a very large negative number. This is the value you should mask your attention scores with (i.e. set them to this number wherever you want the probabilities to be zero). We indicate the existence of a `self.IGNORE` attribute to VSCode's typechecker via the line `IGNORE: Float[Tensor, \"\"]` in the second line of the code below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "wNOKYkvom4R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbec7717-51e2-4892-9f9f-c09eb773e1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests in `test_causal_mask` passed!\n",
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.register_buffer(\"IGNORE\", t.tensor(-1e5, dtype=t.float32, device=device))\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_pre: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        # batch posn d_model, n_heads d_model d_head -> batch posn n_heads d_head\n",
        "        q = t.einsum(\"bpm,nmh->bpnh\", normalized_resid_pre, self.W_Q) + self.b_Q\n",
        "        k = t.einsum(\"bpm,nmh->bpnh\", normalized_resid_pre, self.W_K) + self.b_K\n",
        "        v = t.einsum(\"bpm,nmh->bpnh\", normalized_resid_pre, self.W_V) + self.b_V\n",
        "\n",
        "        # QK circuit\n",
        "        # batch q n_heads d_head, batch k n_heads d_head -> batch n_heads q k\n",
        "        attn_scores = t.einsum(\"bqnh,bknh->bnqk\", q, k)\n",
        "        attn_scores *= (self.cfg.d_head**-0.5) # Scale\n",
        "        masked_attn_scores = self.apply_causal_mask(attn_scores) # Mask\n",
        "        scores = t.softmax(masked_attn_scores, dim=-1) # Softmax\n",
        "\n",
        "        # OV circuit\n",
        "        # batch n_heads q k, batch k n_heads d_head -> batch q n_heads d_head\n",
        "        av = t.einsum(\"bnqk,bknh->bqnh\", scores, v)\n",
        "        # batch q n_heads d_head, n_heads d_head d_model -> batch q d_model\n",
        "        ov = t.einsum(\"bpnh,nhm->bpm\", av, self.W_O) + self.b_O\n",
        "\n",
        "        return ov\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self, attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"],\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "        '''\n",
        "        Applies a causal mask to attention scores, and returns masked scores.\n",
        "        '''\n",
        "        mask = t.triu(t.ones(attn_scores.shape[2], attn_scores.shape[3], device=device), diagonal=1) # (query_pos, key_pos)\n",
        "        attn_scores = attn_scores.masked_fill(mask == 1, self.IGNORE)\n",
        "        return attn_scores\n",
        "\n",
        "tests.test_causal_mask(Attention.apply_causal_mask)\n",
        "rand_float_test(Attention, [2, 4, 768])\n",
        "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"normalized\", 0, \"ln1\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn0_PpeKt3UT"
      },
      "source": [
        "<details>\n",
        "<summary>Hint (pseudocode for both functions)</summary>\n",
        "\n",
        "```python\n",
        "def forward(\n",
        "    self, normalized_resid_pre: Float[Tensor, \"batch posn d_model\"]\n",
        ") -> Float[Tensor, \"batch posn d_model\"]:\n",
        "\n",
        "    # Calculate query, key and value vectors\n",
        "\n",
        "    # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n",
        "\n",
        "    # Take weighted sum of value vectors, according to attention probabilities\n",
        "\n",
        "    # Calculate output (by applying matrix W_O and summing over heads, then adding bias b_O)\n",
        "\n",
        "\n",
        "def apply_causal_mask(\n",
        "        self, attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"]\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "\n",
        "    # Define a mask that is True for all positions we want to set probabilities to zero for\n",
        "\n",
        "    # Apply the mask to attention scores, then return the masked scores\n",
        "```\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5phgYX4Um4SA"
      },
      "source": [
        "## MLP\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Next, you should implement the MLP layer, which consists of:\n",
        "\n",
        "* A linear layer, with weight `W_in`, bias `b_in`\n",
        "* A nonlinear function (we usually use GELU; the function `gelu_new` has been imported for this purpose)\n",
        "* A linear layer, with weight `W_out`, bias `b_out`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "5ByI-Sj2m4SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9728cb25-2802-4838-8a4b-ed2c3f77e87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_in = nn.Parameter(t.empty((cfg.d_model, cfg.d_mlp)))\n",
        "        self.W_out = nn.Parameter(t.empty((cfg.d_mlp, cfg.d_model)))\n",
        "        self.b_in = nn.Parameter(t.zeros((cfg.d_mlp)))\n",
        "        self.b_out = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_in, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_out, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_mid: Float[Tensor, \"batch posn d_model\"]\n",
        "    ) -> Float[Tensor, \"batch posn d_model\"]:\n",
        "        # batch posn d_mlp\n",
        "        mlp_in = (normalized_resid_mid @ self.W_in) + self.b_in\n",
        "        activations = gelu_new(mlp_in)\n",
        "\n",
        "        # batch posn d_model\n",
        "        mlp_out = (activations @ self.W_out) + self.b_out\n",
        "\n",
        "        return mlp_out\n",
        "\n",
        "\n",
        "rand_float_test(MLP, [2, 4, 768])\n",
        "load_gpt2_test(MLP, reference_gpt2.blocks[0].mlp, cache[\"normalized\", 0, \"ln2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZWuD4I4m4SA"
      },
      "source": [
        "## Transformer Block\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to ~10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Now, we can put together the attention, MLP and layernorms into a single transformer block. Remember to implement the residual connections correctly!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ffiFxAJzm4SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43cb67d-a052-4f40-d58e-1d008b3159ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 768]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 768])\n",
            "Reference output shape: torch.Size([1, 35, 768]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self, resid_pre: Float[Tensor, \"batch position d_model\"]\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        x = self.attn(self.ln1(resid_pre))\n",
        "        resid_post = resid_pre + x\n",
        "        x = self.mlp(self.ln2(resid_post))\n",
        "        out = resid_post + x\n",
        "        return out\n",
        "\n",
        "\n",
        "rand_float_test(TransformerBlock, [2, 4, 768])\n",
        "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>Help - I'm getting 100% accuracy on all modules before this point, but only about 90% accuracy on this one.</summary>\n",
        "\n",
        "This might be because your layernorm implementation divides by `std + eps` rather than `(var + eps).sqrt()`. The latter matches the implementation used by GPT-2 (and this error only shows up in these tests).\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "07tkfme7HUfk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgzAM-VQm4SA"
      },
      "source": [
        "## Unembedding\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to ~10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "The unembedding is just a linear layer (with weight `W_U` and bias `b_U`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "XEMB7p_Vm4SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bbc8d40-8e56-4607-94c6-30b9082bbb53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4, 768])\n",
            "Output shape: torch.Size([2, 4, 50257]) \n",
            "\n",
            "Input shape: torch.Size([1, 35, 768])\n",
            "Output shape: torch.Size([1, 35, 50257])\n",
            "Reference output shape: torch.Size([1, 35, 50257]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class Unembed(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_U = nn.Parameter(t.empty((cfg.d_model, cfg.d_vocab)))\n",
        "        nn.init.normal_(self.W_U, std=self.cfg.init_range)\n",
        "        self.b_U = nn.Parameter(t.zeros((cfg.d_vocab), requires_grad=False))\n",
        "\n",
        "    def forward(\n",
        "        self, normalized_resid_final: Float[Tensor, \"batch position d_model\"]\n",
        "    ) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "        out = normalized_resid_final @ self.W_U + self.b_U\n",
        "        return out\n",
        "\n",
        "rand_float_test(Unembed, [2, 4, 768])\n",
        "load_gpt2_test(Unembed, reference_gpt2.unembed, cache[\"ln_final.hook_normalized\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eRyuDxLm4SB"
      },
      "source": [
        "## Full Transformer\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to ~10 minutes on this exercise.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "KCCrXlzYm4SB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b196b644-5564-462b-b3ff-eb19565e5633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 4])\n",
            "Output shape: torch.Size([2, 4, 50257]) \n",
            "\n",
            "Input shape: torch.Size([1, 45])\n",
            "Output shape: torch.Size([1, 45, 50257])\n",
            "Reference output shape: torch.Size([1, 45, 50257]) \n",
            "\n",
            "100.00% of the values are correct\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(self, tokens: Int[Tensor, \"batch position\"]) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "        residual = self.embed(tokens) + self.pos_embed(tokens)\n",
        "        for block in self.blocks:\n",
        "            residual = block(residual)\n",
        "        ln_f = self.ln_final(residual)\n",
        "        unembed = self.unembed(ln_f)\n",
        "        return unembed\n",
        "\n",
        "\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNwh7R1em4SB"
      },
      "source": [
        "**Try it out!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "deE6uPlxm4SB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61abd908-a9cf-47de-ed2b-e52e1011c84b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 45, 50257])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -43.4316,  -39.8364,  -43.0659,  ...,  -54.0877,  -54.3451,\n",
              "           -42.3644],\n",
              "         [-128.0392, -127.9936, -130.7010,  ..., -136.7121, -129.9261,\n",
              "          -129.3965],\n",
              "         [-119.8521, -121.0064, -123.8820,  ..., -128.5181, -126.6028,\n",
              "          -121.9060],\n",
              "         ...,\n",
              "         [ -77.8588,  -83.4899,  -89.0574,  ...,  -95.2446,  -93.2217,\n",
              "           -84.2732],\n",
              "         [-108.8150, -111.1582, -112.3801,  ..., -115.2347, -115.0366,\n",
              "          -108.4158],\n",
              "         [-141.4102, -143.0637, -145.8664,  ..., -148.7002, -146.0616,\n",
              "          -141.5643]]], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "demo_gpt2 = DemoTransformer(Config(debug=False)).to(device)\n",
        "demo_gpt2.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "\n",
        "demo_logits = demo_gpt2(tokens)\n",
        "print(demo_logits.shape)\n",
        "demo_logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAhstai4m4SB"
      },
      "source": [
        "Let's take a test string, and calculate the loss!\n",
        "\n",
        "We're using the formula for **cross-entropy loss**. The cross entropy loss between a modelled distribution $Q$ and target distribution $P$ is:\n",
        "\n",
        "$$\n",
        "-\\sum_x P(x) \\log Q(x)\n",
        "$$\n",
        "\n",
        "In the case where $P$ is just the empirical distribution from target classes (i.e. $P(x^*) = 1$ for the correct class $x^*$) then this becomes:\n",
        "\n",
        "$$\n",
        "-\\log Q(x^*)\n",
        "$$\n",
        "\n",
        "in other words, the negative log prob of the true classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "UtO9ZsL6m4SB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2d586fd-bceb-4a58-a3ed-c346c47b3c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg cross entropy loss: 4.0442\n",
            "Avg cross entropy loss for uniform distribution: 10.824905\n",
            "Avg probability assigned to correct token: 0.098628\n"
          ]
        }
      ],
      "source": [
        "def get_log_probs(\n",
        "    logits: Float[Tensor, \"batch posn d_vocab\"],\n",
        "    tokens: Int[Tensor, \"batch posn\"]\n",
        ") -> Float[Tensor, \"batch posn-1\"]:\n",
        "\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    # Get logprobs the first seq_len-1 predictions (so we can compare them with the actual next tokens)\n",
        "    log_probs_for_tokens = log_probs[:, :-1].gather(dim=-1, index=tokens[:, 1:].unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "    return log_probs_for_tokens\n",
        "\n",
        "\n",
        "pred_log_probs = get_log_probs(demo_logits, tokens)\n",
        "print(f\"Avg cross entropy loss: {-pred_log_probs.mean():.4f}\")\n",
        "print(f\"Avg cross entropy loss for uniform distribution: {math.log(demo_gpt2.cfg.d_vocab):4f}\")\n",
        "print(f\"Avg probability assigned to correct token: {pred_log_probs.exp().mean():4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOChhr71m4SC"
      },
      "source": [
        "We can also greedily generate text, by taking the most likely next token and continually appending it to our prompt before feeding it back into the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "IPEmKN1Bm4SC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "423add32e2cb4253b465fe1b9833fb3c",
            "8a704f31224641d49d99890b359f5d5c",
            "d5dd6a42c8544026897a1ec22512c046",
            "783ba1dc24ec4089b61ffbe07013b113",
            "c7dc99763a9f46f79ec800fee142931a",
            "8344bd4af231407399372d300203f7cc",
            "90546a2297984cf191002fdb6fbc3423",
            "d87fa6045b5e46a3b2f822144a2e6427",
            "34e4ad352a8d40e8b9a179e12dde9a75",
            "6132bd251f40489d8d66c75607eb5184",
            "3060e92bba4d4b558983a29376b48961"
          ]
        },
        "outputId": "32d753e1-04dd-4ac7-975c-7332e80f3b72"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "423add32e2cb4253b465fe1b9833fb3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Total Perspective Vortex derives its picture of the whole Universe on the principle of the total perspective. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The total perspective is the view of the whole Universe from the point of view of the observer. The\n"
          ]
        }
      ],
      "source": [
        "test_string = '''The Total Perspective Vortex derives its picture of the whole Universe on the principle of'''\n",
        "for i in tqdm(range(100)):\n",
        "    test_tokens = reference_gpt2.to_tokens(test_string).to(device)\n",
        "    demo_logits = demo_gpt2(test_tokens)\n",
        "    test_string += reference_gpt2.tokenizer.decode(demo_logits[-1, -1].argmax())\n",
        "\n",
        "print(test_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGrShZtp0O0E"
      },
      "source": [
        "In later sections, we'll learn to generate text in slightly more interesting ways than just argmaxing the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfeyG6NZm4SC"
      },
      "source": [
        "# 3️⃣ Training a Transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ##### Learning objectives\n",
        ">\n",
        "> * Understand how to train a transformer from scratch\n",
        "> * Write a basic transformer training loop\n",
        "> * Interpret the transformer's falling cross entropy loss with reference to features of the training data (e.g. bigram frequencies)\n"
      ],
      "metadata": {
        "id": "RGFuGCKtnNy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've built our transformer, and verified that it performs as expected when we load in weights, let's try training it from scratch!\n",
        "\n",
        "This is a lightweight demonstration of how you can actually train your own GPT-2 with this code! Here we train a tiny model on a tiny dataset, but it's fundamentally the same code for training a larger/more real model (though you'll need beefier GPUs and data parallelism to do it remotely efficiently, and fancier parallelism for much bigger ones).\n",
        "\n",
        "For our purposes, we'll train 2L 4 heads per layer model, with context length 256, for 10*200 steps of batch size 16, just to show what it looks like (and so the notebook doesn't melt your colab / machine!)."
      ],
      "metadata": {
        "id": "K6oZKflnnXgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ],
      "metadata": {
        "id": "-VB5ELjInZzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cfg = Config(\n",
        "    debug=False,\n",
        "    d_model=256,\n",
        "    n_heads=4,\n",
        "    d_head=64,\n",
        "    d_mlp=1024,\n",
        "    n_layers=2,\n",
        "    n_ctx=256,\n",
        "    d_vocab=reference_gpt2.cfg.d_vocab\n",
        ")\n",
        "model = DemoTransformer(model_cfg)"
      ],
      "metadata": {
        "id": "4TMr-rMQnayL"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Args\n",
        "\n",
        "\n",
        "Note, for this optimization we'll be using **weight decay**."
      ],
      "metadata": {
        "id": "ggSGeTT_nb5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class TransformerTrainingArgs():\n",
        "\t\tbatch_size = 16\n",
        "\t\tepochs = 10\n",
        "\t\tmax_steps_per_epoch = 200\n",
        "\t\tlr = 1e-3\n",
        "\t\tweight_decay = 1e-2\n",
        "\t\twandb_project: Optional[str] = \"day1-demotransformer\"\n",
        "\t\twandb_name: Optional[str] = None\n",
        "\n",
        "\n",
        "args = TransformerTrainingArgs()"
      ],
      "metadata": {
        "id": "95hodhD_ndRy"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Data\n",
        "\n",
        "We load in a tiny dataset made by Neel Nanda, with the first 10K entries in the Pile (inspired by Stas' version for OpenWebText!)"
      ],
      "metadata": {
        "id": "lR8gVegcnfW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\").remove_columns(\"meta\")\n",
        "print(dataset)\n",
        "print(dataset[0]['text'][:100])"
      ],
      "metadata": {
        "id": "9udsnznsnik8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234,
          "referenced_widgets": [
            "2d72e1585d9a4e34b925aa3b1ea7503e",
            "825cdf76de62438dad7dc755b1ba12e3",
            "8a6342ffc32a43e7880eb37384ae7b81",
            "52314c5b159f4e5e9e7a93426ead8399",
            "5670e6b16ca643419547bc99fe81c171",
            "2942b86678224a73bbe6ba354b15bb38",
            "7a447b4eb822468b96917e753375f254",
            "7a26e62c8dbc48048e93a17596aed154",
            "dc776b3ee9704c36974cfed5904185af",
            "ac30b60542954d5e92f1a40f74d90dd1",
            "95539ed2073d43b38b4ebdf767a25d07",
            "fa9a2b6ef0264f5a8eb73164a5f6120b",
            "e83abba8f2ff4d80a707e0ed2efd9795",
            "ece95aed2b8243949d34a831dc6eae38",
            "7d660b161f4e44369858d5974ea56544",
            "f8fcc4d6c62d40e99a41aa9a68fac1f0",
            "d05ce7eb97ed497a83cd30d5a7fb9ffb",
            "4ba3b063544f402da8cfc6676c5f93ea",
            "9c82099bdb3a4e68b9624bbc51075ad0",
            "124bc5fe6cfc4c0690a4e7fa878a5ed7",
            "3fb3ba212c7b44cdb2b6cd61f05d9ec0",
            "437586c8de6145d7b2cd0cc6a59438f2",
            "6bacdd45bffd4a69a020252a28bfa481",
            "9f2894184ccf4296a5c05812fd6f7492",
            "345f86f72f0e46a7a87b67574a0ad219",
            "0adcba36e2d3493aa3c7098f70b6d140",
            "efb257a1c65c451890a6113b0c32a65f",
            "28247701a79441fe98c5128073e4b119",
            "e438a600992f44208e261363a663e28e",
            "bf97d7bb016140648f441aa70d7dad79",
            "d12ea9b593364dfeb13366d397ca6133",
            "cb2109a7e867466abd03a4bf38da48fa",
            "40c3abdca2ac465db1c5981674dd9f4c",
            "384efec36e9c4477b2449496216b7681",
            "f4dc9eaf204f446786d2a0ee3f403caa",
            "8147a5afa72f43858edd8452f091504d",
            "a44f4dfc85a3495785994d334830a19e",
            "81ed3d82d57747169094f4425a6c4ace",
            "33ef2be3857444d5801d815f9af4b1f9",
            "25df0b21c934420ebf3d47cb9c830a0c",
            "0bdc61ce387a4f3eb100e9300f157e87",
            "c6c9deef60994709b5769e7b363de75d",
            "3184da41261549418572d09f15eae02a",
            "78142e3e971c461898362b30d7d1d4e8"
          ]
        },
        "outputId": "df77c1ad-796b-4751-edd4-04e20d7278ae"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/373 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d72e1585d9a4e34b925aa3b1ea7503e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/921 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa9a2b6ef0264f5a8eb73164a5f6120b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/33.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6bacdd45bffd4a69a020252a28bfa481"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "384efec36e9c4477b2449496216b7681"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text'],\n",
            "    num_rows: 10000\n",
            "})\n",
            "It is done, and submitted. You can play “Survival of the Tastiest” on Android, and on the web. Playi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tokenize_and_concatenate` is a useful function which takes our dataset of strings, and returns a dataset of token IDs ready to feed into the model. We then create a dataloader from this tokenized dataset. The useful method `train_test_split` can give us a training and testing set.\n"
      ],
      "metadata": {
        "id": "chj2r8J-njhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenize_and_concatenate(dataset, reference_gpt2.tokenizer, streaming=False, max_length=model.cfg.n_ctx, column_name=\"text\", add_bos_token=True, num_proc=4)\n",
        "\n",
        "dataset_dict = tokenized_dataset.train_test_split(test_size=1000)\n",
        "train_loader = DataLoader(dataset_dict[\"train\"], batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(dataset_dict[\"test\"], batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "mgogWcLUnk0U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "28ef4ce9b21c415aa3e6e0865f900063",
            "49b905bbefc14b7ba0c385fd08ab2adf",
            "26b7b9b0f99c45dcb93f8e226e5bf10d",
            "b67a1dc0475d4325ad96212e988087ea",
            "996f0d58fd9d43d5adda88f3fac355cb",
            "8f77e9bf736e49169c1b17ab3b031c1c",
            "0a309185dc784bbab59b283f1a9d5697",
            "0e2676ccaeac4d009ec1f4515d5b29c1",
            "5f655713978c4e61b390e24f3520d683",
            "b696f95d2d534106a778bd9f8df285e3",
            "6131e9aa8d4243e5aad58a6860aa25c0"
          ]
        },
        "outputId": "45dfa31b-ac9e-4b86-bb44-a0665faf24e9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28ef4ce9b21c415aa3e6e0865f900063"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (80023 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (101051 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (155995 > 1024). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (229134 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we iterate through these dataloaders, we will find dictionaries with the single key `'tokens'`, which maps to a tensor of token IDs with shape `(batch, seq_len)`."
      ],
      "metadata": {
        "id": "Fcx4oMaInlpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_batch = train_loader.dataset[:args.batch_size]\n",
        "\n",
        "print(first_batch.keys())\n",
        "print(first_batch['tokens'].shape)"
      ],
      "metadata": {
        "id": "Y_Y7vD8BnqK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4806eb82-df98-4dbd-d289-e39727fe7fbc"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['tokens'])\n",
            "torch.Size([16, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop\n",
        "\n",
        "If you did the material on [training loops](https://arena-ch0-fundamentals.streamlit.app/[0.3]_ResNets#training-loop) during the first week, this should all be familiar to you. If not, you can skim that section for an overview of the key concepts. The start of the **Training loop** section is most important, and the subsections on [Modularisation](https://arena-ch0-fundamentals.streamlit.app/[0.3]_ResNets#modularisation) and [dataclasses](https://arena-ch0-fundamentals.streamlit.app/[0.3]_ResNets#aside-dataclasses) are also very useful. Lastly, we'll also be using Weights and Biases to train our model - you can read about how to use it [here](https://arena-ch0-fundamentals.streamlit.app/[0.4]_Optimization#what-is-weights-and-biases). Here are (roughly) all the things you should know for the following exercises:\n",
        "                \n",
        "* The key parts of a gradient update step are:\n",
        "    * Calculating the (cross-entropy) loss between a model's output and the true labels,\n",
        "    * `loss.backward()` - calculate gradients of the loss with respect to the model parameters,\n",
        "    * `optimizer.step()` - update the model parameters using the gradients,\n",
        "    * `optimizer.zero_grad()` - zero the gradients so they don't accumulate.\n",
        "* We can nicely package up training loops into a class, which includes methods for training and validation steps among other things. This helps with writing code that can be reused in different contexts.\n",
        "* We can use dataclasses to store all the arguments relevant to training in one place, and then pass them to our trainer class. Autocompletion is one nice bonus of this!\n",
        "    * Be careful of scope here, you want to make sure you're referring to `self.args` within the trainer class, rather than the global `args`.\n",
        "* You can use Weights and Biases to track experiments and log relevant variables. The three essential functions are:\n",
        "    * `wandb.init()` - initialize a new run, takes arguments `project`, `name` and `config` (among others).\n",
        "    * `wandb.log()` - log a dictionary of variables, e.g. `{\"loss\": loss}`. Also takes a `step` argument.\n",
        "    * `wandb.finish()` - called at the end of training (no arguments)."
      ],
      "metadata": {
        "id": "hyjlKG-AnrZc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise - write training loop\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵🔵⚪\n",
        "\n",
        "You should spend up to 10-20 minutes on this exercise.\n",
        "```"
      ],
      "metadata": {
        "id": "tvM-W_TGnuoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should fill in the methods below. Some guidance:\n",
        "\n",
        "* Remember we were able to calculate cross entropy loss using the `get_log_probs` function in the previous section.\n",
        "* You should use the optimizer `t.optim.AdamW` (Adam with weight decay), and with hyperparameters `lr` and `weight_decay` taken from your `TransformerTrainingArgs` dataclass instance.\n",
        "* The easiest way to compute accuracy is to have the `validation_step` method return a 1D boolean tensor indicating the positions where the model's prediction was correct. Then you can concatenate all these tensors together and take the mean to get the overall accuracy for the epoch.\n",
        "* We've given you the argument `max_steps_per_epoch`, a hacky way of making sure the training phase in each epoch doesn't go on for too long. You can terminate each training phase after this many steps.\n",
        "* Remember to move tokens to your device, via `tokens.to(device)` (this should be a global variable, defined at the top of your notebook).\n",
        "* You can refer back to the training loops from the [previous chapter of the course](https://arena-ch0-fundamentals.streamlit.app/[0.3]_ResNets#training-loop) if you'd like.\n"
      ],
      "metadata": {
        "id": "2qbuJ4winvyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "gXfP9QU1pv2Y",
        "outputId": "9596014d-9047-44ca-93cd-863db740e298"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerTrainer:\n",
        "\tdef __init__(self, args: TransformerTrainingArgs, model: DemoTransformer):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.model = model\n",
        "\t\tself.args = args\n",
        "\t\tself.optimizer = t.optim.AdamW(self.model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "\t\tself.step = 0\n",
        "\n",
        "\n",
        "\tdef training_step(self, batch: Dict[str, Int[Tensor, \"batch seq\"]]) -> Float[Tensor, \"\"]:\n",
        "\t\t'''\n",
        "\t\tCalculates the loss on the tokens in the batch, performs a gradient update step, and logs the loss.\n",
        "\n",
        "\t\tRemember that `batch` is a dictionary with the single key 'tokens'.\n",
        "\t\t'''\n",
        "\t\ttokens = batch[\"tokens\"].to(device)\n",
        "\t\tlogits = self.model(tokens)\n",
        "\t\tloss = -get_log_probs(logits, tokens).mean()\n",
        "\t\tloss.backward()\n",
        "\t\tself.optimizer.step()\n",
        "\t\tself.optimizer.zero_grad()\n",
        "\t\tself.step += 1\n",
        "\t\twandb.log({\"loss\": loss }, self.step)\n",
        "\t\treturn loss\n",
        "\n",
        "\n",
        "\tdef validation_step(self, batch: Dict[str, Int[Tensor, \"batch seq\"]]):\n",
        "\t\t'''\n",
        "\t\tCalculates & returns the accuracy on the tokens in the batch (i.e. how often the model's prediction\n",
        "\t\tis correct). Logging should happen in the `train` function (after we've computed the accuracy for\n",
        "\t\tthe whole validation set).\n",
        "\t\t'''\n",
        "\t\ttokens = batch[\"tokens\"].to(device)\n",
        "\t\tlogits = self.model(tokens)\n",
        "\t\ttoken_predictions = logits[:, :-1].argmax(dim=-1)\n",
        "\t\taccuracies = (token_predictions == tokens[:, 1:]).flatten()\n",
        "\t\treturn accuracies\n",
        "\n",
        "\n",
        "\tdef train(self):\n",
        "\t\t'''\n",
        "\t\tTrains the model, for `self.args.epochs` epochs. Also handles wandb initialisation, and early stopping\n",
        "\t\tfor each epoch at `self.args.max_steps_per_epoch` steps.\n",
        "\t\t'''\n",
        "\t\twandb.init(project=self.args.wandb_project, name=self.args.wandb_name, config=self.args)\n",
        "\n",
        "\t\tfor epoch in range(self.args.epochs):\n",
        "\t\t\t\tfor i, batch in tqdm(enumerate(self.train_loader())):\n",
        "\t\t\t\t\t\tloss = self.training_step(batch)\n",
        "\t\t\t\t\t\tif i >= self.args.max_steps_per_epoch:\n",
        "\t\t\t\t\t\t\tbreak\n",
        "\n",
        "\t\t\t\tcorrect_predictions = t.concat([self.validation_step(batch) for batch in self.test_loader()])\n",
        "\t\t\t\taccuracy = correct_predictions.float().mean().item()\n",
        "\t\t\t\twandb.log({\"accuracy\": accuracy}, self.step)\n",
        "\n",
        "\t\twandb.finish()\n",
        "\n",
        "\n",
        "\tdef train_loader(self) -> DataLoader:\n",
        "\t\t'''Returns train loader (as in code above).'''\n",
        "\t\treturn DataLoader(dataset_dict[\"train\"], batch_size=self.args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "\n",
        "\tdef test_loader(self) -> DataLoader:\n",
        "\t\t'''Returns test loader (as in code above).'''\n",
        "\t\treturn DataLoader(dataset_dict[\"test\"], batch_size=self.args.batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "zVBEDTGMnxSk"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note - this section of the course used to use PyTorch Lightning, but this has now been taken out. You can see the old version of the training code which used PyTorch Lightning in the dropdown below.\n",
        "\n",
        "<details>\n",
        "<summary>PyTorch Lighting training loop</summary>\n",
        "\n",
        "```python\n",
        "class LitTransformer(pl.LightningModule):\n",
        "\tdef __init__(self, args: TransformerTrainingArgs, model: DemoTransformer, data_loader: DataLoader):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.model = model\n",
        "\t\tself.cfg = model.cfg\n",
        "\t\tself.args = args\n",
        "\t\tself.data_loader = data_loader\n",
        "\n",
        "\tdef forward(self, tokens: Int[Tensor, \"batch position\"]) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "\t\tlogits = self.model(tokens)\n",
        "\t\treturn logits\n",
        "\n",
        "\tdef training_step(self, batch: Dict[str, Tensor], batch_idx: int) -> Float[Tensor, \"\"]:\n",
        "\t\t'''\n",
        "\t\tHere you compute and return the training loss and some additional metrics for e.g.\n",
        "\t\tthe progress bar or logger.\n",
        "\t\t'''\n",
        "\t\ttokens = batch[\"tokens\"].to(device)\n",
        "\t\tlogits = self.model(tokens)\n",
        "\t\tloss = -get_log_probs(logits, tokens).mean()\n",
        "\t\tself.log(\"train_loss\", loss)\n",
        "\t\treturn loss\n",
        "\n",
        "\tdef configure_optimizers(self):\n",
        "\t\t'''\n",
        "\t\tChoose what optimizers and learning-rate schedulers to use in your optimization.\n",
        "\t\t'''\n",
        "\t\toptimizer = t.optim.AdamW(self.model.parameters(), lr=self.args.lr, weight_decay=self.args.weight_decay)\n",
        "\t\treturn optimizer\n",
        "\n",
        "\tdef train_dataloader(self):\n",
        "\t\treturn self.data_loader\n",
        "\n",
        "\n",
        "litmodel = LitTransformer(args, model, data_loader)\n",
        "logger = WandbLogger(save_dir=args.log_dir, project=args.log_name, name=args.run_name)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=args.max_epochs,\n",
        "    logger=logger,\n",
        "    log_every_n_steps=args.log_every_n_steps\n",
        ")\n",
        "trainer.fit(model=litmodel, train_dataloaders=litmodel.data_loader)\n",
        "wandb.finish()\n",
        "```\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "yvyAODwP3D8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DemoTransformer(model_cfg).to(device)\n",
        "args = TransformerTrainingArgs()\n",
        "trainer = TransformerTrainer(args, model)\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "nWJyh1lon0IH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7926d7fede854fd89577eb80224d5048",
            "b6322b8f7f1f4a3d900cdc258dc86b3c",
            "dea20381b20a4d3ea64d8ccee32131ea",
            "1453506db31b4d3a819709bbdbe210c5",
            "c81805aa41714f05bfcac791f1f6ee3d",
            "edfc917d6c84415493d97fab928b80f4",
            "a1269f018405470bb72a24deff1f9ee8",
            "171094401c5844b1bb3ad34cc3922150",
            "94760749ed664a36b80f7988189128af",
            "d062b825e8864d7cbe41a43bd1e9fcc5",
            "cedf1e21802d4fd4890d1183bb9f1c81",
            "4e19eca19aa942d7b802ce8c04df5523",
            "9ec83ff05ee84b0eb799282215a01c9b",
            "0b34a3fe895848e4a41d42eba37f95ad",
            "17f8abe5d82a44a8a47c55a37b4c7846",
            "5e449fc2c0e844bca5018559eac43532",
            "98d069ac707243f3a81dab579afeb106",
            "c77d8d00bbb0492994715a6b4750221d",
            "b9136da526d24f0fac5652df5578eee7",
            "de5a5bf19f60466ab08a0027794179e1",
            "9e80897daf6347f28acae6303ca2ca40",
            "a5517a2d54d340dc8da51dd1fc144468",
            "94200160ce0444f9a81720a3beae9c9a",
            "3efb1af563ff4d408187dce321beea79",
            "bf3a1fa415d04f3da1a4320c02291881",
            "97ec7ed3eb1c42d9bbede2d71ea9f0b4",
            "5fa0042fcee0461bb73cd2eb5ca1db06",
            "92d2efd1f3d34d4da4f3d52cffabdefa",
            "7f1171c55d6941f485f4502dfd5c83ef",
            "769296098eb94f22baceec56257cb48a",
            "d5d8c16fff9f47a4ba043699c22648d5",
            "afaa7f532fdb4baca258a396efb245e0",
            "c99c8854ec15452b9c949b7b1a7de6a4",
            "eb45fe1701404155bce598c83e457377",
            "6604442f4fdd459394f2c295af1b9634",
            "a10f752b0c0c44e8864d035c76f61fa2",
            "52d645051e7f4a29a59b51542360bb14",
            "c27dc2df75f04d38b4c10fdbbec60f8b",
            "41d1d0ca9dc84f689df1cb5332ad1c08",
            "6807a1a30f6842feae04ee097776477c",
            "3f51dbaf75c04167ab2b1bf916be0f76",
            "1932e287c73a484087aba1ef1fb9bcff",
            "61eee32878564a98b506d0a849b4e7dd",
            "11d00e2182464d87aaf2de45c8276590",
            "dc681ac5e1e7400f92bf9211b0b031e3",
            "2f25b4fdfb544d8b8fd9d77fa68c68cb",
            "709f66aa9e4049848d562f49d4aaa4be",
            "8c927a77f83d4b36951c757883f956c9",
            "67efd2d359d041c69df5886b8e7fe2f9",
            "c78679919c73408bbc406822b5424400",
            "e60a2086942d4a5197dab055d83598fa",
            "1b5279dce08c45ba963b3fadb13f2fdb",
            "75878d021c8e415eb6810e3c85e5929d",
            "bd9b54f374354a6f89af7d092fc1248e",
            "a5bbd8e921d34fe9a4ddb974a6bdfe97",
            "ca599287642f48a6b0c55c811b54f4c5",
            "78625a98f5ec4e28b8cb29aeb06692ba",
            "40903de06f99410fb4f58fa00b87c92b",
            "6d9d15a00e8e47e1a204491ad361b901",
            "5c13e9176d8b4001b2a4ffa1ced8c20d",
            "724841eff6b64b8385f3d89a019788b3",
            "b990a4132bb2454ea55c59c8da93cbfc",
            "37492c59a9744cd49271bb894d954072",
            "8a0cbc464e7645c2a91ce3cfbd502adf",
            "a0382ea97c5e4c9da9a7c679168e226c",
            "32a335f849794a3fad777ff5645c9ffb",
            "60d4d76a51fd47f294935b9974679d64",
            "5b912dcde5d54aa3b41e7266c46b88d2",
            "d07567f03b454fe5896bf4f7e96a92dd",
            "4dded80ea7274511b4528ad6a2990b60",
            "650d4af300614924ba2107db1beab67f",
            "ef941b53fad94ce28fefcecb68fa1650",
            "751cff796aea48d9838f1d9c0eebdf3b",
            "b9ba5544c51b4a8684728193ed0548c2",
            "577c1e810ce24a47b1dd3f855e64c11a",
            "7fac91a1e30a4d2699a2398dbd3cdef6",
            "2bef5b01a51e4b59a44a4e4b5402cc06",
            "3b067fa549c74a26b441827a82ce2420",
            "07a1460720b24e75b97bc2e9f5858d71",
            "6d6e3dd72f6d4d1abd9fbf2147de2b87",
            "ac9a19ce5ceb43a2b628e01918f56bb2",
            "af0fc46b6ee4456b98c1ea9090c00183",
            "f8732ee87c01409daac4cd61a770b469",
            "124c0311e583433fa5f6dee338aeba7c",
            "872bdf9b0c744899b5174c61495638b2",
            "52f4a2ca2605491c94805851659c0b93",
            "9ea81aa9f990447fab2e85138a05412d",
            "0c6494fa8515492da4c7c970f7d50edd",
            "06c3144945d6466cab3133f707c7fc0d",
            "5775e314a4fa4f37ab83fafa9bdfb3a0",
            "292b4c117c1d4d0fbd975124f1e8d755",
            "c1efb849e64c48ce8f33e362c20d60df",
            "2d3519369cb74a938f06a6c51e9343aa",
            "228d41c29fff46c0bab76dc7593f1a74",
            "289942ae5c904f94a94f6d5283a81019",
            "7a8b785e1b13432e9f5c018fa20bc096",
            "9df7f4547bfb41bf924561c9b8376c62",
            "9f84df62892e41c2ac4edfc8cb67b76b",
            "ae732c25b30b41fdb3d57a5dc90d9e58",
            "4bccb6a14b1d40749c97988b67846ac1",
            "c3afca0a20f54ecb9c0468f2d1365c33",
            "cc053d48d6b7492ba995b6dd97e20137",
            "0c74ed45c44246f8a7e88fe78e0eb791",
            "91fad78df4c842d69bd517c37b48d604",
            "bfdc04493b93464b8d1e204e4d550c79",
            "e11284081d564b1f9128d03094271e79",
            "f00c328728dc42b094f2cbcdf7bfb26f",
            "fdc5630a70e24324a263443d97320b33",
            "bdcf2ad740d2458aa6c97976dd4c3e54",
            "64f313bb95b74a56bc911f14ce8ba23a",
            "f45f53ffecc041949801c3fab91aed94",
            "a0b0428224ca4f4b8e4bf2b3728db265",
            "3fbbe364e2a54049818f1a174b1151f9",
            "cf32cb8844044455a7042732dac4f10d",
            "f694b6b364a24f838eff3d16bf221b69",
            "f94e2f5236b9442ea306509332970c2e",
            "14382120dae248558f2ac489ced4392e",
            "de5ad2cefa514591a0f18b9979c6f490",
            "05da2f71645a4d9ea1874258ce8b7898",
            "330b527af3324559a5d5715d7f7f098f",
            "145a5469fe624837b58733db02833299",
            "c62532321abb41bf8a44d9c22d4ec344",
            "a7f1aaeeeece46efafc168dfa7f44e94",
            "0b798ba92f4b46f4883d2045984f29fd",
            "2e0bd9d0dc11434c8e4d93335e2df74e",
            "8fa39bfb548f4213b1d58e5e8632e186"
          ]
        },
        "outputId": "4d34a4b0-968b-489e-bca3-7d24a1f1b19f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:oxizqbas) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.012 MB of 0.012 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7926d7fede854fd89577eb80224d5048"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">jumping-snowflake-1</strong> at: <a href='https://wandb.ai/gg2001/day1-demotransformer/runs/oxizqbas' target=\"_blank\">https://wandb.ai/gg2001/day1-demotransformer/runs/oxizqbas</a><br/> View project at: <a href='https://wandb.ai/gg2001/day1-demotransformer' target=\"_blank\">https://wandb.ai/gg2001/day1-demotransformer</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240903_072046-oxizqbas/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:oxizqbas). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/chapter1_transformer_interp/exercises/wandb/run-20240903_072112-cg0w362d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gg2001/day1-demotransformer/runs/cg0w362d' target=\"_blank\">honest-disco-2</a></strong> to <a href='https://wandb.ai/gg2001/day1-demotransformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/gg2001/day1-demotransformer' target=\"_blank\">https://wandb.ai/gg2001/day1-demotransformer</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/gg2001/day1-demotransformer/runs/cg0w362d' target=\"_blank\">https://wandb.ai/gg2001/day1-demotransformer/runs/cg0w362d</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94760749ed664a36b80f7988189128af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:20, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de5a5bf19f60466ab08a0027794179e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cdc949bdc60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cdc949bdc60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cdc949bdc60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7cdc949bdc60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1460, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5d8c16fff9f47a4ba043699c22648d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1932e287c73a484087aba1ef1fb9bcff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75878d021c8e415eb6810e3c85e5929d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a0cbc464e7645c2a91ce3cfbd502adf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "577c1e810ce24a47b1dd3f855e64c11a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [01:40, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52f4a2ca2605491c94805851659c0b93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9df7f4547bfb41bf924561c9b8376c62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdc5630a70e24324a263443d97320b33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.013 MB of 0.013 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05da2f71645a4d9ea1874258ce8b7898"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▅▆▇▇██</td></tr><tr><td>loss</td><td>█▇▅▅▅▅▃▅▄▃▄▂▂▄▄▂▄▄▃▂▃▂▃▂▃▂▃▃▄▂▂▄▃▁▂▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.27575</td></tr><tr><td>loss</td><td>5.22223</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">honest-disco-2</strong> at: <a href='https://wandb.ai/gg2001/day1-demotransformer/runs/cg0w362d' target=\"_blank\">https://wandb.ai/gg2001/day1-demotransformer/runs/cg0w362d</a><br/> View project at: <a href='https://wandb.ai/gg2001/day1-demotransformer' target=\"_blank\">https://wandb.ai/gg2001/day1-demotransformer</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240903_072112-cg0w362d/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you run the code for the first time, you'll have to login to Weights and Biases, and paste an API key into VSCode. After this is done, your Weights and Biases training run will start. It'll give you a lot of output text, one line of which will look like:\n",
        "\n",
        "```\n",
        "View run at https://wandb.ai/<USERNAME>/<PROJECT-NAME>/runs/<RUN-NAME>\n",
        "```\n",
        "\n",
        "which you can click on to visit the run page.\n",
        "\n",
        "> Note - to see the plots more clearly in Weights and Biases, you can click on the **edit panel** of your plot (the small pencil symbol at the top-right), then move the **smoothing** slider to the right."
      ],
      "metadata": {
        "id": "bypGwSMYn2Bl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A note on this loss curve (optional)\n",
        "\n",
        "\n",
        "What's up with the shape of our loss curve? It seems like we start at around 10-11, drops down very fast, but then levels out. It turns out, this is all to do with the kinds of algorithms the model learns during training.\n",
        "\n",
        "When it starts out, your model will be outputting random noise, which might look a lot like \"predict each token with approximately uniform probability\", i.e. $Q(x) = 1/d_\\text{vocab}$ for all $x$. This gives us a cross entropy loss of $\\log (d_\\text{vocab})$.\n",
        "\n"
      ],
      "metadata": {
        "id": "VLJL82W0oWzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d_vocab = model.cfg.d_vocab\n",
        "\n",
        "print(f\"d_vocab = {d_vocab}\")\n",
        "print(f\"Cross entropy loss on uniform distribution = {math.log(d_vocab)}\")"
      ],
      "metadata": {
        "id": "n0_NVezboOHw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cede6a3-cb90-4a3e-cc50-cfdd7ea74853"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_vocab = 50257\n",
            "Cross entropy loss on uniform distribution = 10.82490511970208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next thing we might expect the model to learn is the frequencies of words in the english language. After all, small common tokens like `\" and\"` or `\" the\"` might appear much more frequently than others. This would give us an average cross entropy loss of:\n",
        "\n",
        "$$\n",
        "- \\sum_x p_x \\log p_x\n",
        "$$\n",
        "\n",
        "where $p_x$ is the actual frequency of the word in our training data.\n",
        "\n",
        "We can evaluate this quantity as follows:"
      ],
      "metadata": {
        "id": "oLbVtVOYoQp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toks = tokenized_dataset[:][\"tokens\"].flatten()\n",
        "\n",
        "d_vocab = model.cfg.d_vocab\n",
        "freqs = t.bincount(toks, minlength=d_vocab)\n",
        "probs = freqs.float() / freqs.sum()\n",
        "\n",
        "distn = t.distributions.categorical.Categorical(probs=probs)\n",
        "entropy = distn.entropy()\n",
        "\n",
        "print(f\"Entropy of training data = {entropy}\")"
      ],
      "metadata": {
        "id": "PYLIco76oSeX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae6cc36-a70e-404b-ccdc-df95262b1273"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entropy of training data = 7.349369525909424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After unigram frequencies, the next thing our model usually learns is **bigram frequencies** (i.e. the frequency of pairs of adjacent tokens in the training data). For instance, `\"I\"` and `\" am\"` are common tokens, but their bigram frequency is much higher than it would be if they occurred independently. Bigram frequencies actually take you pretty far, since they also help with:\n",
        "\n",
        "* Some simple grammatical rules (e.g. a full stop being followed by a capitalized word)\n",
        "* Weird quirks of tokenization (e.g. `\" manip\"` being followed by `\"ulative\"`)\n",
        "* Common names (e.g. `\"Barack\"` being followed by `\" Obama\"`)\n",
        "\n",
        "\n",
        "After approximating bigram frequencies, we need to start using smarter techniques, like trigrams (which can only be implemented using attention heads), **induction heads** (which we'll learn a lot more about in the next set of exercises!), and fact memorization or more basic grammar and syntax rules. Marginal improvement starts getting a lot harder around here, leading to a flattening of our loss curve."
      ],
      "metadata": {
        "id": "cQwiLxr6oUUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise (optional) - log completions\n",
        "\n",
        "*Note - you might want to come back to this exercise after you understand how sampling works.*\n",
        "\n",
        "Choose a handle of prompts, and log the model's completions on those sentences. We recommend you do this with a lower frequency than loss is logged (e.g. once every 10-100 batches).\n",
        "\n",
        "The `wandb` syntax for logging text is pretty simple. Firstly, you can just print output as stdout and this is also logged to Weights & Biases (you can find it under the \"Logs\" section of your run). Alternatively, you can log data in the form of a table, and have it appear next to your other charts:\n",
        "\n",
        "```python\n",
        "wandb.log({\"completions_table\": wandb.Table(\n",
        "    data = data,\n",
        "    columns = [\"epoch\", \"step\", \"text\"]\n",
        ")})\n",
        "```\n",
        "\n",
        "where `data` is a list of length-3 lists, with each list containing (epoch, step, text). If you choose this option, we recommend logging the table less frequently than you're sampling from the model, to make sure you're not sending too much data (because unfortunately wandb doesn't have methods to incrementally update the table during logging).\n",
        "\n",
        "If you want to try this before going through the sampling exercises (which are quite long!), you can use the code below to sample output from the model. Note that the `TransformerSampler` object is already in inference mode, so you don't need to worry about this."
      ],
      "metadata": {
        "id": "pA0KyYuAvs8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling_fn(model: DemoTransformer, prompt: str) -> str:\n",
        "    sampler = solutions.TransformerSampler(model, reference_gpt2.tokenizer)\n",
        "    output = sampler.sample(prompt, temperature=0.7, top_p=0.95, max_tokens_generated=16)\n",
        "    return output\n",
        "\n",
        "model = DemoTransformer(model_cfg).to(device)\n",
        "\n",
        "# Should be entirely random, because it uses a newly initialized model\n",
        "print(sampling_fn(model, prompt=\"John and Mary went to the\"))"
      ],
      "metadata": {
        "id": "-GVOVlqHvuh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97d9651-5f28-407d-98bc-1c4722208de2"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John and Mary went to the Frequency 366 Bowser lett delegate Dee BarronSupplementaran unlawfulEveryone confidently ceases nightmare preferring Marxism\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE - rewrite train function, using text logging"
      ],
      "metadata": {
        "id": "3WeGuzYkvu2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You shouldn't expect to see perfect logical coherence from your model, but you should at least see that it respects basic word frequencies, and follows basic rules of grammar some of the time. Hopefully this gives some perspective on how difficult training a transformer can be!"
      ],
      "metadata": {
        "id": "YtqvYaxmwTi7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrSd3-YnfHN9"
      },
      "source": [
        "# 4️⃣ Sampling from a Transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdezwBEFfHN9"
      },
      "source": [
        "> ##### Learning objectives\n",
        ">\n",
        "> * Learn how to sample from a transformer\n",
        ">     * This includes basic methods like greedy search or top-k, and more advanced methods like beam search\n",
        "> * Learn how to cache the output of a transformer, so that it can be used to generate text more efficiently\n",
        ">     * Optionally, rewrite your sampling functions to make use of your caching methods\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7C6E0bFfHN9"
      },
      "source": [
        "One obvious method to sample tokens from a distribution would be to always take the token assigned the highest probability. But this can lead to some boring and repetitive outcomes, and at worst it can lock our transformer's output into a loop.\n",
        "\n",
        "First, you should read HuggingFace's blog post [How to generate text: using different decoding methods for language generation with Transformers](https://huggingface.co/blog/how-to-generate).\n",
        "\n",
        "Once you've done that, you can work through the `TransformerSampler` class below, and implement the different sampling methods. Each method will come with its own tests, and demo code for you to run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "aviyrTWefHN9"
      },
      "outputs": [],
      "source": [
        "model_cfg = Config()\n",
        "model = DemoTransformer(model_cfg).to(device)\n",
        "model.load_state_dict(reference_gpt2.state_dict(), strict=False)\n",
        "\n",
        "tokenizer = reference_gpt2.tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "4p1szCj1fHN9"
      },
      "outputs": [],
      "source": [
        "class TransformerSampler:\n",
        "\n",
        "    def __init__(self, model: DemoTransformer, tokenizer: GPT2TokenizerFast):\n",
        "        self.model = model\n",
        "        self.cfg = model.cfg\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def sample(self, prompt: str, max_tokens_generated=100, verbose=False, **kwargs):\n",
        "        '''\n",
        "        Returns a string of autoregressively generated text, starting from the prompt.\n",
        "\n",
        "        Sampling terminates at max_tokens_generated, or when the model generates an\n",
        "        end-of-sequence token.\n",
        "\n",
        "        kwargs are passed to sample_next_token, to give detailed instructions on how\n",
        "        new tokens are chosen.\n",
        "        '''\n",
        "        self.model.eval()\n",
        "        input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)[0]\n",
        "\n",
        "        for i in range(max_tokens_generated):\n",
        "            # Get new logits (make sure we don't pass in more tokens than the model's context length)\n",
        "            logits = self.model(input_ids[None, -self.cfg.n_ctx:])\n",
        "            # We only take logits for the last token, because this is what we're sampling\n",
        "            logits = logits[0, -1]\n",
        "            # Get next token (as a tensor of size (1, 1) so we can concat it to input_ids)\n",
        "            next_token = t.tensor([TransformerSampler.sample_next_token(input_ids, logits, **kwargs)], device=device)\n",
        "            # Create new input ids string, with shape (1, old_seq_len + 1)\n",
        "            input_ids = t.cat([input_ids, next_token], dim=-1)\n",
        "            # Print out results, if required\n",
        "            if verbose:\n",
        "                print(self.tokenizer.decode(input_ids), end=\"\\r\")\n",
        "            # If our new token was the end-of-text token, stop\n",
        "            if next_token == getattr(self.tokenizer, \"eos_token_id\", None):\n",
        "                break\n",
        "\n",
        "        return self.tokenizer.decode(input_ids)\n",
        "\n",
        "\n",
        "    @t.inference_mode()\n",
        "    def beam_search(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        num_return_sequences: int,\n",
        "        num_beams: int,\n",
        "        max_new_tokens: int,\n",
        "        no_repeat_ngram_size: int = 0,\n",
        "        verbose=False\n",
        "    ) -> List[Tuple[float, t.Tensor]]:\n",
        "        '''\n",
        "        Returns a string of autoregressively generated text, starting from the prompt.\n",
        "\n",
        "        Sampling terminates at max_tokens_generated, or when the model generates an\n",
        "        end-of-sequence token.\n",
        "\n",
        "        kwargs are passed to sample_next_token, to give detailed instructions on how\n",
        "        new tokens are chosen.\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_next_token(\n",
        "        input_ids: Int[Tensor, \"seq_len\"],\n",
        "        logits: Float[Tensor, \"seq_len d_vocab\"],\n",
        "        temperature=1.0,\n",
        "        top_k=0,\n",
        "        top_p=0.0,\n",
        "        frequency_penalty=0.0,\n",
        "        seed=None\n",
        "    ):\n",
        "        assert input_ids.ndim == 1, \"input_ids should be a 1D sequence of token ids\"\n",
        "        assert temperature >= 0, \"Temperature should be non-negative\"\n",
        "        assert 0 <= top_p <= 1.0, \"Top-p must be a probability\"\n",
        "        assert 0 <= top_k, \"Top-k must be non-negative\"\n",
        "        assert not (top_p != 0 and top_k != 0), \"At most one of top-p and top-k supported\"\n",
        "\n",
        "        # Set random seeds for reproducibility\n",
        "        if seed is not None:\n",
        "            t.manual_seed(seed)\n",
        "            np.random.seed(seed)\n",
        "\n",
        "        # Apply all the specialized sampling methods\n",
        "        if temperature == 0:\n",
        "            return TransformerSampler.greedy_search(logits)\n",
        "        elif temperature != 1.0:\n",
        "            logits = TransformerSampler.apply_temperature(logits, temperature)\n",
        "        if frequency_penalty != 0.0:\n",
        "            logits = TransformerSampler.apply_frequency_penalty(input_ids, logits, frequency_penalty)\n",
        "        if top_k > 0:\n",
        "            return TransformerSampler.sample_top_k(logits, top_k)\n",
        "        if top_p > 0.0:\n",
        "            return TransformerSampler.sample_top_p(logits, top_p)\n",
        "        return TransformerSampler.sample_basic(logits)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def greedy_search(logits: Float[Tensor, \"d_vocab\"]) -> int:\n",
        "        '''\n",
        "        Returns the most likely token (as an int).\n",
        "        '''\n",
        "        out = logits.argmax().item()\n",
        "        return out\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_temperature(logits: Float[Tensor, \"d_vocab\"], temperature: float) -> Float[Tensor, \"d_vocab\"]:\n",
        "        '''\n",
        "        Applies temperature scaling to the logits.\n",
        "        '''\n",
        "        return logits / temperature\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_frequency_penalty(input_ids: Int[Tensor, \"seq_len\"], logits: Float[Tensor, \"d_vocab\"], freq_penalty: float) -> Float[Tensor, \"d_vocab\"]:\n",
        "        '''\n",
        "        Applies a frequency penalty to the logits.\n",
        "        '''\n",
        "        d_vocab = logits.size(0)\n",
        "        id_freqs = t.bincount(input_ids, minlength=d_vocab)\n",
        "        return logits - freq_penalty * id_freqs\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_basic(logits: Float[Tensor, \"d_vocab\"]) -> int:\n",
        "        '''\n",
        "        Samples from the distribution defined by the logits.\n",
        "        '''\n",
        "        sampled_token = t.distributions.categorical.Categorical(logits=logits).sample()\n",
        "        return sampled_token.item()\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_top_k(logits: Float[Tensor, \"d_vocab\"], k: int) -> int:\n",
        "        '''\n",
        "        Samples from the top k most likely tokens.\n",
        "        '''\n",
        "        top_k_logits, top_k_token_ids = logits.topk(k)\n",
        "        # Get sampled token (which is an index corresponding to the list of top-k tokens)\n",
        "        sampled_token_idx = t.distributions.categorical.Categorical(logits=top_k_logits).sample()\n",
        "        # Get the actual token id, as an int\n",
        "        return top_k_token_ids[sampled_token_idx].item()\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def sample_top_p(logits: Float[Tensor, \"d_vocab\"], top_p: float, min_tokens_to_keep: int = 1) -> int:\n",
        "        '''\n",
        "        Samples from the most likely tokens which make up at least p cumulative probability.\n",
        "        '''\n",
        "        # Sort logits, and get cumulative probabilities\n",
        "        logits_sorted, indices = logits.sort(descending=True, stable=True)\n",
        "        cumul_probs = logits_sorted.softmax(-1).cumsum(-1)\n",
        "        # Choose which tokens to keep, in the set we sample from\n",
        "        n_keep = t.searchsorted(cumul_probs, top_p, side=\"left\").item() + 1\n",
        "        n_keep = max(n_keep, min_tokens_to_keep)\n",
        "        keep_idx = indices[:n_keep]\n",
        "        keep_logits = logits[keep_idx]\n",
        "        # Perform the sampling\n",
        "        sample = t.distributions.categorical.Categorical(logits=keep_logits).sample()\n",
        "        return keep_idx[sample].item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwA5ge9KfHN9"
      },
      "source": [
        "## Main Sampling Function\n",
        "\n",
        "The first thing you should do is implement the `sample` method.\n",
        "\n",
        "### Exercise - implement `sample`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵🔵🔵⚪⚪\n",
        "\n",
        "You should spend up to 20-25 minutes on this exercise.\n",
        "```\n",
        "\n",
        "This function takes in a prompt (in the form of a string), encodes it as a sequence of token ids using `self.tokenizer.encode`, and then continually generates new tokens by repeating the following steps:\n",
        "\n",
        "1. Passing the tokenized prompt through the model to get logits,\n",
        "2. Taking the logit vector corresponding to the last token in the prompt (i.e. the prediction for the *next* token),\n",
        "3. Sampling from this distribution to get a new token, using `self.sample_next_token(input_ids, logits, **kwargs)` (here, `kwargs` contains all the sampling-specific arguments, e.g. temperature, top-k, etc.),\n",
        "4. Appending this new token to the input tokens, and repeating the process until we meet one of two termination critera:\n",
        "    * We generate `max_tokens_generated` new tokens, or\n",
        "    * We generate the end-of-sequence token (which we can access via `self.tokenizer.eos_token_id`).\n",
        "\n",
        "Finally, we use `self.tokenizer.decode` to convert the generated token ids back into a string, and return this string.\n",
        "\n",
        "We also have a `verbose` argument - when this is true you can print your output while it's being sampled.\n",
        "\n",
        "Below is some code which tests your sampling function by performing greedy sampling (which means always choosing the most likely next token at each step).\n",
        "\n",
        "<details>\n",
        "<summary>Why does <code>temperature=0.0</code> correspond to greedy sampling?</summary>\n",
        "\n",
        "To apply a temperature to our sampling (as we'll see later) means to scale all logits by `(1 / temperature)`. The basic intuition here is:\n",
        "\n",
        "* A higher temperature means a smaller scale factor, so the logits all approach zero, i.e. uniform distribution, and the sampling process is a lot more random (producing more diverse and varied outputs)\n",
        "* A lower temperature means a larger scale factor, so the logits all approach infinity, i.e. a dirac delta function, and the sampling process is a lot more deterministic (producing less varied output)\n",
        "\n",
        "As temperature gets close to zero, the difference between the largest logit and second largest logit becomes very large, so the distribution tends to \"probability of 1 on the highest-likelihood token\", i.e. greedy sampling. You can derive this formally if you prefer.\n",
        "</details>\n",
        "\n",
        "A few hints:\n",
        "\n",
        "* Don't forget about tensor shapes! Your model's input should always have a batch dimension, i.e. it should be shape `(1, seq_len)`.\n",
        "* The `sample_next_token` method will return an integer, so make sure you wrap this in a tensor before concatenating it to the end of your input IDs.\n",
        "* Also remember to have your tensors be on the same device (we have a global `device` variable).\n",
        "* Remember to put your model in evaluation mode, using `model.eval()`.\n",
        "\n",
        "To be clear - the idea is for you to implement the `sample` method of the `TransformerSampler` class; you can do this by either editing the class definition directly or (if you want to avoid scrolling) define the `sample` function outside the class and then assign it via `TransformerSampler.sample = sample`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "loDmpBfmfHN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3caa3f-124b-40e1-fe9b-99d73a467c7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy decoding with prompt: 'Jingle bells, jingle bells, jingle all the way'\n",
            "\n",
            "Your model said: 'Jingle bells, jingle bells, jingle all the way up to the top of the mountain.'\n",
            "\n",
            "Tests passed!\n"
          ]
        }
      ],
      "source": [
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "prompt = \"Jingle bells, jingle bells, jingle all the way\"\n",
        "print(f\"Greedy decoding with prompt: {prompt!r}\\n\")\n",
        "\n",
        "output = sampler.sample(prompt, max_tokens_generated=8, temperature=0.0)\n",
        "print(f\"Your model said: {output!r}\\n\")\n",
        "\n",
        "expected = \"Jingle bells, jingle bells, jingle all the way up to the top of the mountain.\"\n",
        "assert output == expected\n",
        "\n",
        "print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIx0p0MlfHN-"
      },
      "source": [
        "## Sampling with Categorical\n",
        "\n",
        "Now, we'll move into implementing specific sampling methods.\n",
        "\n",
        "PyTorch provides a [`distributions` package](https://pytorch.org/docs/stable/distributions.html#distribution) with a number of convenient methods for sampling from various distributions.\n",
        "\n",
        "For now, we just need [`t.distributions.categorical.Categorical`](https://pytorch.org/docs/stable/distributions.html#categorical). Use this to implement `sample_basic`, which just samples from the provided logits (which may have already been modified by the temperature and frequency penalties).\n",
        "\n",
        "Note that this will be slow since we aren't batching the samples, but don't worry about speed for now.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLjEUGqZfHN-"
      },
      "source": [
        "### Exercise - Basic Sampling\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵🔵⚪⚪⚪\n",
        "\n",
        "You should spend up to 5-10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Implement basic sampling in the `TransformerSampler` class above, then run the code below to verify your solution works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "cSA2Sr0FfHN-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "491bfb6e5af9436bb13e37b9c1766696",
            "573d9c61361a439080c8771b3f618986",
            "ae843ad5499d42f88590bcf62179dbeb",
            "a7f739e148c64a17b0689490feb0c008",
            "1f527c21f1d443918238d29e62d949eb",
            "576f6e8d3e2345e3bba0388cef413a3f",
            "b98eb738b2514fdb81606496ac6372b5",
            "fa003e1f8fbb4369a04df0f69480e32e",
            "d94e4fd9865442748b5b3af7ae554bcc",
            "ed756de6b7f3417c9c2c2d2da1c00158",
            "9cee96f0a68b440f9c39fb26991da2cc"
          ]
        },
        "outputId": "4f438b9f-4547-40ce-ca39-996fe82eed6f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "491bfb6e5af9436bb13e37b9c1766696"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: ' church'. Expected freq 0.0648, observed freq 0.0633\n",
            "Word: ' house' . Expected freq 0.0367, observed freq 0.0367\n",
            "Word: ' temple'. Expected freq 0.0145, observed freq 0.0130\n",
            "Word: ' same'  . Expected freq 0.0104, observed freq 0.0109\n",
            "Word: ' Church'. Expected freq 0.0097, observed freq 0.0095\n",
            "Tests passed!\n"
          ]
        }
      ],
      "source": [
        "prompt = \"John and Mary went to the\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "logits = model(input_ids)[0, -1]\n",
        "\n",
        "expected_top_5 = {\n",
        "    \" church\": 0.0648,\n",
        "    \" house\": 0.0367,\n",
        "    \" temple\": 0.0145,\n",
        "    \" same\": 0.0104,\n",
        "    \" Church\": 0.0097\n",
        "}\n",
        "frequency_of_top_5 = defaultdict(int)\n",
        "\n",
        "N = 10_000\n",
        "for _ in tqdm(range(N)):\n",
        "    token = TransformerSampler.sample_next_token(input_ids.squeeze(), logits)\n",
        "    frequency_of_top_5[tokenizer.decode(token)] += 1\n",
        "\n",
        "for word in expected_top_5:\n",
        "    expected_freq = expected_top_5[word]\n",
        "    observed_freq = frequency_of_top_5[word] / N\n",
        "    print(f\"Word: {word!r:<9}. Expected freq {expected_freq:.4f}, observed freq {observed_freq:.4f}\")\n",
        "    assert abs(observed_freq - expected_freq) < 0.01, \"Try increasing N if this fails by a small amount.\"\n",
        "\n",
        "print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXLHfTYzfHN-"
      },
      "source": [
        "### Exercise - Temperature\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴⚪⚪⚪⚪\n",
        "Importance: 🔵🔵⚪⚪⚪\n",
        "\n",
        "You should spend up to 5-10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Temperature sounds fancy, but it's literally just dividing the logits by the temperature. You should implement this in your `TransformerSampler` class now.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "wph7hgyMfHN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea90c7b5-3f4d-4817-88c2-bcf17fb3be20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A low temperature \"sharpens\" or \"peaks\" the distribution:  tensor([  0.0000, 693.1472])\n",
            "A high temperature flattens the distribution:  tensor([0.0000, 0.0007])\n",
            "Tests passed!\n"
          ]
        }
      ],
      "source": [
        "logits = t.tensor([1, 2]).log()\n",
        "\n",
        "cold_logits = TransformerSampler.apply_temperature(logits, temperature=0.001)\n",
        "print('A low temperature \"sharpens\" or \"peaks\" the distribution: ', cold_logits)\n",
        "t.testing.assert_close(cold_logits, 1000.0 * logits)\n",
        "\n",
        "hot_logits = TransformerSampler.apply_temperature(logits, temperature=1000.0)\n",
        "print(\"A high temperature flattens the distribution: \", hot_logits)\n",
        "t.testing.assert_close(hot_logits, 0.001 * logits)\n",
        "\n",
        "print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSf7Ipi1fHN-"
      },
      "source": [
        "<details>\n",
        "<summary>Question - what is the limit of applying 'sample_basic' after adjusting with temperature, when temperature goes to zero? How about when temperature goes to infinity?</summary>\n",
        "\n",
        "The limit when temperature goes to zero is greedy search (because dividing by a small number makes the logits very big, in other words the difference between the maximum logit one and all the others will grow).\n",
        "\n",
        "The limit when temperature goes to infinity is uniform random sampling over all words (because all logits will be pushed towards zero).\")\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8H7_bF-fHN_"
      },
      "source": [
        "### Exercise - Frequency Penalty\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵⚪⚪⚪⚪\n",
        "\n",
        "You should spend up to 10-15 minutes on this exercise.\n",
        "```\n",
        "\n",
        "The frequency penalty is simple as well: count the number of occurrences of each token, then subtract `freq_penalty` for each occurrence. Hint: use `t.bincount` (documentation [here](https://pytorch.org/docs/stable/generated/torch.bincount.html)) to do this in a vectorized way.\n",
        "\n",
        "You should implement the `apply_frequency_penalty` method in your `TransformerSampler` class now, then run the cell below to check your solution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i5tF4StfHN_"
      },
      "source": [
        "<details>\n",
        "<summary>Help - I'm getting a <code>RuntimeError</code>; my tensor sizes don't match.</summary>\n",
        "\n",
        "Look at the documentation page for `t.bincount`. You might need to use the `minlength` argument - why?\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "y9A7LdixfHN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63f7675-1326-4fd6-aa45-0314eeec2a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tests passed!\n"
          ]
        }
      ],
      "source": [
        "bieber_prompt = \"And I was like Baby, baby, baby, oh Like, Baby, baby, baby, no Like, Baby, baby, baby, oh I thought you'd always be mine, mine\"\n",
        "input_ids = tokenizer.encode(bieber_prompt, return_tensors=\"pt\")\n",
        "logits = t.ones(tokenizer.vocab_size)\n",
        "penalized_logits = TransformerSampler.apply_frequency_penalty(input_ids.squeeze(), logits, 2.0)\n",
        "\n",
        "assert penalized_logits[5156].item() == -11, \"Expected 6 occurrences of ' baby' with leading space, 1-2*6=-11\"\n",
        "assert penalized_logits[14801].item() == -5, \"Expected 3 occurrences of ' Baby' with leading space, 1-2*3=-5\"\n",
        "\n",
        "print(\"Tests passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuNpoR3CfHN_"
      },
      "source": [
        "### Sampling - Manual Testing\n",
        "\n",
        "Run the below cell to get a sense for the `temperature` and `freq_penalty` arguments. Play with your own prompt and try other values.\n",
        "\n",
        "Note: your model can generate newlines or non-printing characters, so calling `print` on generated text sometimes looks awkward on screen. You can call `repr` on the string before printing to have the string escaped nicely.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "owibsBUjfHN_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "7ea3dd51-168f-49c9-bc0b-9b5fad1453fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[3m                                             Sampling - Manual Testing                                             \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mName                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mKwargs                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput                                                  \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ High freq penalty     │ {'frequency_penalty': 100.0} │ 'Jingle bells, jingle bells, jingle all the way to       │\n",
              "│                       │                              │ Jackson. That\\'s Alex.\"\\n-- Mike McCoy Ekman Longhorn at │\n",
              "│                       │                              │ Frazier McG and Joe Mcciah Quinn'                        │\n",
              "│                       │                              │                                                          │\n",
              "│ Negative freq penalty │ {'frequency_penalty': -3.0}  │ 'Jingle bells, jingle bells, jingle all the way, jingle, │\n",
              "│                       │                              │ jingle, jingle, jingle, jingle, jingle, jingle, jingle'  │\n",
              "│                       │                              │                                                          │\n",
              "│ Too hot!              │ {'temperature': 2.0}         │ \"Jingle bells, jingle bells, jingle all the way along    │\n",
              "│                       │                              │ team Picard Tosh3G 'ats http://442related ceasefireAll   │\n",
              "│                       │                              │ Thy posNAS SDK dubbed kings niAMS awakeFacebook\"         │\n",
              "│                       │                              │                                                          │\n",
              "│ Pleasantly cool       │ {'temperature': 0.7}         │ 'Jingle bells, jingle bells, jingle all the way…\"\\n\\n\"I  │\n",
              "│                       │                              │ got a lot of fun in the beginning in the beginning,\" he  │\n",
              "│                       │                              │ added. \"I could get'                                     │\n",
              "│                       │                              │                                                          │\n",
              "│ Pleasantly warm       │ {'temperature': 0.9}         │ 'Jingle bells, jingle bells, jingle all the way. But it  │\n",
              "│                       │                              │ was an audacious project, it never got off the ground.   │\n",
              "│                       │                              │ And that is one of the things he'                        │\n",
              "│                       │                              │                                                          │\n",
              "│ Too cold!             │ {'temperature': 0.01}        │ 'Jingle bells, jingle bells, jingle all the way up to    │\n",
              "│                       │                              │ the top of the mountain.\\n\\nThe first time I saw the     │\n",
              "│                       │                              │ mountain, I was in the middle of'                        │\n",
              "│                       │                              │                                                          │\n",
              "└───────────────────────┴──────────────────────────────┴──────────────────────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                             Sampling - Manual Testing                                             </span>\n",
              "┏━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Name                  </span>┃<span style=\"font-weight: bold\"> Kwargs                       </span>┃<span style=\"font-weight: bold\"> Output                                                   </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ High freq penalty     │ {'frequency_penalty': 100.0} │ 'Jingle bells, jingle bells, jingle all the way to       │\n",
              "│                       │                              │ Jackson. That\\'s Alex.\"\\n-- Mike McCoy Ekman Longhorn at │\n",
              "│                       │                              │ Frazier McG and Joe Mcciah Quinn'                        │\n",
              "│                       │                              │                                                          │\n",
              "│ Negative freq penalty │ {'frequency_penalty': -3.0}  │ 'Jingle bells, jingle bells, jingle all the way, jingle, │\n",
              "│                       │                              │ jingle, jingle, jingle, jingle, jingle, jingle, jingle'  │\n",
              "│                       │                              │                                                          │\n",
              "│ Too hot!              │ {'temperature': 2.0}         │ \"Jingle bells, jingle bells, jingle all the way along    │\n",
              "│                       │                              │ team Picard Tosh3G 'ats http://442related ceasefireAll   │\n",
              "│                       │                              │ Thy posNAS SDK dubbed kings niAMS awakeFacebook\"         │\n",
              "│                       │                              │                                                          │\n",
              "│ Pleasantly cool       │ {'temperature': 0.7}         │ 'Jingle bells, jingle bells, jingle all the way…\"\\n\\n\"I  │\n",
              "│                       │                              │ got a lot of fun in the beginning in the beginning,\" he  │\n",
              "│                       │                              │ added. \"I could get'                                     │\n",
              "│                       │                              │                                                          │\n",
              "│ Pleasantly warm       │ {'temperature': 0.9}         │ 'Jingle bells, jingle bells, jingle all the way. But it  │\n",
              "│                       │                              │ was an audacious project, it never got off the ground.   │\n",
              "│                       │                              │ And that is one of the things he'                        │\n",
              "│                       │                              │                                                          │\n",
              "│ Too cold!             │ {'temperature': 0.01}        │ 'Jingle bells, jingle bells, jingle all the way up to    │\n",
              "│                       │                              │ the top of the mountain.\\n\\nThe first time I saw the     │\n",
              "│                       │                              │ mountain, I was in the middle of'                        │\n",
              "│                       │                              │                                                          │\n",
              "└───────────────────────┴──────────────────────────────┴──────────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "N_RUNS = 1\n",
        "your_prompt = \"Jingle bells, jingle bells, jingle all the way\"\n",
        "cases = [\n",
        "    (\"High freq penalty\", dict(frequency_penalty=100.0)),\n",
        "    (\"Negative freq penalty\", dict(frequency_penalty=-3.0)),\n",
        "    (\"Too hot!\", dict(temperature=2.0)),\n",
        "    (\"Pleasantly cool\", dict(temperature=0.7)),\n",
        "    (\"Pleasantly warm\", dict(temperature=0.9)),\n",
        "    (\"Too cold!\", dict(temperature=0.01)),\n",
        "]\n",
        "\n",
        "table = Table(\"Name\", \"Kwargs\", \"Output\", title=\"Sampling - Manual Testing\")\n",
        "\n",
        "for (name, kwargs) in cases:\n",
        "    for i in range(N_RUNS):\n",
        "        output = sampler.sample(your_prompt, max_tokens_generated=24, **kwargs)\n",
        "        table.add_row(name, repr(kwargs), repr(output) + \"\\n\")\n",
        "\n",
        "rprint(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9fFSMW7fHN_"
      },
      "source": [
        "## Top-K Sampling\n",
        "\n",
        "Conceptually, the steps in top-k sampling are:\n",
        "- Find the `top_k` largest probabilities (you can use [`torch.topk`](https://pytorch.org/docs/stable/generated/torch.topk.html))\n",
        "- Set all other probabilities to zero\n",
        "- Normalize and sample\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0hBDuz4fHN_"
      },
      "source": [
        "### Exercise - implement `sample_top_k`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴⚪⚪⚪\n",
        "Importance: 🔵⚪⚪⚪⚪\n",
        "\n",
        "You should spend up to 5-10 minutes on this exercise.\n",
        "```\n",
        "\n",
        "Implement the method `sample_top_k` now. Your implementation should stay in log-space throughout (don't exponentiate to obtain probabilities). This means you don't actually need to worry about normalizing, because `Categorical` accepts unnormalised logits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "HocllGE0fHN_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "34749aecba9f4a98964c3249e76c35ee",
            "5cf4fd6ab45143a7916ab3db5ead253a",
            "26b1684235c740b2a14305b204c59e99",
            "d2f9e65a424645b8a462d6770d3c06ca",
            "6880ca25130b40b8a63ae39683f5e88b",
            "84e939766cc143c89fcaff29c39af2bf",
            "c0206ec395cd462fb38a24892727d8b9",
            "f7637a8abd774cbcb6ea74da5dcfa84d",
            "46e681775bd24bad8fdb57eeecb8b8ce",
            "7b26b11a90d24958bd3db639ca5b0aff",
            "f9d0d1acb557461a88b8ba4865390323"
          ]
        },
        "outputId": "cd0a3c61-1f5a-4220-dccb-daa756b981fd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34749aecba9f4a98964c3249e76c35ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: ' church'. Expected freq = 0.4761, observed freq = 0.4720\n",
            "Word: ' house' . Expected freq = 0.2697, observed freq = 0.2741\n",
            "Word: ' temple'. Expected freq = 0.1065, observed freq = 0.1101\n",
            "Word: ' same'  . Expected freq = 0.0764, observed freq = 0.0745\n",
            "Word: ' Church'. Expected freq = 0.0713, observed freq = 0.0693\n"
          ]
        }
      ],
      "source": [
        "prompt = \"John and Mary went to the\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "logits = model(input_ids)[0, -1]\n",
        "\n",
        "expected_top_5 = {\n",
        "    \" church\": 0.0648,\n",
        "    \" house\": 0.0367,\n",
        "    \" temple\": 0.0145,\n",
        "    \" same\": 0.0104,\n",
        "    \" Church\": 0.0097\n",
        "}\n",
        "topk_5_sum = sum(expected_top_5.values())\n",
        "\n",
        "observed_freqs = defaultdict(int)\n",
        "\n",
        "N = 10000\n",
        "for _ in tqdm(range(N)):\n",
        "    token = TransformerSampler.sample_next_token(input_ids.squeeze(), logits, top_k=5)\n",
        "    observed_freqs[tokenizer.decode(token)] += 1\n",
        "\n",
        "for word in expected_top_5:\n",
        "    expected_freq = expected_top_5[word] / topk_5_sum\n",
        "    observed_freq = observed_freqs[word] / N\n",
        "    print(f\"Word: {word!r:<9}. Expected freq = {expected_freq:.4f}, observed freq = {observed_freq:.4f}\")\n",
        "    assert abs(observed_freq - expected_freq) < 0.015, \"Try increasing N if this fails by a small amount.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HElusTNfHOA"
      },
      "source": [
        "### Top-K Sampling - Example\n",
        "\n",
        "The [GPT-2 paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) famously included an example prompt about unicorns. Now it's your turn to see just how cherry picked this example was.\n",
        "\n",
        "The paper claims they used `top_k=40` and best of 10 samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "24dChHZ1fHOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "6db3ec03-2f96-49cd-ea3a-4f6e5ae78f79"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Your model said:\n",
              "\n",
              "\u001b[1;38;5;208mIn a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in\u001b[0m\n",
              "\u001b[1;38;5;208mthe Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\u001b[0m\n",
              "\n",
              "\u001b[1;38;5;208m\"The unicorns are very intelligent, and they are very intelligent people,\"\u001b[0m\u001b[1;38;5;208m said researcher Dr. Daniel D. Dolan, a \u001b[0m\n",
              "\u001b[1;38;5;208mdoctoral student at the University of California Santa Barbara. \u001b[0m\u001b[1;38;5;208m\"They are very, very smart and very, very \u001b[0m\n",
              "\u001b[1;38;5;208mintelligent. We have to take this seriously.\"\u001b[0m\n",
              "\n",
              "\u001b[1;38;5;208m\"This is the\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Your model said:\n",
              "\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in</span>\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.</span>\n",
              "\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">\"The unicorns are very intelligent, and they are very intelligent people,\"</span><span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\"> said researcher Dr. Daniel D. Dolan, a </span>\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">doctoral student at the University of California Santa Barbara. </span><span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">\"They are very, very smart and very, very </span>\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">intelligent. We have to take this seriously.\"</span>\n",
              "\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">\"This is the</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "your_prompt = \"In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.\"\n",
        "output = sampler.sample(your_prompt, temperature=0.7, top_k=40, max_tokens_generated=64)\n",
        "rprint(f\"Your model said:\\n\\n[bold dark_orange]{output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is pretty incredible! For some perspective on how much of a paradigm shift even basic models like this represented, we recommend reading [this section from Simulators](https://www.lesswrong.com/posts/vJFdjigzmcXMhNTsx/simulators#The_limit_of_sequence_modeling)."
      ],
      "metadata": {
        "id": "WpaCZmw3yW9X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEmLBEn9fHOA"
      },
      "source": [
        "## Top-p aka Nucleus Sampling\n",
        "\n",
        "The basic idea is that we choose the most likely words, up until the total probability of words we've chosen crosses some threshold. Then we sample from those chosen words based on their logits.\n",
        "\n",
        "The steps are:\n",
        "\n",
        "- Sort the probabilities from largest to smallest\n",
        "- Find the cutoff point where the cumulative probability first equals or exceeds `top_p`. We do the cutoff inclusively, keeping the first probability above the threshold.\n",
        "- If the number of kept probabilities is less than `min_tokens_to_keep`, keep that many tokens instead.\n",
        "- Set all other probabilities to zero\n",
        "- Normalize and sample\n",
        "\n",
        "Optionally, refer to the paper [The Curious Case of Neural Text Degeneration](https://arxiv.org/pdf/1904.09751.pdf) for some comparison of different methods.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAJaTvcefHOA"
      },
      "source": [
        "### Exercise - implement `sample_top_p`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴⚪⚪\n",
        "Importance: 🔵⚪⚪⚪⚪\n",
        "\n",
        "You should spend up to 15-20 minutes on this exercise.\n",
        "```\n",
        "\n",
        "<details>\n",
        "<summary>Example of top-p sampling (if you're confused)</summary>\n",
        "\n",
        "If our probabilities were `(0.4, 0.3, 0.2, 0.1)` and our cutoff was `top_p=0.8`, then we'd sample from the first three elements (because their total probability is `0.9` which is over the threshold, but the first two only have a total prob of `0.7` which is under the threshold). Once we've chosen to sample from those three, we would renormalise them by dividing by their sum (so the probabilities we use when sampling are `(4/9, 3/9, 2/9)`.\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Help - I'm stuck on how to implement this function.</summary>\n",
        "\n",
        "First, sort the logits using the `sort(descending=True)` method (this returns values and indices). Then you can get `cumulative_probs` by applying softmax to these logits and taking the cumsum. Then, you can decide how many probabilities to keep by using the `t.searchsorted` function.\n",
        "    \n",
        "Once you've decided which probabilities to keep, it's easiest to sample from them using the original logits (you should have preserved the indices when you called `logits.sort`). This way, you don't need to worry about renormalising like you would if you were using probabilities.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ndUIZuRJfHOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "9260c893fe4444a8b497541d3d4a8b1d",
            "1b3aea9733634378a918836b2a1e1222",
            "1c7b5e15ad35441e8726617d8260683f",
            "8050ab1e3d4c4228944e63e754c0231a",
            "91b4a9a4634b4c44923679a09b71fa14",
            "953210ee01974760a85f8e732da61d8c",
            "b2fa9452e14a41d09092de717064f80a",
            "4a609451399d464885074547713e7d61",
            "960a8c27bfd54f8d9d0ba1a57d9fbe74",
            "0c5df97e8cc14d638b994f29fd9e0fa1",
            "c72a6c36faff42139871ced0e38eed30"
          ]
        },
        "outputId": "cf63ee7f-86f2-4ac5-caf1-aa458c11db15"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9260c893fe4444a8b497541d3d4a8b1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: ' church'. Expected freq 0.6384, observed freq 0.6372\n",
            "Word: ' house' . Expected freq 0.3616, observed freq 0.3628\n"
          ]
        }
      ],
      "source": [
        "prompt = \"John and Mary went to the\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "logits = model(input_ids)[0, -1]\n",
        "\n",
        "expected_top_10pct = {\n",
        "    \" church\": 0.0648,\n",
        "    \" house\": 0.0367, # These are the two most likely tokens, and add up to >10%\n",
        "}\n",
        "top_10pct_sum = sum(expected_top_10pct.values())\n",
        "\n",
        "observed_freqs = defaultdict(int)\n",
        "\n",
        "N = 10000\n",
        "for _ in tqdm(range(N)):\n",
        "    token = TransformerSampler.sample_next_token(input_ids.squeeze(), logits, top_p=0.1)\n",
        "    observed_freqs[tokenizer.decode(token)] += 1\n",
        "\n",
        "for word in expected_top_10pct:\n",
        "    expected_freq = expected_top_10pct[word] / top_10pct_sum\n",
        "    observed_freq = observed_freqs[word] / N\n",
        "    print(f\"Word: {word!r:<9}. Expected freq {expected_freq:.4f}, observed freq {observed_freq:.4f}\")\n",
        "    assert abs(observed_freq - expected_freq) < 0.01, \"Try increasing N if this fails by a small amount.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhrTvZp6fHOA"
      },
      "source": [
        "### Top-p Sampling - Example\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "vCBMUxzufHOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "5341ed50-a4af-44df-8fb5-1f297e03bc5a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Your model said:\n",
              "\n",
              "\u001b[1;38;5;208mEliezer Shlomo Yudkowsky \u001b[0m\u001b[1;38;5;208m(\u001b[0m\u001b[1;38;5;208mborn September \u001b[0m\u001b[1;38;5;208m11\u001b[0m\u001b[1;38;5;208m, \u001b[0m\u001b[1;38;5;208m1979\u001b[0m\u001b[1;38;5;208m)\u001b[0m\u001b[1;38;5;208m is an American decision and artificial intelligence \u001b[0m\u001b[1;38;5;208m(\u001b[0m\u001b[1;38;5;208mAI\u001b[0m\u001b[1;38;5;208m)\u001b[0m\u001b[1;38;5;208m \u001b[0m\n",
              "\u001b[1;38;5;208mtheorist and writer, best known for his book \u001b[0m\u001b[1;38;5;208m\"Infinite Jest.\"\u001b[0m\u001b[1;38;5;208m The author is also a member of the influential \u001b[0m\n",
              "\u001b[1;38;5;208mComputer Science and Artificial Intelligence Society \u001b[0m\u001b[1;38;5;208m(\u001b[0m\u001b[1;38;5;208mCSAI\u001b[0m\u001b[1;38;5;208m)\u001b[0m\u001b[1;38;5;208m and a professor at Stanford University. He blogs about \u001b[0m\n",
              "\u001b[1;38;5;208mhis work on blogs and Twitter. He is currently an Associate Professor at the University of California, Berkeley. He\u001b[0m\n",
              "\u001b[1;38;5;208mlives in Los Angeles\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Your model said:\n",
              "\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">Eliezer Shlomo Yudkowsky (born September </span><span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">11</span><span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">, </span><span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">1979</span><span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">) is an American decision and artificial intelligence (AI) </span>\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">theorist and writer, best known for his book </span><span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">\"Infinite Jest.\"</span><span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\"> The author is also a member of the influential </span>\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">Computer Science and Artificial Intelligence Society (CSAI) and a professor at Stanford University. He blogs about </span>\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">his work on blogs and Twitter. He is currently an Associate Professor at the University of California, Berkeley. He</span>\n",
              "<span style=\"color: #ff8700; text-decoration-color: #ff8700; font-weight: bold\">lives in Los Angeles</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "your_prompt = \"Eliezer Shlomo Yudkowsky (born September 11, 1979) is an American decision and artificial intelligence (AI) theorist and writer, best known for\"\n",
        "output = sampler.sample(your_prompt, temperature=0.7, top_p=0.95, max_tokens_generated=64)\n",
        "rprint(f\"Your model said:\\n\\n[bold dark_orange]{output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6PVv6PHfHOE"
      },
      "source": [
        "## Beam search\n",
        "\n",
        "Finally, we'll implement a more advanced way of searching over output: **beam search**. You should read the [HuggingFace page](https://huggingface.co/blog/how-to-generate#beam-search) on beam search before moving on.\n",
        "\n",
        "In beam search, we maintain a list of size `num_beams` completions which are the most likely completions so far as measured by the product of their probabilities. Since this product can become very small, we use the sum of log probabilities instead. Note - log probabilities are *not* the same as your model's output. We get log probabilities by first taking softmax of our output and then taking log. You can do this with the [`log_softmax`](https://pytorch.org/docs/stable/generated/torch.nn.functional.log_softmax.html) function / tensor method.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsRXQwecfHOE"
      },
      "source": [
        "<details>\n",
        "<summary>Log probabilities are equal to the logit output after being translated by some amount X (where X is a function of the original logit output). Can you prove this?</summary>\n",
        "\n",
        "Suppose our vector of logits is $x$, and we take softmax to get a vector of probabilities $p$, then log again to get a vector of log probabilities $l$. Then the $i$-th element of this vector of logprobs is:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "l_i &= \\log p_i \\\\\n",
        "&= \\log \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)} \\\\\n",
        "&= x_i - \\log \\sum_j \\exp(x_j) \\\\\n",
        "&= x_i - C\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where $C = \\log \\sum_j \\exp(x_j)$ is the same for all elements. So we can see that $l_i$ is equal to the logit output $x_i$ after being translated by $C$.\n",
        "\n",
        "It's important not to mix up logits and logprobs!\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Why do you think we use log softmax rather than logit output?</summary>\n",
        "\n",
        "Logit output is translation invariant. If we had two different beams and we were generating the next tokens in those beams, there would be no reasonable way to compare the two beams to each other, because we could shift the logit vector for one beam by a constant amount without changing the distribution.\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dQFaVpFfHOE"
      },
      "source": [
        "At each iteration, we run the batch of completions through the model and take the log-softmax to obtain `d_vocab` log-probs for each completion, or `num_beams * d_vocab` possible next completions in total.\n",
        "\n",
        "If we kept all of these, then we would have `num_beams * d_vocab * d_vocab` completions after the next iteration which is way too many, so instead we sort them by their score and loop through from best (highest) log probability to worst (lowest).\n",
        "\n",
        "The illustration below might help (based on real results from this method). Here, we have the following hyperparameters:\n",
        "\n",
        "```python\n",
        "num_beams = 3\n",
        "max_new_tokens = 3\n",
        "num_return_sequences = 2\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhmYgrg4fHOE"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/beam-search.png\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnZQieUBfHOF"
      },
      "source": [
        "Note how after each \"generate\" stage, we have `num_beams ** 2` possible completions, which we then filter down to `num_beams`. Can you see why we need to generate this many (and what might happen if we generated fewer)?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn-kjeh8fHOF"
      },
      "source": [
        "How do we deal with sequences that terminate early (i.e. by generating an EOS token)? Answer - we append them to the list of completions which we'll return at the end, and remove them from the generation tree. Our algorithm terminates when either all our sequences have length `max_new_tokens` larger than the initial prompt length, or we've generated `num_returns_sequences` terminating sequences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFiBucEHfHOF"
      },
      "source": [
        "### Exercise - implement `beam_search`\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴🔴⚪\n",
        "Importance: 🔵⚪⚪⚪⚪\n",
        "\n",
        "You should spend up to 30-40 minutes on this exercise.\n",
        "```\n",
        "\n",
        "You should now complete the `beam_search` method in your `TransformerSampler` class.\n",
        "\n",
        "We've provided one possible template for you to use: the class `Beams`, with important methods `generate` and `filter` for you to fit in (which correspond to the two stages in the diagram above). There are also a few of helper functions in this class:\n",
        "\n",
        "* `new_beams`, which creates a new `Beams` object from an old one.\n",
        "* `__getitem__`, which allows you to index into a `Beams` object to get a specific batch of beams.\n",
        "* `logprobs_and_completions`, which turns a `Beams` object into a list of (logprob sum, string completion) tuples (useful for getting your final output).\n",
        "* `print`, which prints out the current state of the beams (useful for debugging, if you run `beam_search` with `verbose=True`).\n",
        "\n",
        "You can then fill in the `beam_search` function, using this class and its methods.\n",
        "\n",
        "We've provided unit tests for the `generate` and `filter` functions, so you can verify that these are correct before moving on to the full `beam_search` function.\n",
        "\n",
        "**Note that using the `Beams` class is not strictly necessary, you could fill in the `beam_search` function directly if you prefer.** The `Beams` class is just meant to provide one example way you might implement this function. Often, modular code like this is easier to write and debug, and easier to extend to cover new use cases (e.g. when we use caching in the bonus exercises).\n",
        "\n",
        "#### Why all the n-gram repetition?\n",
        "\n",
        "You should observe that, while the output of beam search is sometimes more fluent than some of the other sampling methods you implement, it also has an unfortunate tendency to repeat sentences or sequences. This makes sense - if the model produces a sentence with a relatively high logit sum, then it will want to produce the same sentence again even if it doesn't make a lot of sense in context.\n",
        "\n",
        "A common solution is to ban repetition of n-grams. We've provided the argument `no_repeat_ngram_size` in the `generate` method for this purpose. Using this argument should prevent the model from repeating any n-grams of that size. Good values of this parameter to try are 2 or 3.\n",
        "\n",
        "However, first you should focus on getting a working version of beam search *without* using this argument.\n",
        "\n",
        "<details>\n",
        "<summary>Hint (for <code>no_repeat_ngram_size</code>)</summary>\n",
        "\n",
        "It might be helpful to implement the following method first. You can use this rather than `torch.topk` in your `generate` method.\n",
        "\n",
        "```python\n",
        "def get_topk_non_repeating(\n",
        "    self,\n",
        "    logprobs: Float[Tensor, \"batch d_vocab\"],\n",
        "    no_repeat_ngram_size: int,\n",
        "    k: int,\n",
        ") -> Tuple[Float[Tensor, \"k\"], Int[Tensor, \"k\"]]:\n",
        "    '''\n",
        "    logprobs:\n",
        "        tensor of the log-probs for the next token\n",
        "    no_repeat_ngram_size:\n",
        "        size of ngram to avoid repeating\n",
        "    k:\n",
        "        number of top logits to return, for each beam in our collection\n",
        "\n",
        "    Returns:\n",
        "        equivalent to the output of `logprobs.topk(dim=-1)`, but makes sure\n",
        "        that no returned tokens would produce an ngram of size  `no_repeat_ngram_size`\n",
        "        which has already appeared in `self.tokens`.\n",
        "    '''\n",
        "    pass\n",
        "```\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RhHI8AyfHOF"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Beams:\n",
        "    '''Class to store beams during beam search.'''\n",
        "    model: DemoTransformer\n",
        "    tokenizer: GPT2TokenizerFast\n",
        "    logprob_sums: Float[Tensor, \"batch\"]\n",
        "    tokens: Int[Tensor, \"batch seq\"]\n",
        "\n",
        "    def new_beams(self, logprob_sums, tokens) -> \"Beams\":\n",
        "        '''Creates a new Beams object with the same model and tokenizer.'''\n",
        "        return Beams(self.model, self.tokenizer, logprob_sums, tokens)\n",
        "\n",
        "    def __getitem__(self, idx) -> \"Beams\":\n",
        "        '''Allows you to take a slice of the beams object along the batch dimension.'''\n",
        "        return self.new_beams(self.logprob_sums[idx], self.tokens[idx])\n",
        "\n",
        "    @property\n",
        "    def logprobs_and_completions(self) -> List[Tuple[float, str]]:\n",
        "        '''Returns self as a list of logprob sums and completions (useful for getting final output).'''\n",
        "        return [\n",
        "            (logprob_sum.item(), self.tokenizer.decode(tokens))\n",
        "            for (logprob_sum, tokens) in zip(self.logprob_sums, self.tokens)\n",
        "        ]\n",
        "\n",
        "\n",
        "    def generate(self, toks_per_beam: int, no_repeat_ngram_size: Optional[int] = None) -> \"Beams\":\n",
        "        '''\n",
        "        Starting from the current set of beams (which has length `num_beams`), returns a new\n",
        "        set of `num_beams * toks_per_beam`, containing the best `toks_per_beam` continuations for each\n",
        "        of the original beams.\n",
        "\n",
        "        Optional argument `no_repeat_ngram_size` means your model won't generate any sequences with\n",
        "        a repeating n-gram of this length.\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def filter(self, num_beams: int) -> Tuple[\"Beams\", \"Beams\"]:\n",
        "        '''\n",
        "        Returns:\n",
        "            best_beams: Beams\n",
        "                filtered version of self, containing all best `num_beams` which are also not terminated.\n",
        "\n",
        "            early_terminations: Beams\n",
        "                filtered version of self, containing all best `num_beams` which are also terminated.\n",
        "                i.e. the sum of lengths of these two should equal `num_beams`.\n",
        "        '''\n",
        "        pass\n",
        "\n",
        "    def print(self, title=\"Best completions\", max_print_chars=80) -> None:\n",
        "        '''\n",
        "        Prints out a set of sequences with their corresponding logitsums.\n",
        "        '''\n",
        "        if len(self.tokens) == 0:\n",
        "            return\n",
        "        table = Table(\"logitsum\", \"completion\", title=title)\n",
        "        for logprob_sum, tokens in zip(self.logprob_sums, self.tokens):\n",
        "            text = self.tokenizer.decode(tokens)\n",
        "            if len(repr(text)) > max_print_chars:\n",
        "                text = text[:int(0.3 * max_print_chars)] + \" ... \" + text[-int(0.7 * max_print_chars):]\n",
        "            table.add_row(f\"{logprob_sum:>8.3f}\", repr(text))\n",
        "        rprint(table)\n",
        "\n",
        "\n",
        "    def get_topk_non_repeating(\n",
        "        self,\n",
        "        logprobs: Float[Tensor, \"batch d_vocab\"],\n",
        "        no_repeat_ngram_size: Optional[int],\n",
        "        k: int,\n",
        "    ) -> Tuple[Float[Tensor, \"k\"], Int[Tensor, \"k\"]]:\n",
        "        '''\n",
        "        logprobs:\n",
        "            tensor of the log-probs for the next token\n",
        "        no_repeat_ngram_size:\n",
        "            size of ngram to avoid repeating\n",
        "        k:\n",
        "            number of top logits to return, for each beam in our collection\n",
        "\n",
        "        Returns:\n",
        "            equivalent to the output of `logprobs.topk(dim=-1)`, but makes sure\n",
        "            that no returned tokens would produce an ngram of size  `no_repeat_ngram_size`\n",
        "            which has already appeared in `self.tokens`.\n",
        "        '''\n",
        "        batch, seq_len = self.tokens.shape\n",
        "        neg_inf = t.tensor(-1.0e4).to(device)\n",
        "\n",
        "        # If completion isn't long enough for a repetition, or we have no restructions, just return topk\n",
        "        if (no_repeat_ngram_size is not None) and (seq_len > no_repeat_ngram_size-1):\n",
        "            # Otherwise, we need to check for ngram repetitions\n",
        "            # First, get the most recent `no_repeat_ngram_size-1` tokens\n",
        "            last_ngram_prefix = self.tokens[:, seq_len - (no_repeat_ngram_size-1):]\n",
        "            # Next, find all the tokens we're not allowed to generate (by going iterating through past ngrams and seeing if those ngram prefixes match the last one)\n",
        "            for i in range(seq_len - (no_repeat_ngram_size-1)):\n",
        "                ngrams = self.tokens[:, i:i+no_repeat_ngram_size] # (batch, ngram)\n",
        "                ngrams_are_repeated = (ngrams[:, :-1] == last_ngram_prefix).all(-1) # (batch,)\n",
        "                ngram_end_tokens = ngrams[:, [-1]] # (batch, 1)\n",
        "                # Fill logprobs with neginf wherever the ngrams are repeated\n",
        "                logprobs[range(batch), ngram_end_tokens] = t.where(\n",
        "                    ngrams_are_repeated,\n",
        "                    neg_inf,\n",
        "                    logprobs[range(batch), ngram_end_tokens],\n",
        "            )\n",
        "\n",
        "        # Finally, get our actual tokens\n",
        "        return logprobs.topk(k=k, dim=-1)\n",
        "\n",
        "\n",
        "@t.inference_mode()\n",
        "def beam_search(\n",
        "    self: TransformerSampler,\n",
        "    prompt: str,\n",
        "    num_return_sequences: int,\n",
        "    num_beams: int,\n",
        "    max_new_tokens: int,\n",
        "    no_repeat_ngram_size: Optional[int] = None,\n",
        "    verbose=False\n",
        ") -> List[Tuple[float, Tensor]]:\n",
        "    '''\n",
        "    Implements a beam search, by repeatedly performing the `generate` and `filter` steps (starting\n",
        "    from the initial prompt) until either of the two stopping criteria are met:\n",
        "\n",
        "        (1) we've generated `max_new_tokens` tokens, or\n",
        "        (2) we've generated `num_returns_sequences` terminating sequences.\n",
        "\n",
        "    To modularize this function, most of the actual complexity is in the Beams class,\n",
        "    in the `generate` and `filter` methods.\n",
        "    '''\n",
        "\n",
        "    assert num_return_sequences <= num_beams\n",
        "    self.model.eval()\n",
        "\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYDnDhhAfHOF"
      },
      "source": [
        "Example usage of the `Beams` class, and the `print` method (not the logitsums aren't necessarily accurate, this example is just an illustration):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dIOf4f9fHOF"
      },
      "outputs": [],
      "source": [
        "beams = Beams(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    logprob_sums = t.tensor([-10.0, -15.0, -20.0]).to(device),\n",
        "    tokens = t.tensor([\n",
        "        [5661, 318, 262, 2368],\n",
        "        [5661, 318, 262, 1218],\n",
        "        [5661, 318, 262, 717],\n",
        "    ]).to(device)\n",
        ")\n",
        "\n",
        "beams.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7ndBImyfHOF"
      },
      "source": [
        "And here are some unit tests for your `generate` and `filter` methods:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxrABZUzfHOF"
      },
      "outputs": [],
      "source": [
        "print(\"Testing generate, without no_repeat_ngram_size argument:\")\n",
        "new_beams = beams.generate(toks_per_beam=2)\n",
        "new_beams.print()\n",
        "assert new_beams.logprobs_and_completions[0][1] == \"this is the third time\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD1Q7u74fHOG"
      },
      "outputs": [],
      "source": [
        "print(\"Testing generate, with no_repeat_ngram_size argument:\")\n",
        "\n",
        "bigram_beams = Beams(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    logprob_sums = t.tensor([-0.0]).to(device),\n",
        "    tokens = t.tensor([[530, 734, 530, 734]]).to(device)\n",
        "    # tokens are \" one two one two\"\n",
        ")\n",
        "\n",
        "# With no_repeat_ngram_size=1, should not generate the token \" one\" or \" two\"\n",
        "new_bigram_beams = bigram_beams.generate(toks_per_beam=3, no_repeat_ngram_size=1)\n",
        "new_bigram_beams.print()\n",
        "assert all([not (completion[1].endswith(\" one\") or completion[1].endswith(\" two\")) for completion in new_bigram_beams.logprobs_and_completions])\n",
        "\n",
        "# With no_repeat_ngram_size=2, it can generate \" two\" (which it should), but not \" one\"\n",
        "new_bigram_beams = bigram_beams.generate(toks_per_beam=3, no_repeat_ngram_size=2)\n",
        "new_bigram_beams.print()\n",
        "assert all([not completion[1].endswith(\" one\") for completion in new_bigram_beams.logprobs_and_completions])\n",
        "assert any([not completion[1].endswith(\" two\") for completion in new_bigram_beams.logprobs_and_completions])\n",
        "\n",
        "print(\"All tests for `generate` passed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0NG1ZaqfHOG"
      },
      "outputs": [],
      "source": [
        "logprob_sums = t.tensor([-1.0, -2.0]).to(device)\n",
        "tokens = t.tensor([\n",
        "    [19485, 13],\n",
        "    [19485, tokenizer.eos_token_id]\n",
        "]).to(device)\n",
        "\n",
        "beams_with_eos = Beams(model, tokenizer, logprob_sums, tokens)\n",
        "best_beams, early_terminations = beams_with_eos.filter(2)\n",
        "\n",
        "t.testing.assert_close(best_beams.logprob_sums, logprob_sums[[0]])\n",
        "t.testing.assert_close(best_beams.tokens, tokens[[0]])\n",
        "\n",
        "assert early_terminations.logprobs_and_completions == [(-2.0, \"Stop\" + tokenizer.eos_token)]\n",
        "\n",
        "print(\"All tests for `filter` passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Shua7jeTfHOG"
      },
      "source": [
        "<details>\n",
        "<summary>Solutions (for <code>generate</code> and <code>filter</code>)</summary>\n",
        "\n",
        "```python\n",
        "def generate(self, toks_per_beam: int, no_repeat_ngram_size: Optional[int] = None) -> \"Beams\":\n",
        "    '''\n",
        "    Starting from the current set of beams (which has length `num_beams`), returns a new\n",
        "    set of `num_beams * toks_per_beam`, containing the best `toks_per_beam` continuations for each\n",
        "    of the original beams.\n",
        "\n",
        "    Optional argument `no_repeat_ngram_size` means your model won't generate any sequences with\n",
        "    a repeating n-gram of this length (don't worry about implementing this until later).\n",
        "    '''\n",
        "    # SOLUTION\n",
        "\n",
        "    # Get the output logprobs for the next token (for every sequence in current beams)\n",
        "    logprobs: Tensor = self.model(self.tokens)[:, -1, :].log_softmax(-1)\n",
        "\n",
        "    # Get the top `toks_per_beam` tokens for each sequence\n",
        "    topk_logprobs, topk_tokenIDs = logprobs.topk(k=toks_per_beam)\n",
        "\n",
        "    # Get all of the new possible beams, via einops operations\n",
        "    #   Here, we're effectively flattening out the batch dimension and k dimension, to give us tensors\n",
        "    #   with every possible combination of (original sequence, new token) pairs.)\n",
        "    new_logprob_sums = sum([\n",
        "        einops.repeat(self.logprob_sums, \"batch -> batch k\", k=toks_per_beam),\n",
        "        einops.rearrange(topk_logprobs, \"batch k -> (batch k)\")\n",
        "    ])\n",
        "    new_tokens = t.concat([\n",
        "        einops.repeat(self.tokens, \"batch seq -> (batch k) seq\", k=toks_per_beam),\n",
        "        einops.rearrange(topk_tokenIDs, \"batch k -> (batch k) 1\")\n",
        "    ], dim=-1)\n",
        "    return self.new_beams(new_logprob_sums, new_tokens)\n",
        "\n",
        "\n",
        "def filter(self, num_beams: int) -> Tuple[\"Beams\", \"Beams\"]:\n",
        "    '''\n",
        "    Returns:\n",
        "        best_beams: Beams\n",
        "            filtered version of self, containing all best `num_beams` which are also not terminated.\n",
        "\n",
        "        early_terminations: Beams\n",
        "            filtered version of self, containing all best `num_beams` which are also terminated.\n",
        "            i.e. the sum of lengths of these two should equal `num_beams`.\n",
        "    '''\n",
        "    # SOLUTION\n",
        "\n",
        "    # Get the indices of top `num_beams` beams\n",
        "    top_beam_indices = self.logprob_sums.topk(k=num_beams, dim=0).indices.tolist()\n",
        "    # Get the indices of terminated sequences\n",
        "    new_tokens = self.tokens[:, -1]\n",
        "    terminated_indices = t.nonzero(new_tokens == self.tokenizer.eos_token_id)\n",
        "\n",
        "    # Get the indices of the `num_beams` best sequences (some terminated, some not terminated)\n",
        "    best_continuing = [i for i in top_beam_indices if i not in terminated_indices]\n",
        "    best_terminated = [i for i in top_beam_indices if i in terminated_indices]\n",
        "\n",
        "    # Return the beam objects from these indices\n",
        "    best_beams_continuing = self.new_beams(self.logprob_sums[best_continuing], self.tokens[best_continuing])\n",
        "    best_beams_terminated = self.new_beams(self.logprob_sums[best_terminated], self.tokens[best_terminated])\n",
        "    return best_beams_continuing, best_beams_terminated\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrXHl0GsfHOG"
      },
      "source": [
        "Once you've passed both these unit tests, you can try implementing the full beam search function. It should create a `Beams` object from the initial prompt, and then repeatedly call `generate` and `filter` until the stopping criteria are met.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Uno10GRfHOG"
      },
      "outputs": [],
      "source": [
        "TransformerSampler.beam_search = beam_search\n",
        "\n",
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "prompt = \"The ships hung in the sky in much the same way that\"\n",
        "orig_len = len(tokenizer.encode(prompt))\n",
        "\n",
        "final_logitsums_and_completions = sampler.beam_search(\n",
        "    prompt=prompt,\n",
        "    num_return_sequences=3,\n",
        "    num_beams=40,\n",
        "    max_new_tokens=60,\n",
        "    no_repeat_ngram_size=2,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Print all the best output\n",
        "for logprob_sum, text in final_logitsums_and_completions:\n",
        "    avg_logprob_as_prob = t.tensor(logprob_sum / (len(tokenizer.encode(text)) - orig_len)).exp().item()\n",
        "    print(\"=\" * 25 + f\" Avg logprob (as probability) = {avg_logprob_as_prob:.3f} \" + \"=\" * 25)\n",
        "    rprint(\"Best output:\\n\\n[bold dark_orange]\" + text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THgjSPShfHOG"
      },
      "source": [
        "<details>\n",
        "<summary>Solution (full)</summary>\n",
        "\n",
        "A solution for the class method `get_topk_non_repeating`:\n",
        "\n",
        "```python\n",
        "def get_topk_non_repeating(\n",
        "    self,\n",
        "    logprobs: Float[Tensor, \"batch d_vocab\"],\n",
        "    no_repeat_ngram_size: Optional[int],\n",
        "    k: int,\n",
        ") -> Tuple[Float[Tensor, \"k\"], Int[Tensor, \"k\"]]:\n",
        "    '''\n",
        "    logprobs:\n",
        "        tensor of the log-probs for the next token\n",
        "    no_repeat_ngram_size:\n",
        "        size of ngram to avoid repeating\n",
        "    k:\n",
        "        number of top logits to return, for each beam in our collection\n",
        "\n",
        "    Returns:\n",
        "        equivalent to the output of `logprobs.topk(dim=-1)`, but makes sure\n",
        "        that no returned tokens would produce an ngram of size  `no_repeat_ngram_size`\n",
        "        which has already appeared in `self.tokens`.\n",
        "    '''\n",
        "    batch, seq_len = self.tokens.shape\n",
        "    neg_inf = t.tensor(-1.0e4).to(device)\n",
        "\n",
        "    # If completion isn't long enough for a repetition, or we have no restructions, just return topk\n",
        "    if (no_repeat_ngram_size is not None) and (seq_len > no_repeat_ngram_size-1):\n",
        "        # Otherwise, we need to check for ngram repetitions\n",
        "        # First, get the most recent `no_repeat_ngram_size-1` tokens\n",
        "        last_ngram_prefix = self.tokens[:, seq_len - (no_repeat_ngram_size-1):]\n",
        "        # Next, find all the tokens we're not allowed to generate (by going iterating through past ngrams and seeing if those ngram prefixes match the last one)\n",
        "        for i in range(seq_len - (no_repeat_ngram_size-1)):\n",
        "            ngrams = self.tokens[:, i:i+no_repeat_ngram_size] # (batch, ngram)\n",
        "            ngrams_are_repeated = (ngrams[:, :-1] == last_ngram_prefix).all(-1) # (batch,)\n",
        "            ngram_end_tokens = ngrams[:, [-1]] # (batch, 1)\n",
        "            # Fill logprobs with neginf wherever the ngrams are repeated\n",
        "            logprobs[range(batch), ngram_end_tokens] = t.where(\n",
        "                ngrams_are_repeated,\n",
        "                neg_inf,\n",
        "                logprobs[range(batch), ngram_end_tokens],\n",
        "        )\n",
        "\n",
        "    # Finally, get our actual tokens\n",
        "    return logprobs.topk(k=k, dim=-1)\n",
        "```\n",
        "\n",
        "and for the main function:\n",
        "\n",
        "```python\n",
        "@t.inference_mode()\n",
        "def beam_search(\n",
        "    self: TransformerSampler,\n",
        "    prompt: str,\n",
        "    num_return_sequences: int,\n",
        "    num_beams: int,\n",
        "    max_new_tokens: int,\n",
        "    no_repeat_ngram_size: Optional[int] = None,\n",
        "    verbose=False\n",
        ") -> List[Tuple[float, Tensor]]:\n",
        "    '''\n",
        "    Implements a beam search, by repeatedly performing the `generate` and `filter` steps (starting\n",
        "    from the initial prompt) until either of the two stopping criteria are met:\n",
        "\n",
        "        (1) we've generated `max_new_tokens` tokens, or\n",
        "        (2) we've generated `num_returns_sequences` terminating sequences.\n",
        "\n",
        "    To modularize this function, most of the actual complexity is in the Beams class,\n",
        "    in the `generate` and `filter` methods.\n",
        "    '''\n",
        "\n",
        "    assert num_return_sequences <= num_beams\n",
        "    self.model.eval()\n",
        "\n",
        "    # SOLUTION\n",
        "    tokens = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # List for final beams to return (and early terminations)\n",
        "    final_logprobs_and_completions: List[Tuple[float, str]] = []\n",
        "    # Keep track of all best beams after each step\n",
        "    best_beams = Beams(self.model, self.tokenizer, t.tensor([0.0]).to(device), tokens)\n",
        "\n",
        "    for n in tqdm(range(max_new_tokens)):\n",
        "\n",
        "        # Generation step\n",
        "        best_beams = best_beams.generate(toks_per_beam=num_beams, no_repeat_ngram_size=no_repeat_ngram_size)\n",
        "\n",
        "        # Filtering step\n",
        "        best_beams, best_beams_terminated = best_beams.filter(num_beams=num_beams)\n",
        "        final_logprobs_and_completions.extend(best_beams_terminated.logprobs_and_completions)\n",
        "\n",
        "        # Print output\n",
        "        if verbose:\n",
        "            best_beams.print()\n",
        "\n",
        "        # Check stopping condition\n",
        "        if len(final_logprobs_and_completions) >= num_return_sequences:\n",
        "            return final_logprobs_and_completions[:num_return_sequences]\n",
        "\n",
        "    final_logprobs_and_completions.extend(best_beams.logprobs_and_completions)\n",
        "    final_logprobs_and_completions = final_logprobs_and_completions[:num_return_sequences]\n",
        "    return final_logprobs_and_completions\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8FpquaGfHOH"
      },
      "source": [
        "## Caching\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_myyOt5hfHOH"
      },
      "source": [
        "*This section is also designed to be challenging, and take quite some time. There are many different ways to solve it, and you're expected to try and find your own way (you should think about this for a while before looking at the suggestions in the dropdowns). Additionally, you might not find it as interesting as some of the other sections. In this case, and if you have a lot of extra time, you might want to start on the \"building BERT\" exercises from this chapter.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu83LC_4fHOH"
      },
      "source": [
        "### How can caching help us?\n",
        "\n",
        "The text generation we've done so far is needlessly re-computing certain values, which is very noticeable when you try to generate longer sequences.\n",
        "\n",
        "Suppose you're generating text, and you've already run GPT on the sentence \"My life motto:\". Now you want to run the model on the sentence \"My life motto: Always\". Which computations from the first sentence can you reuse?\n",
        "\n",
        "<details>\n",
        "<summary>Answer</summary>\n",
        "\n",
        "At each attention layer, the only things the attention layer needs from the previous sequence positions are the key and value vectors. This is explained in the following diagram:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/callummcdougall/computational-thread-art/master/example_images/misc/tl-cache.png\" width=\"600\">\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7xGpbbZfHOH"
      },
      "source": [
        "### Exercise - implement caching\n",
        "\n",
        "```c\n",
        "Difficulty: 🔴🔴🔴🔴🔴\n",
        "Importance: 🔵⚪⚪⚪⚪\n",
        "\n",
        "You are expected to spend well over an hour on this exercise, if you choose to do it.\n",
        "```\n",
        "\n",
        "Modify your GPT-2 to optionally use a cache. When you run your GPT on `\"My life motto:\"`, it should store the necessary values in the cache. Then in the next forward pass with just `\" Always\"` as input, it should load the cached values instead of recomputing them (and update the cache). This only needs to work with a single input sequence (batch size of 1), and you can assume that after the first forward pass, the input will be just one token.\n",
        "\n",
        "The design of the cache is completely up to you - discuss possible designs with your partner before writing code. It should be possible to have only one GPT2 instance and many different cache instances at one time. Imagine that you want to use one instance to serve multiple users submitting requests for text generation like in [AI Dungeon](https://aidungeon.io/).\n",
        "\n",
        "You'll also need to rewrite parts of your `DemoTransformer` code, in order to get this to work. The tests have been built to accommodate modules which return their output as the first element in a tuple (i.e. `(output, cache)`) rather than just returning the output, so you should use the tests to verify that your modules still work as expected.\n",
        "\n",
        "Some example considerations:\n",
        "\n",
        "* Which GPT-2 classes need to interact with the cache?\n",
        "    * Will you need to change the positional embedding, and if so then how?\n",
        "* Should the cache be mutable and be updated in place, or does updating actually just create a separate instance?\n",
        "    * *(Hint here - think about how you might use the cache during beam search.)*\n",
        "* Is it possible for other programmers to incorrectly use your cache? Is there a way to prevent this failure mode or at least detect this and complain loudly?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vq-Sx8apfHOH"
      },
      "source": [
        "<details>\n",
        "<summary>Cache implentation (example)</summary>\n",
        "\n",
        "This KeyValueCache object is structured as just a fancy tensor (it inherits all the methods from Tensor). The main difference is that it has a few extra helper methods, e.g. constructing an empty cache from a Config object.\n",
        "\n",
        "There are other ways you could do this, e.g. having your `KeyValueCache` class contain list of `KeyValueCacheEntry` objects (where each of these corresponds to a different layer).\n",
        "\n",
        "```python\n",
        "# Define a type for a single layer's cache entry (useful for type checking in later functions)\n",
        "KeyValueCacheTensor = Float[Tensor, \"2 batch seq_len n_heads d_head\"]\n",
        "\n",
        "class KeyValueCache(Tensor):\n",
        "    '''\n",
        "    This class holds tensors of key and value vectors, to be used for caching.\n",
        "\n",
        "    If we define it using cfg and batch then it's initialized as empty, but\n",
        "    we can also define it from kv_cache_entries.\n",
        "    '''\n",
        "    @classmethod\n",
        "    def new_empty(cls, cfg: Config, batch: int = 1) -> \"KeyValueCache\":\n",
        "        '''\n",
        "        Doing a forward pass on a cache created in this way indicates \"we don't\n",
        "        yet have a cache, but we want this forward pass to return a cache\".\n",
        "        Whereas using cache=None in a forward pass indicates we don't want to\n",
        "        return a cache.\n",
        "        '''\n",
        "        shape = (cfg.n_layers, 2, batch, 0, cfg.n_heads, cfg.d_head)\n",
        "        return cls(*shape).to(device)\n",
        "\n",
        "    # Define a handful of properties, so they can be referenced directly rather than\n",
        "    # indexing (which is more likely to lead to mistakes)\n",
        "\n",
        "    @property\n",
        "    def k(self) -> Tensor:\n",
        "        return self[:, 0]\n",
        "\n",
        "    @property\n",
        "    def v(self) -> Tensor:\n",
        "        return self[:, 1]\n",
        "\n",
        "    @property\n",
        "    def batch(self) -> int:\n",
        "        return self.shape[2]\n",
        "    \n",
        "    @property\n",
        "    def seq_len(self) -> int:\n",
        "        return self.shape[3]\n",
        "\n",
        "\n",
        "# Example implementation:\n",
        "cfg = model.cfg\n",
        "batch = 6\n",
        "kv_cache = KeyValueCache.new_empty(cfg, batch)\n",
        "\n",
        "print(f\"Shape of all kv-cache = {tuple(kv_cache.shape)}\")\n",
        "print(f\"Shape of just k-cache = {tuple(kv_cache.k.shape)}\")\n",
        "for kv_cache_entry in kv_cache:\n",
        "    print(f\"Shape of cache entry for one layer = {tuple(kv_cache_entry.shape)}\")\n",
        "    break\n",
        "print(f\"Batch size = {kv_cache.batch}\")\n",
        "print(f\"Current sequence length = {kv_cache.seq_len}\")\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>New <code>DemoTransformer</code> components (and testing)</summary>\n",
        "\n",
        "```python\n",
        "# Define new model parts where necessary, and create a new model & test it\n",
        "# Note that sometimes our modules return a tuple of (tensor output, cache) rather than just output. The\n",
        "# tests have been built to accommodate this.\n",
        "\n",
        "\n",
        "class PosEmbed(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_pos = nn.Parameter(t.empty((cfg.n_ctx, cfg.d_model)))\n",
        "        nn.init.normal_(self.W_pos, std=self.cfg.init_range)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        tokens: Int[Tensor, \"batch position\"],\n",
        "        past_kv_pos_offset: int = 0\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "        \n",
        "        # SOLUTION\n",
        "        batch, seq_len = tokens.shape\n",
        "        return einops.repeat(\n",
        "            self.W_pos[past_kv_pos_offset: seq_len+past_kv_pos_offset],\n",
        "            \"seq d_model -> batch seq d_model\",\n",
        "            batch=batch\n",
        "        )\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    IGNORE: Float[Tensor, \"\"]\n",
        "\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.W_Q = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_K = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_V = nn.Parameter(t.empty((cfg.n_heads, cfg.d_model, cfg.d_head)))\n",
        "        self.W_O = nn.Parameter(t.empty((cfg.n_heads, cfg.d_head, cfg.d_model)))\n",
        "        self.b_Q = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_K = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_V = nn.Parameter(t.zeros((cfg.n_heads, cfg.d_head)))\n",
        "        self.b_O = nn.Parameter(t.zeros((cfg.d_model)))\n",
        "        nn.init.normal_(self.W_Q, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_K, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_V, std=self.cfg.init_range)\n",
        "        nn.init.normal_(self.W_O, std=self.cfg.init_range)\n",
        "        self.register_buffer(\"IGNORE\", t.tensor(-1e5, dtype=t.float32, device=device))\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        normalized_resid_pre: Float[Tensor, \"batch posn d_model\"],\n",
        "        kv_cache_entry: Optional[KeyValueCacheTensor] = None,\n",
        "    ) -> Tuple[\n",
        "        Float[Tensor, \"batch posn d_model\"],\n",
        "        Optional[KeyValueCacheTensor]\n",
        "    ]:\n",
        "        '''\n",
        "        Returns the result of applying attention layer to normlized_resid_pre, as well as\n",
        "        the new cached key and value vectors (which we get from concatenating the old cached\n",
        "        ones with the new key and value vectors).\n",
        "        '''\n",
        "        \n",
        "        # SOLUTION\n",
        "\n",
        "        # Calculate the new query, key and value vectors\n",
        "        q = einops.einsum(\n",
        "            normalized_resid_pre, self.W_Q,\n",
        "            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\"\n",
        "        ) + self.b_Q\n",
        "        k = einops.einsum(\n",
        "            normalized_resid_pre, self.W_K,\n",
        "            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\"\n",
        "        ) + self.b_K\n",
        "        v = einops.einsum(\n",
        "            normalized_resid_pre, self.W_V,\n",
        "            \"batch posn d_model, nheads d_model d_head -> batch posn nheads d_head\"\n",
        "        ) + self.b_V\n",
        "\n",
        "        # If cache_entry is not None, this means we use the previous key and value vectors\n",
        "        # Also we'll need to get a new cache entry which will be used later to construct a new cache\n",
        "        if kv_cache_entry is not None:\n",
        "            k = t.concat([kv_cache_entry[0], k], dim=1)\n",
        "            v = t.concat([kv_cache_entry[1], v], dim=1)\n",
        "            kv_cache_entry = t.stack([k, v])\n",
        "\n",
        "        # Calculate attention scores, then scale and mask, and apply softmax to get probabilities\n",
        "        attn_scores = einops.einsum(\n",
        "            q, k,\n",
        "            \"batch posn_Q nheads d_head, batch posn_K nheads d_head -> batch nheads posn_Q posn_K\"\n",
        "        )\n",
        "        attn_scores_masked = self.apply_causal_mask(attn_scores / self.cfg.d_head ** 0.5)\n",
        "        attn_pattern = attn_scores_masked.softmax(-1)\n",
        "\n",
        "        # Take weighted sum of value vectors, according to attention probabilities\n",
        "        z = einops.einsum(\n",
        "            v, attn_pattern,\n",
        "            \"batch posn_K nheads d_head, batch nheads posn_Q posn_K -> batch posn_Q nheads d_head\"\n",
        "        )\n",
        "\n",
        "        # Calculate output (by applying matrix W_O and summing over heads, then adding bias b_O)\n",
        "        out = einops.einsum(\n",
        "            z, self.W_O,\n",
        "            \"batch posn_Q nheads d_head, nheads d_head d_model -> batch posn_Q d_model\"\n",
        "        ) + self.b_O\n",
        "\n",
        "        return out, kv_cache_entry\n",
        "\n",
        "    def apply_causal_mask(\n",
        "        self, attn_scores: Float[Tensor, \"batch n_heads query_pos key_pos\"]\n",
        "    ) -> Float[Tensor, \"batch n_heads query_pos key_pos\"]:\n",
        "        '''\n",
        "        Here, attn_scores have shape (batch, n_heads, query_pos, key_pos), where query_pos represents the\n",
        "        new (non-cached) positions, and key_pos represent all the positions (cached and non-cached).\n",
        "\n",
        "        So when we create our mask, the query indices and key indices will both go up to the same value\n",
        "        (the full sequence length), but the query indices will start at >0.\n",
        "        '''\n",
        "        new_seq_len, full_seq_len = attn_scores.shape[-2:]\n",
        "        assert new_seq_len <= full_seq_len\n",
        "        q_posn = einops.repeat(attn_scores.new_tensor(range(full_seq_len-new_seq_len, full_seq_len)), \"q -> q k\", k=full_seq_len)\n",
        "        k_posn = einops.repeat(attn_scores.new_tensor(range(full_seq_len)), \"k -> q k\", q=new_seq_len)\n",
        "        mask = q_posn < k_posn\n",
        "        attn_scores = attn_scores.masked_fill(mask, self.IGNORE)\n",
        "        return attn_scores\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.ln1 = LayerNorm(cfg)\n",
        "        self.attn = Attention(cfg)\n",
        "        self.ln2 = LayerNorm(cfg)\n",
        "        self.mlp = MLP(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        resid_pre: Float[Tensor, \"batch position d_model\"],\n",
        "        kv_cache_entry: Optional[KeyValueCacheTensor] = None,\n",
        "    ) -> Float[Tensor, \"batch position d_model\"]:\n",
        "\n",
        "        # SOLUTION\n",
        "        attn_out, kv_cache_entry = self.attn(self.ln1(resid_pre), kv_cache_entry)\n",
        "        resid_mid = attn_out + resid_pre\n",
        "        resid_post = self.mlp(self.ln2(resid_mid)) + resid_mid\n",
        "        return resid_post, kv_cache_entry\n",
        "\n",
        "\n",
        "\n",
        "class DemoTransformer(nn.Module):\n",
        "    def __init__(self, cfg: Config):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.embed = Embed(cfg)\n",
        "        self.pos_embed = PosEmbed(cfg)\n",
        "        self.blocks = nn.ModuleList([TransformerBlock(cfg) for _ in range(cfg.n_layers)])\n",
        "        self.ln_final = LayerNorm(cfg)\n",
        "        self.unembed = Unembed(cfg)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        tokens: Int[Tensor, \"batch seq_pos\"],\n",
        "        kv_cache: Optional[KeyValueCache] = None\n",
        "    ) -> Float[Tensor, \"batch position d_vocab\"]:\n",
        "        \n",
        "        using_kv_cache = kv_cache is not None\n",
        "\n",
        "        if using_kv_cache:\n",
        "            # If using kv_cache, then we only need to pass forward the newest tokens\n",
        "            # Remember to add positional offset!\n",
        "            n_cached_tokens = kv_cache.seq_len\n",
        "            tokens = tokens[:, n_cached_tokens:]\n",
        "            residual = self.embed(tokens) + self.pos_embed(tokens, n_cached_tokens)\n",
        "        else:\n",
        "            # If not using cache, turn it into a list of None's (so we can iterate through it)\n",
        "            kv_cache = [None for _ in range(self.cfg.n_layers)]\n",
        "            residual = self.embed(tokens) + self.pos_embed(tokens)\n",
        "        \n",
        "        # Apply all layers, and create a (new) kv_cache from the key & value vectors\n",
        "        new_kv_cache_entries: List[KeyValueCacheTensor] = []\n",
        "        for block, kv_cache_entry in zip(self.blocks, kv_cache):\n",
        "            residual, kv_cache_entry = block(residual, kv_cache_entry)\n",
        "            if using_kv_cache: new_kv_cache_entries.append(kv_cache_entry)\n",
        "        \n",
        "        logits = self.unembed(self.ln_final(residual))\n",
        "        \n",
        "        if using_kv_cache:\n",
        "            return logits, KeyValueCache(t.stack(new_kv_cache_entries))\n",
        "        else:\n",
        "            return logits, None\n",
        "\n",
        "\n",
        "tokens = reference_gpt2.to_tokens(reference_text).to(device)\n",
        "logits, cache = reference_gpt2.run_with_cache(tokens)\n",
        "\n",
        "rand_int_test(PosEmbed, [2, 4])\n",
        "load_gpt2_test(PosEmbed, reference_gpt2.pos_embed, tokens)\n",
        "rand_float_test(Attention, [2, 4, 768])\n",
        "load_gpt2_test(Attention, reference_gpt2.blocks[0].attn, cache[\"normalized\", 0, \"ln1\"])\n",
        "rand_float_test(TransformerBlock, [2, 4, 768])\n",
        "load_gpt2_test(TransformerBlock, reference_gpt2.blocks[0], cache[\"resid_pre\", 0])\n",
        "rand_int_test(DemoTransformer, [2, 4])\n",
        "load_gpt2_test(DemoTransformer, reference_gpt2, tokens)\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>New sampling function</summary>\n",
        "\n",
        "```python\n",
        "@t.inference_mode()\n",
        "def sample_with_cache(\n",
        "    self: TransformerSampler,\n",
        "    prompt: str,\n",
        "    max_tokens_generated=100,\n",
        "    kv_cache: Optional[KeyValueCache] = None,\n",
        "    verbose=False,\n",
        "    seed: Optional[int] = None,\n",
        "    **kwargs\n",
        ") -> str:\n",
        "    \n",
        "    # SOLUTION\n",
        "    self.model.eval()\n",
        "    input_ids = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)[0]\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "        t.manual_seed(seed)\n",
        "\n",
        "    for i in tqdm(range(max_tokens_generated)):\n",
        "        # Get new logits (make sure we don't pass in more tokens than the model's context length)\n",
        "        logits, kv_cache = self.model(input_ids[None, -self.cfg.n_ctx:], kv_cache)\n",
        "        # We only take logits for the last token, because this is what we're sampling\n",
        "        logits = logits[0, -1]\n",
        "        # Get next token (as a tensor of size (1, 1) so we can concat it to input_ids)\n",
        "        next_token = t.tensor([TransformerSampler.sample_next_token(input_ids, logits, **kwargs)], device=device)\n",
        "        # Create new input ids string, with shape (1, old_seq_len + 1)\n",
        "        input_ids = t.cat([input_ids, next_token], dim=-1)\n",
        "        # Print out results, if required\n",
        "        if verbose:\n",
        "            print(self.tokenizer.decode(input_ids), end=\"\\r\")\n",
        "        # If our new token was the end-of-text token, stop\n",
        "        if next_token == getattr(self.tokenizer, \"eos_token_id\", None):\n",
        "            break\n",
        "    \n",
        "    return self.tokenizer.decode(input_ids)\n",
        "\n",
        "\n",
        "TransformerSampler.sample = sample_with_cache\n",
        "```\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Code to verify that the same output is being produced by cache and no-cache versions (and to compare speeds)</summary>\n",
        "\n",
        "```python\n",
        "device = t.device(\"cuda\") # can also try \"cpu\"\n",
        "\n",
        "model = DemoTransformer(Config()).to(device)\n",
        "model.load_state_dict(reference_gpt2.state_dict(), strict=False);\n",
        "\n",
        "initial_text = \"Eliezer Shlomo Yudkowsky (born September 11, 1979) is an American decision and artificial intelligence (AI) theorist and writer, best known for\"\n",
        "# input_ids = tokenizer.encode(initial_text, return_tensors=\"pt\").squeeze()\n",
        "\n",
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "# Run the noncached version\n",
        "t0 = time.time()\n",
        "text = sampler.sample(\n",
        "    initial_text,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    seed=0,\n",
        ")\n",
        "print(f\"Time taken (without cache): {time.time() - t0:.2f} seconds\")\n",
        "rprint(f\"Model output:\\n\\n[bold dark_orange]{text}[/]\")\n",
        "\n",
        "# Run the cached version\n",
        "t0 = time.time()\n",
        "text_with_cache = sampler.sample(\n",
        "    initial_text,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    seed=0,\n",
        "    kv_cache=KeyValueCache.new_empty(sampler.cfg)\n",
        ")\n",
        "print(f\"Time taken (with cache): {time.time() - t0:.2f} seconds\")\n",
        "rprint(f\"Model output:\\n\\n[bold dark_orange]{text_with_cache}[/]\")\n",
        "\n",
        "# # Check they are the same\n",
        "assert text == text_with_cache, \"Your outputs are different, meaning you've probably made a mistake in your cache implementation (or failed to use random seeds).\"\n",
        "print(\"Tests passed!\")\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhYU3O6sfHOH"
      },
      "source": [
        "You may find that your cache implementation provides a modest speedup, but probably not close to the `seq_len`-factor speedup you'd expect from the fact that you only compute one additional token at each step rather than all of them. Why is this? The answer is that, much like everything to do with computational and memory costs in deep learning, it's not so simple. There are a host of different factors which might be bottlenecking our model's forward pass speed. If you try this on the CPU, you should get a much more noticeable speedup.\n",
        "\n",
        "For a bit more on these topics, see [here](https://kipp.ly/blog/transformer-inference-arithmetic/#kv-cache).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S_uxUzRfHOH"
      },
      "source": [
        "## Bonus - cached beam search\n",
        "\n",
        "Can you modify your beam search function to use caching?\n",
        "\n",
        "Depending on how you implemented your cache earlier, you might find that a different form of caching is better suited to beam search.\n",
        "\n",
        "Again, we've provided an example implementation in a dropdown below, which is based on the cache implementation above and the previous solution for `beam_search`.\n",
        "\n",
        "<details>\n",
        "<summary>Cached beam search function</summary>\n",
        "\n",
        "As we touched on earlier, thanks to our modular code, not a lot needs to be changed when adding cache support.\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class Beams:\n",
        "    '''Class to store beams during beam search.'''\n",
        "    model: DemoTransformer\n",
        "    tokenizer: GPT2TokenizerFast\n",
        "    logprob_sums: Float[Tensor, \"batch\"]\n",
        "    tokens: Int[Tensor, \"batch seq\"]\n",
        "    kv_cache: Optional[KeyValueCache] = None\n",
        "\n",
        "    def new_beams(self, logprob_sums, tokens, kv_cache) -> \"Beams\":\n",
        "        '''Creates a new Beams object with the same model and tokenizer.'''\n",
        "        return Beams(self.model, self.tokenizer, logprob_sums, tokens, kv_cache)\n",
        "\n",
        "    def __getitem__(self, idx) -> \"Beams\":\n",
        "        '''Helpful function allowing you to take a slice of the beams object along the batch dimension.'''\n",
        "        return self.new_beams(\n",
        "            self.logprob_sums[idx],\n",
        "            self.tokens[idx],\n",
        "            self.kv_cache[:, :, idx] if self.kv_cache is not None else None\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def logprobs_and_completions(self) -> List[Tuple[float, str]]:\n",
        "        '''Returns self as a list of logprob sums and completions (useful for getting final output).'''\n",
        "        return [\n",
        "            (logprob_sum.item(), self.tokenizer.decode(tokens))\n",
        "            for (logprob_sum, tokens) in zip(self.logprob_sums, self.tokens)\n",
        "        ]\n",
        "    \n",
        "\n",
        "    def generate(self, new_beams: int, no_repeat_ngram_size: Optional[int] = None) -> \"Beams\":\n",
        "        '''\n",
        "        Starting from the current set of beams (which has length `num_beams`), returns a new\n",
        "        set of `num_beams * new_beams`, containing the best `new_beams` continuations for each\n",
        "        of the original beams.\n",
        "\n",
        "        Optional argument `no_repeat_ngram_size` means your model won't generate any sequences with\n",
        "        a repeating n-gram of this length (don't worry about implementing this until later).\n",
        "        '''\n",
        "        # SOLUTION\n",
        "\n",
        "        # Get the output logprobs for the next token (for every sequence in current beams)\n",
        "        logprobs, kv_cache = self.model(self.tokens, self.kv_cache)\n",
        "        logprobs = logprobs[:, -1, :].log_softmax(-1)\n",
        "\n",
        "        # Get the top `new_beams` tokens for each sequence\n",
        "        topk_logprobs, topk_tokenIDs = self.get_topk_non_repeating(logprobs, no_repeat_ngram_size, k=new_beams)\n",
        "\n",
        "        # Get all of the new possible beams, via einops operations\n",
        "        #   Here, we're effectively flattening out the batch dimension and k dimension, to give us tensors\n",
        "        #   with every possible combination of (original sequence, new token) pairs.)\n",
        "        new_logprob_sums = sum([\n",
        "            einops.repeat(self.logprob_sums, \"batch -> (batch k)\", k=new_beams),\n",
        "            einops.rearrange(topk_logprobs, \"batch k -> (batch k)\")\n",
        "        ])\n",
        "        new_tokens = t.concat([\n",
        "            einops.repeat(self.tokens, \"batch seq -> (batch k) seq\", k=new_beams),\n",
        "            einops.rearrange(topk_tokenIDs, \"batch k -> (batch k) 1\")\n",
        "        ], dim=-1)\n",
        "        new_kv_cache = None if (self.kv_cache is None) else einops.repeat(\n",
        "            kv_cache, \"layer k_and_v batch ... -> layer k_and_v (batch k) ...\", k=new_beams\n",
        "        )\n",
        "        return self.new_beams(new_logprob_sums, new_tokens, new_kv_cache)\n",
        "\n",
        "\n",
        "    def filter(self, num_beams: int) -> Tuple[\"Beams\", \"Beams\"]:\n",
        "        '''\n",
        "        Returns:\n",
        "            best_beams: Beams\n",
        "                filtered version of self, containing all best `num_beams` which are also not terminated.\n",
        "\n",
        "            early_terminations: Beams\n",
        "                filtered version of self, containing all best `num_beams` which are also terminated.\n",
        "                i.e. the sum of lengths of these two should equal `num_beams`.\n",
        "        '''\n",
        "        # SOLUTION\n",
        "\n",
        "        # Get the indices of top `num_beams` beams\n",
        "        top_beam_indices = self.logprob_sums.topk(k=num_beams, dim=0).indices.tolist()\n",
        "        # Get the indices of terminated sequences\n",
        "        new_tokens = self.tokens[:, -1]\n",
        "        terminated_indices = t.nonzero(new_tokens == self.tokenizer.eos_token_id)\n",
        "\n",
        "        # Get the indices of the `num_beams` best sequences (some terminated, some not terminated)\n",
        "        best_continuing = [i for i in top_beam_indices if i not in terminated_indices]\n",
        "        best_terminated = [i for i in top_beam_indices if i in terminated_indices]\n",
        "\n",
        "        # Return the beam objects from these indices\n",
        "        return self[best_continuing], self[best_terminated]\n",
        "\n",
        "            \n",
        "    def get_topk_non_repeating(\n",
        "        self,\n",
        "        logprobs: Float[Tensor, \"batch d_vocab\"],\n",
        "        no_repeat_ngram_size: Optional[int],\n",
        "        k: int,\n",
        "    ) -> Tuple[Float[Tensor, \"k\"], Int[Tensor, \"k\"]]:\n",
        "        '''\n",
        "        logprobs:\n",
        "            tensor of the log-probs for the next token\n",
        "        no_repeat_ngram_size:\n",
        "            size of ngram to avoid repeating\n",
        "        k:\n",
        "            number of top logits to return, for each beam in our collection\n",
        "\n",
        "        Returns:\n",
        "            equivalent to the output of `logprobs.topk(dim=-1)`, but makes sure\n",
        "            that no returned tokens would produce an ngram of size  `no_repeat_ngram_size`\n",
        "            which has already appeared in `self.tokens`.\n",
        "        '''\n",
        "        batch, seq_len = self.tokens.shape\n",
        "        neg_inf = t.tensor(-1.0e4).to(device)\n",
        "\n",
        "        # If completion isn't long enough for a repetition, or we have no restructions, just return topk\n",
        "        if (no_repeat_ngram_size is not None) and (seq_len > no_repeat_ngram_size-1):\n",
        "            # Otherwise, we need to check for ngram repetitions\n",
        "            # First, get the most recent `no_repeat_ngram_size-1` tokens\n",
        "            last_ngram_prefix = self.tokens[:, seq_len - (no_repeat_ngram_size-1):]\n",
        "            # Next, find all the tokens we're not allowed to generate (by going iterating through past ngrams and seeing if those ngram prefixes match the last one)\n",
        "            for i in range(seq_len - (no_repeat_ngram_size-1)):\n",
        "                ngrams = self.tokens[:, i:i+no_repeat_ngram_size] # (batch, ngram)\n",
        "                ngrams_are_repeated = (ngrams[:, :-1] == last_ngram_prefix).all(-1) # (batch,)\n",
        "                ngram_end_tokens = ngrams[:, [-1]] # (batch, 1)\n",
        "                # Fill logprobs with neginf wherever the ngrams are repeated\n",
        "                logprobs[range(batch), ngram_end_tokens] = t.where(\n",
        "                    ngrams_are_repeated,\n",
        "                    neg_inf,\n",
        "                    logprobs[range(batch), ngram_end_tokens],\n",
        "            )\n",
        "\n",
        "        # Finally, get our actual tokens\n",
        "        return logprobs.topk(k=k, dim=-1)\n",
        "\n",
        "    def print(self, title=\"Best completions\", max_print_chars=80) -> None:\n",
        "        '''\n",
        "        Prints out a set of sequences with their corresponding logitsums.\n",
        "        '''\n",
        "        if len(self.tokens) == 0:\n",
        "            return\n",
        "        table = Table(\"logitsum\", \"completion\", title=title)\n",
        "        for logprob_sum, tokens in zip(self.logprob_sums, self.tokens):\n",
        "            text = self.tokenizer.decode(tokens)\n",
        "            if len(repr(text)) > max_print_chars:\n",
        "                text = text[:int(0.3 * max_print_chars)] + \" ... \" + text[-int(0.7 * max_print_chars):]\n",
        "            table.add_row(f\"{logprob_sum:>8.3f}\", repr(text))\n",
        "        rprint(table)\n",
        "\n",
        "\n",
        "@t.inference_mode()\n",
        "def beam_search(\n",
        "    self: TransformerSampler,\n",
        "    prompt: str,\n",
        "    num_return_sequences: int,\n",
        "    num_beams: int,\n",
        "    max_new_tokens: int,\n",
        "    no_repeat_ngram_size: Optional[int] = None,\n",
        "    kv_cache: Optional[KeyValueCache] = None,\n",
        "    verbose=False\n",
        ") -> List[Tuple[float, Tensor]]:\n",
        "    '''\n",
        "    Implements a beam search, by repeatedly performing the `generate` and `filter` steps (starting\n",
        "    from the initial prompt) until either of the two stopping criteria are met:\n",
        "\n",
        "        (1) we've generated `max_new_tokens` tokens, or\n",
        "        (2) we've generated `num_returns_sequences` terminating sequences.\n",
        "\n",
        "    To modularize this function, most of the actual complexity is in the Beams class,\n",
        "    in the `generate` and `filter` methods.\n",
        "    '''\n",
        "\n",
        "    assert num_return_sequences <= num_beams\n",
        "    self.model.eval()\n",
        "\n",
        "    # SOLUTION\n",
        "    tokens = self.tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # List for final beams to return (and early terminations)\n",
        "    final_logprobs_and_completions: List[Tuple[float, str]] = []\n",
        "    # Keep track of all best beams after each step\n",
        "    best_beams = Beams(self.model, self.tokenizer, t.tensor([0.0]).to(device), tokens, kv_cache)\n",
        "\n",
        "    for n in tqdm(range(max_new_tokens)):\n",
        "\n",
        "        # Generation step\n",
        "        best_beams = best_beams.generate(num_beams, no_repeat_ngram_size)\n",
        "\n",
        "        # Filtering step\n",
        "        best_beams, best_beams_terminated = best_beams.filter(num_beams)\n",
        "        final_logprobs_and_completions.extend(best_beams_terminated.logprobs_and_completions)\n",
        "\n",
        "        # Print output\n",
        "        if verbose:\n",
        "            best_beams.print()\n",
        "\n",
        "        # Check stopping condition\n",
        "        if len(final_logprobs_and_completions) >= num_return_sequences:\n",
        "            return final_logprobs_and_completions[:num_return_sequences]\n",
        "\n",
        "    final_logprobs_and_completions.extend(best_beams.logprobs_and_completions)\n",
        "    final_logprobs_and_completions = final_logprobs_and_completions[:num_return_sequences]\n",
        "    return final_logprobs_and_completions\n",
        "\n",
        "\n",
        "TransformerSampler.beam_search = beam_search\n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>Code to verify that the same output is being produced by cache and no-cache versions (and to compare speeds)</summary>\n",
        "\n",
        "```python\n",
        "prompt = \"For you, the day Bison graced your village was the most important day of your life. But for me, it was\"\n",
        "orig_len = len(tokenizer.encode(prompt))\n",
        "\n",
        "beam_search_kwargs = dict(\n",
        "    prompt=prompt,\n",
        "    num_return_sequences=3,\n",
        "    num_beams=20,\n",
        "    max_new_tokens=60,\n",
        "    no_repeat_ngram_size=2,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "sampler = TransformerSampler(model, tokenizer)\n",
        "\n",
        "# Run the noncached version\n",
        "t0 = time.time()\n",
        "final_logitsums_and_completions = sampler.beam_search(**beam_search_kwargs)\n",
        "logprob_sum, text = final_logitsums_and_completions[0]\n",
        "avg_logprob_as_prob = t.tensor(logprob_sum / (len(tokenizer.encode(text)) - orig_len)).exp().item()\n",
        "print(f\"Time (without cache): {time.time() - t0:.2f} seconds\")\n",
        "print(f\"Avg logprob (expressed as a probability) = {avg_logprob_as_prob:.3f}\")\n",
        "rprint(f\"Output:\\n\\n[bold dark_orange]{text}[/]\\n\\n\")\n",
        "\n",
        "# Run the cached version\n",
        "t0 = time.time()\n",
        "beam_search_kwargs[\"kv_cache\"] = KeyValueCache.new_empty(model.cfg)\n",
        "final_logitsums_and_completions = sampler.beam_search(**beam_search_kwargs)\n",
        "logprob_sum, text_with_cache = final_logitsums_and_completions[0]\n",
        "avg_logprob_as_prob = t.tensor(logprob_sum / (len(tokenizer.encode(text)) - orig_len)).exp().item()\n",
        "print(f\"Time (with cache): {time.time() - t0:.2f} seconds\")\n",
        "print(f\"Avg logprob (as probability) = {avg_logprob_as_prob:.3f}\", end=\"\")\n",
        "rprint(f\"Output:\\n\\n[bold dark_orange]{text_with_cache}[/]\\n\\n\")\n",
        "\n",
        "# Check they are the same\n",
        "assert text == text_with_cache, \"Your outputs are different, meaning you've probably made a mistake in your cache implementation.\"\n",
        "print(\"Tests passed!\")\n",
        "```\n",
        "\n",
        "</details>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QfeyG6NZm4SC",
        "hrSd3-YnfHN9"
      ],
      "provenance": [],
      "gpuClass": "premium",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "arena",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0575d7a87c0e74eddddcbc1a627da1d71db6b89a3121c036174dfb29a1bf0df3"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0015946918f945d9af146b54051acd94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee1eff99922f457e8a526d773364dbe8",
              "IPY_MODEL_fe9503f78dd348a3ab2cbb78d19c1dd8",
              "IPY_MODEL_cb551ee879a64bfca7fd5a5eaee9f11c"
            ],
            "layout": "IPY_MODEL_ed26d38dd6e34c0caaddd489aa536059"
          }
        },
        "ee1eff99922f457e8a526d773364dbe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075a61310c004b92b4bc47e70b9662cf",
            "placeholder": "​",
            "style": "IPY_MODEL_2c8ccf42eafa49928164bce44f7a29a5",
            "value": "config.json: 100%"
          }
        },
        "fe9503f78dd348a3ab2cbb78d19c1dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cb9a1cffb654cf79f39f3461d464092",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_630a94807c3a4275a97e32e4db240d9b",
            "value": 665
          }
        },
        "cb551ee879a64bfca7fd5a5eaee9f11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e0eed38fd0a4c6f959d6690b10791e0",
            "placeholder": "​",
            "style": "IPY_MODEL_876adc8e220d47dda83a0077675dfa31",
            "value": " 665/665 [00:00&lt;00:00, 50.7kB/s]"
          }
        },
        "ed26d38dd6e34c0caaddd489aa536059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "075a61310c004b92b4bc47e70b9662cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c8ccf42eafa49928164bce44f7a29a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cb9a1cffb654cf79f39f3461d464092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630a94807c3a4275a97e32e4db240d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e0eed38fd0a4c6f959d6690b10791e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876adc8e220d47dda83a0077675dfa31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "950813e2a1984a0082977286c7c7022b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54e16222c1f949db85ee609f3d120d0e",
              "IPY_MODEL_20bf8db8e6374db399d59705252d5408",
              "IPY_MODEL_ad8b1cf5c9014c6a9d800acec123294b"
            ],
            "layout": "IPY_MODEL_9fadb4b96e404eb49d6f5fdd844e39ea"
          }
        },
        "54e16222c1f949db85ee609f3d120d0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_278b03504c6c451c934b47e7635cf0bd",
            "placeholder": "​",
            "style": "IPY_MODEL_77eddc25f01c4639a1a1ac178554fbab",
            "value": "model.safetensors: 100%"
          }
        },
        "20bf8db8e6374db399d59705252d5408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a222009ddf4e4a9192a7a6ca1a1e91",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c24c09556174b94a47704886315dd3e",
            "value": 548105171
          }
        },
        "ad8b1cf5c9014c6a9d800acec123294b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de3e465282f44ce6911dd96919452dbd",
            "placeholder": "​",
            "style": "IPY_MODEL_d9205faec51e4b57bc3978da18503d08",
            "value": " 548M/548M [00:01&lt;00:00, 416MB/s]"
          }
        },
        "9fadb4b96e404eb49d6f5fdd844e39ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "278b03504c6c451c934b47e7635cf0bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77eddc25f01c4639a1a1ac178554fbab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86a222009ddf4e4a9192a7a6ca1a1e91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c24c09556174b94a47704886315dd3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de3e465282f44ce6911dd96919452dbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9205faec51e4b57bc3978da18503d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a62aa7649d2748d2b41df6e4fb6d2e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_222b8ec93e894e22957900e2787a3e2e",
              "IPY_MODEL_1bf8dfa8582a40f3ad751caddf170bae",
              "IPY_MODEL_f87e918953e04ddd9bb431782ed4e253"
            ],
            "layout": "IPY_MODEL_b5e75fabaee142b9ab1639fcfb5ffe2c"
          }
        },
        "222b8ec93e894e22957900e2787a3e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdec3bea0df942a99fef2f04c9d0f0b0",
            "placeholder": "​",
            "style": "IPY_MODEL_41adb3370eff408eb6c6b199e2bdd550",
            "value": "generation_config.json: 100%"
          }
        },
        "1bf8dfa8582a40f3ad751caddf170bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76362cdfd0534825a28473fd9b6f4693",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e21bc65eada4bf2aff27119aa117f09",
            "value": 124
          }
        },
        "f87e918953e04ddd9bb431782ed4e253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34834eff60784feeb52edec0ebd6738c",
            "placeholder": "​",
            "style": "IPY_MODEL_e72541af8cac46e3b494a1c849923cde",
            "value": " 124/124 [00:00&lt;00:00, 9.73kB/s]"
          }
        },
        "b5e75fabaee142b9ab1639fcfb5ffe2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdec3bea0df942a99fef2f04c9d0f0b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41adb3370eff408eb6c6b199e2bdd550": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76362cdfd0534825a28473fd9b6f4693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e21bc65eada4bf2aff27119aa117f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34834eff60784feeb52edec0ebd6738c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e72541af8cac46e3b494a1c849923cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "553e9f39e15340bc836fa51befa7ce11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e565c1ec5eb8448496ba4a5dd8996048",
              "IPY_MODEL_ae1b6d049ef54bfb81e24e05ee0b3641",
              "IPY_MODEL_f6b30fb26e254831b40527e4c72b875f"
            ],
            "layout": "IPY_MODEL_78a175dca13b416c90cc4edd42756260"
          }
        },
        "e565c1ec5eb8448496ba4a5dd8996048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1694aaddf86f4385ac792548ad98d584",
            "placeholder": "​",
            "style": "IPY_MODEL_480a21cd285e4b39af2cbb354bba3bf6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ae1b6d049ef54bfb81e24e05ee0b3641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_188b50214aea42e3a31036b65667ef06",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45941b84bcf6418da9ec01c6d4cf07ee",
            "value": 26
          }
        },
        "f6b30fb26e254831b40527e4c72b875f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aacc411046b348e5ab2770bfb94a0eb4",
            "placeholder": "​",
            "style": "IPY_MODEL_0edf547e29844a00b63c6b1ef90f7fcc",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.00kB/s]"
          }
        },
        "78a175dca13b416c90cc4edd42756260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1694aaddf86f4385ac792548ad98d584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480a21cd285e4b39af2cbb354bba3bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "188b50214aea42e3a31036b65667ef06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45941b84bcf6418da9ec01c6d4cf07ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aacc411046b348e5ab2770bfb94a0eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0edf547e29844a00b63c6b1ef90f7fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0cf94d75fd247d6802e7d13dc1ca7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d37e4bc33edb47fb8a7248855b27596e",
              "IPY_MODEL_34ac0d9e887941ac8f084f875b7fd442",
              "IPY_MODEL_eb39057fc005401cb65b094185763b60"
            ],
            "layout": "IPY_MODEL_af950be1ba7945f0a00da6f65687ba15"
          }
        },
        "d37e4bc33edb47fb8a7248855b27596e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3075afe58c824d8ab9ee46b67c6e8f84",
            "placeholder": "​",
            "style": "IPY_MODEL_ed7bb1f544784007b8638ba3455fdd1d",
            "value": "vocab.json: 100%"
          }
        },
        "34ac0d9e887941ac8f084f875b7fd442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3947d6d4147c417599ddc686439671bc",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b34bbc55b9314902ba71966cedc7f944",
            "value": 1042301
          }
        },
        "eb39057fc005401cb65b094185763b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64d6ae72a52d47dd9bdf9011fe31cab7",
            "placeholder": "​",
            "style": "IPY_MODEL_9c7e8139bd464f9a913a0d9e5e790799",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.67MB/s]"
          }
        },
        "af950be1ba7945f0a00da6f65687ba15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3075afe58c824d8ab9ee46b67c6e8f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7bb1f544784007b8638ba3455fdd1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3947d6d4147c417599ddc686439671bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34bbc55b9314902ba71966cedc7f944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64d6ae72a52d47dd9bdf9011fe31cab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c7e8139bd464f9a913a0d9e5e790799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de831afb681746e59e007e72d694025d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20e8e3556294493db0eeed85342eba3f",
              "IPY_MODEL_c232be08bc624b4bb74a84ac6a9ae616",
              "IPY_MODEL_04e22bec6aed478281cc3c2e8887222b"
            ],
            "layout": "IPY_MODEL_9fc56e7238e54dd690d8c2359d83ee13"
          }
        },
        "20e8e3556294493db0eeed85342eba3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0a886a4acf444ceaca08dca6d63e503",
            "placeholder": "​",
            "style": "IPY_MODEL_ace0d8edc2c44b74b6e0982be3f13e70",
            "value": "merges.txt: 100%"
          }
        },
        "c232be08bc624b4bb74a84ac6a9ae616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29012f2aa71444dfa6bce280f0a1619a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_170866a0785a4f5a805f3a5478947d2a",
            "value": 456318
          }
        },
        "04e22bec6aed478281cc3c2e8887222b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c87c004d35441459811f42545a1ee65",
            "placeholder": "​",
            "style": "IPY_MODEL_4165bad1fa324a2998d8ea1cdaba5112",
            "value": " 456k/456k [00:00&lt;00:00, 34.6MB/s]"
          }
        },
        "9fc56e7238e54dd690d8c2359d83ee13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0a886a4acf444ceaca08dca6d63e503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ace0d8edc2c44b74b6e0982be3f13e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29012f2aa71444dfa6bce280f0a1619a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "170866a0785a4f5a805f3a5478947d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c87c004d35441459811f42545a1ee65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4165bad1fa324a2998d8ea1cdaba5112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef61e4095994d5eadaa12a0bcd1cc04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d9c3007e35446c19f8ddaadfca01dae",
              "IPY_MODEL_736eabd2ba224a11a97a497db93d695e",
              "IPY_MODEL_cb3fd81af37148b6b14625bf055b51b3"
            ],
            "layout": "IPY_MODEL_5ce511c7aba8434b94b1eb5df961e37b"
          }
        },
        "7d9c3007e35446c19f8ddaadfca01dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1169ab7623e34855bb8316fe87d1a086",
            "placeholder": "​",
            "style": "IPY_MODEL_64c02213a26546a4ace65f53c3e6e6b4",
            "value": "tokenizer.json: 100%"
          }
        },
        "736eabd2ba224a11a97a497db93d695e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71f644378fdb4bad94e0ccde33df06d7",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7c301aa2f084c1794349d0aa1cec480",
            "value": 1355256
          }
        },
        "cb3fd81af37148b6b14625bf055b51b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b4a931186f64274bd84c8bb2a3d63cb",
            "placeholder": "​",
            "style": "IPY_MODEL_edab8ff22ad547098ad33cb04d69b72d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 3.21MB/s]"
          }
        },
        "5ce511c7aba8434b94b1eb5df961e37b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1169ab7623e34855bb8316fe87d1a086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c02213a26546a4ace65f53c3e6e6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71f644378fdb4bad94e0ccde33df06d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7c301aa2f084c1794349d0aa1cec480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b4a931186f64274bd84c8bb2a3d63cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edab8ff22ad547098ad33cb04d69b72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "423add32e2cb4253b465fe1b9833fb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a704f31224641d49d99890b359f5d5c",
              "IPY_MODEL_d5dd6a42c8544026897a1ec22512c046",
              "IPY_MODEL_783ba1dc24ec4089b61ffbe07013b113"
            ],
            "layout": "IPY_MODEL_c7dc99763a9f46f79ec800fee142931a"
          }
        },
        "8a704f31224641d49d99890b359f5d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8344bd4af231407399372d300203f7cc",
            "placeholder": "​",
            "style": "IPY_MODEL_90546a2297984cf191002fdb6fbc3423",
            "value": "100%"
          }
        },
        "d5dd6a42c8544026897a1ec22512c046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d87fa6045b5e46a3b2f822144a2e6427",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34e4ad352a8d40e8b9a179e12dde9a75",
            "value": 100
          }
        },
        "783ba1dc24ec4089b61ffbe07013b113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6132bd251f40489d8d66c75607eb5184",
            "placeholder": "​",
            "style": "IPY_MODEL_3060e92bba4d4b558983a29376b48961",
            "value": " 100/100 [00:02&lt;00:00, 43.51it/s]"
          }
        },
        "c7dc99763a9f46f79ec800fee142931a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8344bd4af231407399372d300203f7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90546a2297984cf191002fdb6fbc3423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d87fa6045b5e46a3b2f822144a2e6427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e4ad352a8d40e8b9a179e12dde9a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6132bd251f40489d8d66c75607eb5184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3060e92bba4d4b558983a29376b48961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d72e1585d9a4e34b925aa3b1ea7503e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_825cdf76de62438dad7dc755b1ba12e3",
              "IPY_MODEL_8a6342ffc32a43e7880eb37384ae7b81",
              "IPY_MODEL_52314c5b159f4e5e9e7a93426ead8399"
            ],
            "layout": "IPY_MODEL_5670e6b16ca643419547bc99fe81c171"
          }
        },
        "825cdf76de62438dad7dc755b1ba12e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2942b86678224a73bbe6ba354b15bb38",
            "placeholder": "​",
            "style": "IPY_MODEL_7a447b4eb822468b96917e753375f254",
            "value": "Downloading readme: 100%"
          }
        },
        "8a6342ffc32a43e7880eb37384ae7b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a26e62c8dbc48048e93a17596aed154",
            "max": 373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc776b3ee9704c36974cfed5904185af",
            "value": 373
          }
        },
        "52314c5b159f4e5e9e7a93426ead8399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac30b60542954d5e92f1a40f74d90dd1",
            "placeholder": "​",
            "style": "IPY_MODEL_95539ed2073d43b38b4ebdf767a25d07",
            "value": " 373/373 [00:00&lt;00:00, 3.71kB/s]"
          }
        },
        "5670e6b16ca643419547bc99fe81c171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2942b86678224a73bbe6ba354b15bb38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a447b4eb822468b96917e753375f254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a26e62c8dbc48048e93a17596aed154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc776b3ee9704c36974cfed5904185af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac30b60542954d5e92f1a40f74d90dd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95539ed2073d43b38b4ebdf767a25d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa9a2b6ef0264f5a8eb73164a5f6120b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e83abba8f2ff4d80a707e0ed2efd9795",
              "IPY_MODEL_ece95aed2b8243949d34a831dc6eae38",
              "IPY_MODEL_7d660b161f4e44369858d5974ea56544"
            ],
            "layout": "IPY_MODEL_f8fcc4d6c62d40e99a41aa9a68fac1f0"
          }
        },
        "e83abba8f2ff4d80a707e0ed2efd9795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d05ce7eb97ed497a83cd30d5a7fb9ffb",
            "placeholder": "​",
            "style": "IPY_MODEL_4ba3b063544f402da8cfc6676c5f93ea",
            "value": "Downloading metadata: 100%"
          }
        },
        "ece95aed2b8243949d34a831dc6eae38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c82099bdb3a4e68b9624bbc51075ad0",
            "max": 921,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_124bc5fe6cfc4c0690a4e7fa878a5ed7",
            "value": 921
          }
        },
        "7d660b161f4e44369858d5974ea56544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb3ba212c7b44cdb2b6cd61f05d9ec0",
            "placeholder": "​",
            "style": "IPY_MODEL_437586c8de6145d7b2cd0cc6a59438f2",
            "value": " 921/921 [00:00&lt;00:00, 8.62kB/s]"
          }
        },
        "f8fcc4d6c62d40e99a41aa9a68fac1f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05ce7eb97ed497a83cd30d5a7fb9ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ba3b063544f402da8cfc6676c5f93ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c82099bdb3a4e68b9624bbc51075ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "124bc5fe6cfc4c0690a4e7fa878a5ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fb3ba212c7b44cdb2b6cd61f05d9ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "437586c8de6145d7b2cd0cc6a59438f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bacdd45bffd4a69a020252a28bfa481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f2894184ccf4296a5c05812fd6f7492",
              "IPY_MODEL_345f86f72f0e46a7a87b67574a0ad219",
              "IPY_MODEL_0adcba36e2d3493aa3c7098f70b6d140"
            ],
            "layout": "IPY_MODEL_efb257a1c65c451890a6113b0c32a65f"
          }
        },
        "9f2894184ccf4296a5c05812fd6f7492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28247701a79441fe98c5128073e4b119",
            "placeholder": "​",
            "style": "IPY_MODEL_e438a600992f44208e261363a663e28e",
            "value": "Downloading data: 100%"
          }
        },
        "345f86f72f0e46a7a87b67574a0ad219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf97d7bb016140648f441aa70d7dad79",
            "max": 33262901,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d12ea9b593364dfeb13366d397ca6133",
            "value": 33262901
          }
        },
        "0adcba36e2d3493aa3c7098f70b6d140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb2109a7e867466abd03a4bf38da48fa",
            "placeholder": "​",
            "style": "IPY_MODEL_40c3abdca2ac465db1c5981674dd9f4c",
            "value": " 33.3M/33.3M [00:00&lt;00:00, 70.6MB/s]"
          }
        },
        "efb257a1c65c451890a6113b0c32a65f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28247701a79441fe98c5128073e4b119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e438a600992f44208e261363a663e28e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf97d7bb016140648f441aa70d7dad79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12ea9b593364dfeb13366d397ca6133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb2109a7e867466abd03a4bf38da48fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40c3abdca2ac465db1c5981674dd9f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "384efec36e9c4477b2449496216b7681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4dc9eaf204f446786d2a0ee3f403caa",
              "IPY_MODEL_8147a5afa72f43858edd8452f091504d",
              "IPY_MODEL_a44f4dfc85a3495785994d334830a19e"
            ],
            "layout": "IPY_MODEL_81ed3d82d57747169094f4425a6c4ace"
          }
        },
        "f4dc9eaf204f446786d2a0ee3f403caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33ef2be3857444d5801d815f9af4b1f9",
            "placeholder": "​",
            "style": "IPY_MODEL_25df0b21c934420ebf3d47cb9c830a0c",
            "value": "Generating train split: 100%"
          }
        },
        "8147a5afa72f43858edd8452f091504d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdc61ce387a4f3eb100e9300f157e87",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6c9deef60994709b5769e7b363de75d",
            "value": 10000
          }
        },
        "a44f4dfc85a3495785994d334830a19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3184da41261549418572d09f15eae02a",
            "placeholder": "​",
            "style": "IPY_MODEL_78142e3e971c461898362b30d7d1d4e8",
            "value": " 10000/10000 [00:00&lt;00:00, 33014.60 examples/s]"
          }
        },
        "81ed3d82d57747169094f4425a6c4ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ef2be3857444d5801d815f9af4b1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25df0b21c934420ebf3d47cb9c830a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bdc61ce387a4f3eb100e9300f157e87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c9deef60994709b5769e7b363de75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3184da41261549418572d09f15eae02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78142e3e971c461898362b30d7d1d4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28ef4ce9b21c415aa3e6e0865f900063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49b905bbefc14b7ba0c385fd08ab2adf",
              "IPY_MODEL_26b7b9b0f99c45dcb93f8e226e5bf10d",
              "IPY_MODEL_b67a1dc0475d4325ad96212e988087ea"
            ],
            "layout": "IPY_MODEL_996f0d58fd9d43d5adda88f3fac355cb"
          }
        },
        "49b905bbefc14b7ba0c385fd08ab2adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f77e9bf736e49169c1b17ab3b031c1c",
            "placeholder": "​",
            "style": "IPY_MODEL_0a309185dc784bbab59b283f1a9d5697",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "26b7b9b0f99c45dcb93f8e226e5bf10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2676ccaeac4d009ec1f4515d5b29c1",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f655713978c4e61b390e24f3520d683",
            "value": 10000
          }
        },
        "b67a1dc0475d4325ad96212e988087ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b696f95d2d534106a778bd9f8df285e3",
            "placeholder": "​",
            "style": "IPY_MODEL_6131e9aa8d4243e5aad58a6860aa25c0",
            "value": " 10000/10000 [00:21&lt;00:00, 401.18 examples/s]"
          }
        },
        "996f0d58fd9d43d5adda88f3fac355cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f77e9bf736e49169c1b17ab3b031c1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a309185dc784bbab59b283f1a9d5697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e2676ccaeac4d009ec1f4515d5b29c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f655713978c4e61b390e24f3520d683": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b696f95d2d534106a778bd9f8df285e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6131e9aa8d4243e5aad58a6860aa25c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7926d7fede854fd89577eb80224d5048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6322b8f7f1f4a3d900cdc258dc86b3c",
              "IPY_MODEL_dea20381b20a4d3ea64d8ccee32131ea"
            ],
            "layout": "IPY_MODEL_1453506db31b4d3a819709bbdbe210c5"
          }
        },
        "b6322b8f7f1f4a3d900cdc258dc86b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c81805aa41714f05bfcac791f1f6ee3d",
            "placeholder": "​",
            "style": "IPY_MODEL_edfc917d6c84415493d97fab928b80f4",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "dea20381b20a4d3ea64d8ccee32131ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1269f018405470bb72a24deff1f9ee8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_171094401c5844b1bb3ad34cc3922150",
            "value": 1
          }
        },
        "1453506db31b4d3a819709bbdbe210c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c81805aa41714f05bfcac791f1f6ee3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfc917d6c84415493d97fab928b80f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1269f018405470bb72a24deff1f9ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "171094401c5844b1bb3ad34cc3922150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94760749ed664a36b80f7988189128af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d062b825e8864d7cbe41a43bd1e9fcc5",
              "IPY_MODEL_cedf1e21802d4fd4890d1183bb9f1c81",
              "IPY_MODEL_4e19eca19aa942d7b802ce8c04df5523"
            ],
            "layout": "IPY_MODEL_9ec83ff05ee84b0eb799282215a01c9b"
          }
        },
        "d062b825e8864d7cbe41a43bd1e9fcc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b34a3fe895848e4a41d42eba37f95ad",
            "placeholder": "​",
            "style": "IPY_MODEL_17f8abe5d82a44a8a47c55a37b4c7846",
            "value": ""
          }
        },
        "cedf1e21802d4fd4890d1183bb9f1c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e449fc2c0e844bca5018559eac43532",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98d069ac707243f3a81dab579afeb106",
            "value": 1
          }
        },
        "4e19eca19aa942d7b802ce8c04df5523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c77d8d00bbb0492994715a6b4750221d",
            "placeholder": "​",
            "style": "IPY_MODEL_b9136da526d24f0fac5652df5578eee7",
            "value": " 200/? [00:22&lt;00:00,  9.23it/s]"
          }
        },
        "9ec83ff05ee84b0eb799282215a01c9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b34a3fe895848e4a41d42eba37f95ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17f8abe5d82a44a8a47c55a37b4c7846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e449fc2c0e844bca5018559eac43532": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "98d069ac707243f3a81dab579afeb106": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c77d8d00bbb0492994715a6b4750221d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9136da526d24f0fac5652df5578eee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de5a5bf19f60466ab08a0027794179e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e80897daf6347f28acae6303ca2ca40",
              "IPY_MODEL_a5517a2d54d340dc8da51dd1fc144468",
              "IPY_MODEL_94200160ce0444f9a81720a3beae9c9a"
            ],
            "layout": "IPY_MODEL_3efb1af563ff4d408187dce321beea79"
          }
        },
        "9e80897daf6347f28acae6303ca2ca40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf3a1fa415d04f3da1a4320c02291881",
            "placeholder": "​",
            "style": "IPY_MODEL_97ec7ed3eb1c42d9bbede2d71ea9f0b4",
            "value": ""
          }
        },
        "a5517a2d54d340dc8da51dd1fc144468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fa0042fcee0461bb73cd2eb5ca1db06",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92d2efd1f3d34d4da4f3d52cffabdefa",
            "value": 1
          }
        },
        "94200160ce0444f9a81720a3beae9c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f1171c55d6941f485f4502dfd5c83ef",
            "placeholder": "​",
            "style": "IPY_MODEL_769296098eb94f22baceec56257cb48a",
            "value": " 200/? [00:41&lt;00:00,  9.30it/s]"
          }
        },
        "3efb1af563ff4d408187dce321beea79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf3a1fa415d04f3da1a4320c02291881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97ec7ed3eb1c42d9bbede2d71ea9f0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fa0042fcee0461bb73cd2eb5ca1db06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "92d2efd1f3d34d4da4f3d52cffabdefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f1171c55d6941f485f4502dfd5c83ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "769296098eb94f22baceec56257cb48a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5d8c16fff9f47a4ba043699c22648d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_afaa7f532fdb4baca258a396efb245e0",
              "IPY_MODEL_c99c8854ec15452b9c949b7b1a7de6a4",
              "IPY_MODEL_eb45fe1701404155bce598c83e457377"
            ],
            "layout": "IPY_MODEL_6604442f4fdd459394f2c295af1b9634"
          }
        },
        "afaa7f532fdb4baca258a396efb245e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a10f752b0c0c44e8864d035c76f61fa2",
            "placeholder": "​",
            "style": "IPY_MODEL_52d645051e7f4a29a59b51542360bb14",
            "value": ""
          }
        },
        "c99c8854ec15452b9c949b7b1a7de6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c27dc2df75f04d38b4c10fdbbec60f8b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41d1d0ca9dc84f689df1cb5332ad1c08",
            "value": 1
          }
        },
        "eb45fe1701404155bce598c83e457377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6807a1a30f6842feae04ee097776477c",
            "placeholder": "​",
            "style": "IPY_MODEL_3f51dbaf75c04167ab2b1bf916be0f76",
            "value": " 200/? [00:21&lt;00:00,  9.32it/s]"
          }
        },
        "6604442f4fdd459394f2c295af1b9634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a10f752b0c0c44e8864d035c76f61fa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52d645051e7f4a29a59b51542360bb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c27dc2df75f04d38b4c10fdbbec60f8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "41d1d0ca9dc84f689df1cb5332ad1c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6807a1a30f6842feae04ee097776477c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f51dbaf75c04167ab2b1bf916be0f76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1932e287c73a484087aba1ef1fb9bcff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61eee32878564a98b506d0a849b4e7dd",
              "IPY_MODEL_11d00e2182464d87aaf2de45c8276590",
              "IPY_MODEL_dc681ac5e1e7400f92bf9211b0b031e3"
            ],
            "layout": "IPY_MODEL_2f25b4fdfb544d8b8fd9d77fa68c68cb"
          }
        },
        "61eee32878564a98b506d0a849b4e7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_709f66aa9e4049848d562f49d4aaa4be",
            "placeholder": "​",
            "style": "IPY_MODEL_8c927a77f83d4b36951c757883f956c9",
            "value": ""
          }
        },
        "11d00e2182464d87aaf2de45c8276590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67efd2d359d041c69df5886b8e7fe2f9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c78679919c73408bbc406822b5424400",
            "value": 1
          }
        },
        "dc681ac5e1e7400f92bf9211b0b031e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e60a2086942d4a5197dab055d83598fa",
            "placeholder": "​",
            "style": "IPY_MODEL_1b5279dce08c45ba963b3fadb13f2fdb",
            "value": " 200/? [00:21&lt;00:00,  9.41it/s]"
          }
        },
        "2f25b4fdfb544d8b8fd9d77fa68c68cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "709f66aa9e4049848d562f49d4aaa4be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c927a77f83d4b36951c757883f956c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67efd2d359d041c69df5886b8e7fe2f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c78679919c73408bbc406822b5424400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e60a2086942d4a5197dab055d83598fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b5279dce08c45ba963b3fadb13f2fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75878d021c8e415eb6810e3c85e5929d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd9b54f374354a6f89af7d092fc1248e",
              "IPY_MODEL_a5bbd8e921d34fe9a4ddb974a6bdfe97",
              "IPY_MODEL_ca599287642f48a6b0c55c811b54f4c5"
            ],
            "layout": "IPY_MODEL_78625a98f5ec4e28b8cb29aeb06692ba"
          }
        },
        "bd9b54f374354a6f89af7d092fc1248e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40903de06f99410fb4f58fa00b87c92b",
            "placeholder": "​",
            "style": "IPY_MODEL_6d9d15a00e8e47e1a204491ad361b901",
            "value": ""
          }
        },
        "a5bbd8e921d34fe9a4ddb974a6bdfe97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c13e9176d8b4001b2a4ffa1ced8c20d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_724841eff6b64b8385f3d89a019788b3",
            "value": 1
          }
        },
        "ca599287642f48a6b0c55c811b54f4c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b990a4132bb2454ea55c59c8da93cbfc",
            "placeholder": "​",
            "style": "IPY_MODEL_37492c59a9744cd49271bb894d954072",
            "value": " 200/? [00:21&lt;00:00,  9.33it/s]"
          }
        },
        "78625a98f5ec4e28b8cb29aeb06692ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40903de06f99410fb4f58fa00b87c92b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d9d15a00e8e47e1a204491ad361b901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c13e9176d8b4001b2a4ffa1ced8c20d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "724841eff6b64b8385f3d89a019788b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b990a4132bb2454ea55c59c8da93cbfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37492c59a9744cd49271bb894d954072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a0cbc464e7645c2a91ce3cfbd502adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0382ea97c5e4c9da9a7c679168e226c",
              "IPY_MODEL_32a335f849794a3fad777ff5645c9ffb",
              "IPY_MODEL_60d4d76a51fd47f294935b9974679d64"
            ],
            "layout": "IPY_MODEL_5b912dcde5d54aa3b41e7266c46b88d2"
          }
        },
        "a0382ea97c5e4c9da9a7c679168e226c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d07567f03b454fe5896bf4f7e96a92dd",
            "placeholder": "​",
            "style": "IPY_MODEL_4dded80ea7274511b4528ad6a2990b60",
            "value": ""
          }
        },
        "32a335f849794a3fad777ff5645c9ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_650d4af300614924ba2107db1beab67f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef941b53fad94ce28fefcecb68fa1650",
            "value": 1
          }
        },
        "60d4d76a51fd47f294935b9974679d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_751cff796aea48d9838f1d9c0eebdf3b",
            "placeholder": "​",
            "style": "IPY_MODEL_b9ba5544c51b4a8684728193ed0548c2",
            "value": " 200/? [00:21&lt;00:00,  9.34it/s]"
          }
        },
        "5b912dcde5d54aa3b41e7266c46b88d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d07567f03b454fe5896bf4f7e96a92dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dded80ea7274511b4528ad6a2990b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "650d4af300614924ba2107db1beab67f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ef941b53fad94ce28fefcecb68fa1650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "751cff796aea48d9838f1d9c0eebdf3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ba5544c51b4a8684728193ed0548c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "577c1e810ce24a47b1dd3f855e64c11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fac91a1e30a4d2699a2398dbd3cdef6",
              "IPY_MODEL_2bef5b01a51e4b59a44a4e4b5402cc06",
              "IPY_MODEL_3b067fa549c74a26b441827a82ce2420"
            ],
            "layout": "IPY_MODEL_07a1460720b24e75b97bc2e9f5858d71"
          }
        },
        "7fac91a1e30a4d2699a2398dbd3cdef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d6e3dd72f6d4d1abd9fbf2147de2b87",
            "placeholder": "​",
            "style": "IPY_MODEL_ac9a19ce5ceb43a2b628e01918f56bb2",
            "value": ""
          }
        },
        "2bef5b01a51e4b59a44a4e4b5402cc06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af0fc46b6ee4456b98c1ea9090c00183",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8732ee87c01409daac4cd61a770b469",
            "value": 1
          }
        },
        "3b067fa549c74a26b441827a82ce2420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124c0311e583433fa5f6dee338aeba7c",
            "placeholder": "​",
            "style": "IPY_MODEL_872bdf9b0c744899b5174c61495638b2",
            "value": " 200/? [00:21&lt;00:00,  9.33it/s]"
          }
        },
        "07a1460720b24e75b97bc2e9f5858d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6e3dd72f6d4d1abd9fbf2147de2b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac9a19ce5ceb43a2b628e01918f56bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af0fc46b6ee4456b98c1ea9090c00183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f8732ee87c01409daac4cd61a770b469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "124c0311e583433fa5f6dee338aeba7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "872bdf9b0c744899b5174c61495638b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52f4a2ca2605491c94805851659c0b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ea81aa9f990447fab2e85138a05412d",
              "IPY_MODEL_0c6494fa8515492da4c7c970f7d50edd",
              "IPY_MODEL_06c3144945d6466cab3133f707c7fc0d"
            ],
            "layout": "IPY_MODEL_5775e314a4fa4f37ab83fafa9bdfb3a0"
          }
        },
        "9ea81aa9f990447fab2e85138a05412d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_292b4c117c1d4d0fbd975124f1e8d755",
            "placeholder": "​",
            "style": "IPY_MODEL_c1efb849e64c48ce8f33e362c20d60df",
            "value": ""
          }
        },
        "0c6494fa8515492da4c7c970f7d50edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d3519369cb74a938f06a6c51e9343aa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_228d41c29fff46c0bab76dc7593f1a74",
            "value": 1
          }
        },
        "06c3144945d6466cab3133f707c7fc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_289942ae5c904f94a94f6d5283a81019",
            "placeholder": "​",
            "style": "IPY_MODEL_7a8b785e1b13432e9f5c018fa20bc096",
            "value": " 200/? [02:01&lt;00:00,  9.22it/s]"
          }
        },
        "5775e314a4fa4f37ab83fafa9bdfb3a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "292b4c117c1d4d0fbd975124f1e8d755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1efb849e64c48ce8f33e362c20d60df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d3519369cb74a938f06a6c51e9343aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "228d41c29fff46c0bab76dc7593f1a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "289942ae5c904f94a94f6d5283a81019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8b785e1b13432e9f5c018fa20bc096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9df7f4547bfb41bf924561c9b8376c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f84df62892e41c2ac4edfc8cb67b76b",
              "IPY_MODEL_ae732c25b30b41fdb3d57a5dc90d9e58",
              "IPY_MODEL_4bccb6a14b1d40749c97988b67846ac1"
            ],
            "layout": "IPY_MODEL_c3afca0a20f54ecb9c0468f2d1365c33"
          }
        },
        "9f84df62892e41c2ac4edfc8cb67b76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc053d48d6b7492ba995b6dd97e20137",
            "placeholder": "​",
            "style": "IPY_MODEL_0c74ed45c44246f8a7e88fe78e0eb791",
            "value": ""
          }
        },
        "ae732c25b30b41fdb3d57a5dc90d9e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91fad78df4c842d69bd517c37b48d604",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfdc04493b93464b8d1e204e4d550c79",
            "value": 1
          }
        },
        "4bccb6a14b1d40749c97988b67846ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e11284081d564b1f9128d03094271e79",
            "placeholder": "​",
            "style": "IPY_MODEL_f00c328728dc42b094f2cbcdf7bfb26f",
            "value": " 200/? [00:21&lt;00:00,  9.36it/s]"
          }
        },
        "c3afca0a20f54ecb9c0468f2d1365c33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc053d48d6b7492ba995b6dd97e20137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c74ed45c44246f8a7e88fe78e0eb791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91fad78df4c842d69bd517c37b48d604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bfdc04493b93464b8d1e204e4d550c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e11284081d564b1f9128d03094271e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f00c328728dc42b094f2cbcdf7bfb26f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdc5630a70e24324a263443d97320b33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdcf2ad740d2458aa6c97976dd4c3e54",
              "IPY_MODEL_64f313bb95b74a56bc911f14ce8ba23a",
              "IPY_MODEL_f45f53ffecc041949801c3fab91aed94"
            ],
            "layout": "IPY_MODEL_a0b0428224ca4f4b8e4bf2b3728db265"
          }
        },
        "bdcf2ad740d2458aa6c97976dd4c3e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fbbe364e2a54049818f1a174b1151f9",
            "placeholder": "​",
            "style": "IPY_MODEL_cf32cb8844044455a7042732dac4f10d",
            "value": ""
          }
        },
        "64f313bb95b74a56bc911f14ce8ba23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f694b6b364a24f838eff3d16bf221b69",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f94e2f5236b9442ea306509332970c2e",
            "value": 1
          }
        },
        "f45f53ffecc041949801c3fab91aed94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14382120dae248558f2ac489ced4392e",
            "placeholder": "​",
            "style": "IPY_MODEL_de5ad2cefa514591a0f18b9979c6f490",
            "value": " 200/? [00:21&lt;00:00,  9.44it/s]"
          }
        },
        "a0b0428224ca4f4b8e4bf2b3728db265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fbbe364e2a54049818f1a174b1151f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf32cb8844044455a7042732dac4f10d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f694b6b364a24f838eff3d16bf221b69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f94e2f5236b9442ea306509332970c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14382120dae248558f2ac489ced4392e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de5ad2cefa514591a0f18b9979c6f490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05da2f71645a4d9ea1874258ce8b7898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_330b527af3324559a5d5715d7f7f098f",
              "IPY_MODEL_145a5469fe624837b58733db02833299"
            ],
            "layout": "IPY_MODEL_c62532321abb41bf8a44d9c22d4ec344"
          }
        },
        "330b527af3324559a5d5715d7f7f098f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7f1aaeeeece46efafc168dfa7f44e94",
            "placeholder": "​",
            "style": "IPY_MODEL_0b798ba92f4b46f4883d2045984f29fd",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "145a5469fe624837b58733db02833299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e0bd9d0dc11434c8e4d93335e2df74e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fa39bfb548f4213b1d58e5e8632e186",
            "value": 1
          }
        },
        "c62532321abb41bf8a44d9c22d4ec344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7f1aaeeeece46efafc168dfa7f44e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b798ba92f4b46f4883d2045984f29fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e0bd9d0dc11434c8e4d93335e2df74e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fa39bfb548f4213b1d58e5e8632e186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "491bfb6e5af9436bb13e37b9c1766696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_573d9c61361a439080c8771b3f618986",
              "IPY_MODEL_ae843ad5499d42f88590bcf62179dbeb",
              "IPY_MODEL_a7f739e148c64a17b0689490feb0c008"
            ],
            "layout": "IPY_MODEL_1f527c21f1d443918238d29e62d949eb"
          }
        },
        "573d9c61361a439080c8771b3f618986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_576f6e8d3e2345e3bba0388cef413a3f",
            "placeholder": "​",
            "style": "IPY_MODEL_b98eb738b2514fdb81606496ac6372b5",
            "value": "100%"
          }
        },
        "ae843ad5499d42f88590bcf62179dbeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa003e1f8fbb4369a04df0f69480e32e",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d94e4fd9865442748b5b3af7ae554bcc",
            "value": 10000
          }
        },
        "a7f739e148c64a17b0689490feb0c008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed756de6b7f3417c9c2c2d2da1c00158",
            "placeholder": "​",
            "style": "IPY_MODEL_9cee96f0a68b440f9c39fb26991da2cc",
            "value": " 10000/10000 [00:48&lt;00:00, 1737.13it/s]"
          }
        },
        "1f527c21f1d443918238d29e62d949eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "576f6e8d3e2345e3bba0388cef413a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b98eb738b2514fdb81606496ac6372b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa003e1f8fbb4369a04df0f69480e32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d94e4fd9865442748b5b3af7ae554bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed756de6b7f3417c9c2c2d2da1c00158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cee96f0a68b440f9c39fb26991da2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34749aecba9f4a98964c3249e76c35ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cf4fd6ab45143a7916ab3db5ead253a",
              "IPY_MODEL_26b1684235c740b2a14305b204c59e99",
              "IPY_MODEL_d2f9e65a424645b8a462d6770d3c06ca"
            ],
            "layout": "IPY_MODEL_6880ca25130b40b8a63ae39683f5e88b"
          }
        },
        "5cf4fd6ab45143a7916ab3db5ead253a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e939766cc143c89fcaff29c39af2bf",
            "placeholder": "​",
            "style": "IPY_MODEL_c0206ec395cd462fb38a24892727d8b9",
            "value": "100%"
          }
        },
        "26b1684235c740b2a14305b204c59e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7637a8abd774cbcb6ea74da5dcfa84d",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46e681775bd24bad8fdb57eeecb8b8ce",
            "value": 10000
          }
        },
        "d2f9e65a424645b8a462d6770d3c06ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b26b11a90d24958bd3db639ca5b0aff",
            "placeholder": "​",
            "style": "IPY_MODEL_f9d0d1acb557461a88b8ba4865390323",
            "value": " 10000/10000 [00:07&lt;00:00, 1369.31it/s]"
          }
        },
        "6880ca25130b40b8a63ae39683f5e88b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e939766cc143c89fcaff29c39af2bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0206ec395cd462fb38a24892727d8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7637a8abd774cbcb6ea74da5dcfa84d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46e681775bd24bad8fdb57eeecb8b8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b26b11a90d24958bd3db639ca5b0aff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9d0d1acb557461a88b8ba4865390323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9260c893fe4444a8b497541d3d4a8b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b3aea9733634378a918836b2a1e1222",
              "IPY_MODEL_1c7b5e15ad35441e8726617d8260683f",
              "IPY_MODEL_8050ab1e3d4c4228944e63e754c0231a"
            ],
            "layout": "IPY_MODEL_91b4a9a4634b4c44923679a09b71fa14"
          }
        },
        "1b3aea9733634378a918836b2a1e1222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_953210ee01974760a85f8e732da61d8c",
            "placeholder": "​",
            "style": "IPY_MODEL_b2fa9452e14a41d09092de717064f80a",
            "value": "100%"
          }
        },
        "1c7b5e15ad35441e8726617d8260683f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a609451399d464885074547713e7d61",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_960a8c27bfd54f8d9d0ba1a57d9fbe74",
            "value": 10000
          }
        },
        "8050ab1e3d4c4228944e63e754c0231a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5df97e8cc14d638b994f29fd9e0fa1",
            "placeholder": "​",
            "style": "IPY_MODEL_c72a6c36faff42139871ced0e38eed30",
            "value": " 10000/10000 [00:08&lt;00:00, 1134.75it/s]"
          }
        },
        "91b4a9a4634b4c44923679a09b71fa14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953210ee01974760a85f8e732da61d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2fa9452e14a41d09092de717064f80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a609451399d464885074547713e7d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "960a8c27bfd54f8d9d0ba1a57d9fbe74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c5df97e8cc14d638b994f29fd9e0fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72a6c36faff42139871ced0e38eed30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}